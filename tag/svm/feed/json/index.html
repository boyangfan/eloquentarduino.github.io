<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><p>{
    "version": "https://jsonfeed.org/version/1.1",
    "user_comment": "This feed allows you to read the posts from this site in any feed reader that supports the JSON Feed format. To add this feed to your reader, copy the following URL -- https://eloquentarduino.github.io/tag/svm/feed/json/ -- and add it your reader.",
    "home_page_url": "https://eloquentarduino.github.io/tag/svm/",
    "feed_url": "https://eloquentarduino.github.io/tag/svm/feed/json/",
    "language": "en-US",
    "title": "svm â€“ Eloquent Arduino Blog",
    "description": "Machine learning on Arduino, programming & electronics",
    "items": [
        {
            "id": "https://eloquentarduino.github.io/?p=1008",
            "url": "https://eloquentarduino.github.io/2020/03/how-to-train-a-iris-classification-machine-learning-classifier-directly-on-your-arduino-board/",
            "title": "How to train a IRIS classification Machine learning classifier directly on your Arduino board",
            "content_html": "</p><p>In this hands-on guide about <a href="%5C%22/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board%5C%22">on-board SVM training</a> we're going to see a classifier in action, training it on the Iris dataset and evaluating its performance.</p>\n<p><span id='\"more-1008\"'></span></p>\n<h2>What we'll make</h2>\n<p>In this demo project we're going to take a know dataset (<a href="%5C%22https://en.wikipedia.org/wiki/Iris_flower_data_set%5C%22">iris flowers</a>) and interactively train an SVM classifier on it, adjusting the number of samples to see the effects on both training time, inference time and accuracy.</p>\n<h2>Definitions</h2>\n<pre><code class='\"language-c\"'>#ifdef ESP32\n#define min(a, b) (a) < (b) ? (a) : (b)\n#define max(a, b) (a) > (b) ? (a) : (b)\n#define abs(x) ((x) > 0 ? (x) : -(x))\n#endif\n\n#include <EloquentSVMSMO.h>\n#include "iris.h"\n\n#define TOTAL_SAMPLES (POSITIVE_SAMPLES + NEGATIVE_SAMPLES)\n\nfloat X_train[TOTAL_SAMPLES][FEATURES_DIM];\nfloat X_test[TOTAL_SAMPLES][FEATURES_DIM];\nint y_train[TOTAL_SAMPLES];\nint y_test[TOTAL_SAMPLES];\nEloquent::TinyML::SVMSMO<FEATURES_DIM> classifier(linearKernel);</code></pre>\n<p>First of all we need to include a couple files, namely <code>EloquentSVMSMO.h</code> for the SVM classifier and <code>iris.h</code> for the dataset.</p>\n<p><code>iris.h</code> defines a couple constants:</p>\n<ul>\n<li><code>FEATURES_DIM</code>: the number of features each sample has (4 in this case)</li>\n<li><code>POSITIVE_SAMPLES</code>: the number of samples that belong to the positive class (50)</li>\n<li><code>NEGATIVE_SAMPLES</code>: the number of samples that belong to the negative class (50)</li>\n</ul>\n<p>The we declare the array that hold the data: <code>X_train</code> and <code>y_train</code> for the training process, <code>X_test</code> and <code>y_test</code> for the inference process.</p>\n<h2>Setup</h2>\n<pre><code class='\"language-c\"'>void setup() {\n    Serial.begin(115200);\n    delay(5000);\n\n    // configure classifier\n    classifier.setC(5);\n    classifier.setTol(1e-5);\n    classifier.setMaxIter(10000);\n}</code></pre>\n<p>Here we just set a few parameters for the classifier. You could actually skip this step in this demo, since the defaults will work well. Those lines are there so you know you can tweak them, if needed.</p>\n<p>Please refer to the <a href="%5C%22/2020/03/how-to-train-a-color-classification-machine-learning-classifier-directly-on-your-arduino-board%5C%22">demo for color classification</a> for an explanation of each parameter.</p>\n<h2>Interactivity</h2>\n<pre><code class='\"language-c\"'>void loop() {\n    int positiveSamples = readSerialNumber("How many positive samples will you use for training? ", POSITIVE_SAMPLES);\n\n    if (positiveSamples > POSITIVE_SAMPLES - 1) {\n        Serial.println("Too many positive samples entered. All but one will be used instead");\n        positiveSamples = POSITIVE_SAMPLES - 1;\n    }\n\n    int negativeSamples = readSerialNumber("How many negative samples will you use for training? ", NEGATIVE_SAMPLES);\n\n    if (negativeSamples > NEGATIVE_SAMPLES - 1) {\n        Serial.println("Too many negative samples entered. All but one will be used instead");\n        negativeSamples = NEGATIVE_SAMPLES - 1;\n    }\n\n    loadDataset(positiveSamples, negativeSamples);\n\n    // ...\n}\n\n/**\n * Ask the user to enter a numeric value\n */\nint readSerialNumber(String prompt, int maxAllowed) {\n    Serial.print(prompt);\n    Serial.print(" (");\n    Serial.print(maxAllowed);\n    Serial.print(" max) ");\n\n    while (!Serial.available()) delay(1);\n\n    int n = Serial.readStringUntil('\\n').toInt();\n\n    Serial.println(n);\n\n    return n;\n}\n\n/**\n * Divide training and test data\n */\nvoid loadDataset(int positiveSamples, int negativeSamples) {\n    int positiveTestSamples = POSITIVE_SAMPLES - positiveSamples;\n\n    for (int i = 0; i < positiveSamples; i++) {\n        memcpy(X_train[i], X_positive[i], FEATURES_DIM);\n        y_train[i] = 1;\n    }\n\n    for (int i = 0; i < negativeSamples; i++) {\n        memcpy(X_train[i + positiveSamples], X_negative[i], FEATURES_DIM);\n        y_train[i + positiveSamples] = -1;\n    }\n\n    for (int i = 0; i < positiveTestSamples; i++) {\n        memcpy(X_test[i], X_positive[i + positiveSamples], FEATURES_DIM);\n        y_test[i] = 1;\n    }\n\n    for (int i = 0; i < NEGATIVE_SAMPLES - negativeSamples; i++) {\n        memcpy(X_test[i + positiveTestSamples], X_negative[i + negativeSamples], FEATURES_DIM);\n        y_test[i + positiveTestSamples] = -1;\n    }\n}</code></pre>\n<p>The code above is a preliminary step where you're asked to enter how many samples you will use for training of both positive and negative classes.</p>\n<p>This way you can have multiple run of benchmarking without the need to re-compile and re-upload the sketch.</p>\n<p>It also shows that the training process can be "dynamic", in the sense that you can tweak it at runtime as per your need.</p>\n<h2>Training</h2>\n<pre><code class='\"language-c\"'>time_t start = millis();\nclassifier.fit(X_train, y_train, positiveSamples + negativeSamples);\nSerial.print("It took ");\nSerial.print(millis() - start);\nSerial.print("ms to train on ");\nSerial.print(positiveSamples + negativeSamples);\nSerial.println(" samples");</code></pre>\n<p>Training is actually a one line operation. Here we'll also logging how much time it takes to train.</p>\n<h3>Predicting</h3>\n<pre><code class='\"language-c\"'>void loop() {\n    // ...\n\n    int tp = 0;\n    int tn = 0;\n    int fp = 0;\n    int fn = 0;\n\n    start = millis();\n\n    for (int i = 0; i < TOTAL_SAMPLES - positiveSamples - negativeSamples; i++) {\n        int y_pred = classifier.predict(X_train, X_test[i]);\n        int y_true = y_test[i];\n\n        if (y_pred == y_true && y_pred ==  1) tp += 1;\n        if (y_pred == y_true && y_pred == -1) tn += 1;\n        if (y_pred != y_true && y_pred ==  1) fp += 1;\n        if (y_pred != y_true && y_pred == -1) fn += 1;\n    }\n\n    Serial.print("It took ");\n    Serial.print(millis() - start);\n    Serial.print("ms to test on ");\n    Serial.print(TOTAL_SAMPLES - positiveSamples - negativeSamples);\n    Serial.println(" samples");\n\n    printConfusionMatrix(tp, tn, fp, fn);\n}\n\n/**\n * Dump confusion matrix to Serial monitor\n */\nvoid printConfusionMatrix(int tp, int tn, int fp, int fn) {\n    Serial.print("Overall accuracy ");\n    Serial.print(100.0 * (tp + tn) / (tp + tn + fp + fn));\n    Serial.println("%");\n    Serial.println("Confusion matrix");\n    Serial.print("          | Predicted 1 | Predicted -1 |\\n");\n    Serial.print("----------------------------------------\\n");\n    Serial.print("Actual  1 |      ");\n    Serial.print(tp);\n    Serial.print("     |      ");\n    Serial.print(fn);\n    Serial.print("       |\\n");\n    Serial.print("----------------------------------------\\n");\n    Serial.print("Actual -1 |      ");\n    Serial.print(fp);\n    Serial.print("      |      ");\n    Serial.print(tn);\n    Serial.print("       |\\n");\n    Serial.print("----------------------------------------\\n\\n\\n");\n}</code></pre>\n<p>Finally we can run the classification on our test set and get the overall accuracy.</p>\n<p>We also print the <a href="%5C%22https://en.wikipedia.org/wiki/Confusion_matrix%5C%22">confusion matrix</a> to double-check each class accuracy.</p>\n\r\n<div id='\"mc_embed_signup\"'>\r\n<form action="%5C%22https://github.us4.list-manage.com/subscribe/post?u=f0eaedd94d554cf2ee781742a&id=37d3496031%5C%22" method='\"post\"' id='\"mc-embedded-subscribe-form\"' name='\"mc-embedded-subscribe-form\"' class='\"validate\"' target='\"_blank\"' novalidate>\r\n    <div id='\"mc_embed_signup_scroll\"'>\r\n\t<h2 style='\"margin:' text-align: center>Finding this content useful?</h2>\r\n<div class='\"mc-field-group\"'>\r\n\t<input type='\"email\"' value='\"\"' name='\"EMAIL\"' class='\"required' email id='\"mce-EMAIL\"' placeholder='\"join' the monthly newsletter>\r\n</div>\r\n\t<div id='\"mce-responses\"' class='\"clear\"'>\r\n\t\t<div class='\"response\"' id='\"mce-error-response\"' style='\"display:none\"'></div>\r\n\t\t<div class='\"response\"' id='\"mce-success-response\"' style='\"display:none\"'></div>\r\n\t</div>    \r\n    <div style='\"position:' absolute left: aria-hidden='\"true\"'><input type='\"text\"' name='\"b_f0eaedd94d554cf2ee781742a_37d3496031\"' tabindex='\"-1\"' value='\"\"'></div>\r\n    <div class='\"clear\"' style='\"position:' relative top:><input type='\"submit\"' value='\"Subscribe\"' name='\"subscribe\"' id='\"mc-embedded-subscribe\"' class='\"button\"'></div>\r\n    </div>\r\n</form>\r\n</div>\r\n\r\n\n<hr>\n<p>Check the full project code on <a href="%5C%22https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/IrisClassificationTrainingExample/IrisClassificationTrainingExample.ino%5C%22">Github</a> where you'll also find another dataset to test, which is characterized by a number of features much higher (30 instead of 4).</p>\n<p>L'articolo <a rel='\"nofollow\"' href="%5C%22https://eloquentarduino.github.io/2020/03/how-to-train-a-iris-classification-machine-learning-classifier-directly-on-your-arduino-board/%5C%22">How to train a IRIS classification Machine learning classifier directly on your Arduino board</a> proviene da <a rel='\"nofollow\"' href="%5C%22https://eloquentarduino.github.io%5C%22">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this hands-on guide about on-board SVM training we're going to see a classifier in action, training it on the Iris dataset and evaluating its performance.\n\nWhat we'll make\nIn this demo project we're going to take a know dataset (iris flowers) and interactively train an SVM classifier on it, adjusting the number of samples to see the effects on both training time, inference time and accuracy.\nDefinitions\n#ifdef ESP32\n#define min(a, b) (a) < (b) ? (a) : (b)\n#define max(a, b) (a) > (b) ? (a) : (b)\n#define abs(x) ((x) > 0 ? (x) : -(x))\n#endif\n\n#include <EloquentSVMSMO.h>\n#include "iris.h"\n\n#define TOTAL_SAMPLES (POSITIVE_SAMPLES + NEGATIVE_SAMPLES)\n\nfloat X_train[TOTAL_SAMPLES][FEATURES_DIM];\nfloat X_test[TOTAL_SAMPLES][FEATURES_DIM];\nint y_train[TOTAL_SAMPLES];\nint y_test[TOTAL_SAMPLES];\nEloquent::TinyML::SVMSMO<FEATURES_DIM> classifier(linearKernel);\nFirst of all we need to include a couple files, namely EloquentSVMSMO.h for the SVM classifier and iris.h for the dataset.\niris.h defines a couple constants:\n\nFEATURES_DIM: the number of features each sample has (4 in this case)\nPOSITIVE_SAMPLES: the number of samples that belong to the positive class (50)\nNEGATIVE_SAMPLES: the number of samples that belong to the negative class (50)\n\nThe we declare the array that hold the data: X_train and y_train for the training process, X_test and y_test for the inference process.\nSetup\nvoid setup() {\n    Serial.begin(115200);\n    delay(5000);\n\n    // configure classifier\n    classifier.setC(5);\n    classifier.setTol(1e-5);\n    classifier.setMaxIter(10000);\n}\nHere we just set a few parameters for the classifier. You could actually skip this step in this demo, since the defaults will work well. Those lines are there so you know you can tweak them, if needed.\nPlease refer to the demo for color classification for an explanation of each parameter.\nInteractivity\nvoid loop() {\n    int positiveSamples = readSerialNumber("How many positive samples will you use for training? ", POSITIVE_SAMPLES);\n\n    if (positiveSamples > POSITIVE_SAMPLES - 1) {\n        Serial.println("Too many positive samples entered. All but one will be used instead");\n        positiveSamples = POSITIVE_SAMPLES - 1;\n    }\n\n    int negativeSamples = readSerialNumber("How many negative samples will you use for training? ", NEGATIVE_SAMPLES);\n\n    if (negativeSamples > NEGATIVE_SAMPLES - 1) {\n        Serial.println("Too many negative samples entered. All but one will be used instead");\n        negativeSamples = NEGATIVE_SAMPLES - 1;\n    }\n\n    loadDataset(positiveSamples, negativeSamples);\n\n    // ...\n}\n\n/**\n * Ask the user to enter a numeric value\n */\nint readSerialNumber(String prompt, int maxAllowed) {\n    Serial.print(prompt);\n    Serial.print(" (");\n    Serial.print(maxAllowed);\n    Serial.print(" max) ");\n\n    while (!Serial.available()) delay(1);\n\n    int n = Serial.readStringUntil('\\n').toInt();\n\n    Serial.println(n);\n\n    return n;\n}\n\n/**\n * Divide training and test data\n */\nvoid loadDataset(int positiveSamples, int negativeSamples) {\n    int positiveTestSamples = POSITIVE_SAMPLES - positiveSamples;\n\n    for (int i = 0; i < positiveSamples; i++) {\n        memcpy(X_train[i], X_positive[i], FEATURES_DIM);\n        y_train[i] = 1;\n    }\n\n    for (int i = 0; i < negativeSamples; i++) {\n        memcpy(X_train[i + positiveSamples], X_negative[i], FEATURES_DIM);\n        y_train[i + positiveSamples] = -1;\n    }\n\n    for (int i = 0; i < positiveTestSamples; i++) {\n        memcpy(X_test[i], X_positive[i + positiveSamples], FEATURES_DIM);\n        y_test[i] = 1;\n    }\n\n    for (int i = 0; i < NEGATIVE_SAMPLES - negativeSamples; i++) {\n        memcpy(X_test[i + positiveTestSamples], X_negative[i + negativeSamples], FEATURES_DIM);\n        y_test[i + positiveTestSamples] = -1;\n    }\n}\nThe code above is a preliminary step where you're asked to enter how many samples you will use for training of both positive and negative classes.\nThis way you can have multiple run of benchmarking without the need to re-compile and re-upload the sketch.\nIt also shows that the training process can be "dynamic", in the sense that you can tweak it at runtime as per your need.\nTraining\ntime_t start = millis();\nclassifier.fit(X_train, y_train, positiveSamples + negativeSamples);\nSerial.print("It took ");\nSerial.print(millis() - start);\nSerial.print("ms to train on ");\nSerial.print(positiveSamples + negativeSamples);\nSerial.println(" samples");\nTraining is actually a one line operation. Here we'll also logging how much time it takes to train.\nPredicting\nvoid loop() {\n    // ...\n\n    int tp = 0;\n    int tn = 0;\n    int fp = 0;\n    int fn = 0;\n\n    start = millis();\n\n    for (int i = 0; i < TOTAL_SAMPLES - positiveSamples - negativeSamples; i++) {\n        int y_pred = classifier.predict(X_train, X_test[i]);\n        int y_true = y_test[i];\n\n        if (y_pred == y_true && y_pred ==  1) tp += 1;\n        if (y_pred == y_true && y_pred == -1) tn += 1;\n        if (y_pred != y_true && y_pred ==  1) fp += 1;\n        if (y_pred != y_true && y_pred == -1) fn += 1;\n    }\n\n    Serial.print("It took ");\n    Serial.print(millis() - start);\n    Serial.print("ms to test on ");\n    Serial.print(TOTAL_SAMPLES - positiveSamples - negativeSamples);\n    Serial.println(" samples");\n\n    printConfusionMatrix(tp, tn, fp, fn);\n}\n\n/**\n * Dump confusion matrix to Serial monitor\n */\nvoid printConfusionMatrix(int tp, int tn, int fp, int fn) {\n    Serial.print("Overall accuracy ");\n    Serial.print(100.0 * (tp + tn) / (tp + tn + fp + fn));\n    Serial.println("%");\n    Serial.println("Confusion matrix");\n    Serial.print("          | Predicted 1 | Predicted -1 |\\n");\n    Serial.print("----------------------------------------\\n");\n    Serial.print("Actual  1 |      ");\n    Serial.print(tp);\n    Serial.print("     |      ");\n    Serial.print(fn);\n    Serial.print("       |\\n");\n    Serial.print("----------------------------------------\\n");\n    Serial.print("Actual -1 |      ");\n    Serial.print(fp);\n    Serial.print("      |      ");\n    Serial.print(tn);\n    Serial.print("       |\\n");\n    Serial.print("----------------------------------------\\n\\n\\n");\n}\nFinally we can run the classification on our test set and get the overall accuracy.\nWe also print the confusion matrix to double-check each class accuracy.\n\r\n\r\n\r\n    \r\n\tFinding this content useful?\r\n\r\n\t\r\n\r\n\t\r\n\t\t\r\n\t\t\r\n\t    \r\n    \r\n    \r\n    \r\n\r\n\r\n\r\n\n\nCheck the full project code on Github where you'll also find another dataset to test, which is characterized by a number of features much higher (30 instead of 4).\nL'articolo How to train a IRIS classification Machine learning classifier directly on your Arduino board proviene da Eloquent Arduino Blog.",
            "date_published": "2020-03-28T19:02:09+01:00",
            "date_modified": "2020-03-29T13:33:45+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "tags": [
                "microml",
                "svm",
                "Arduino Machine learning"
            ]
        }
    ]
}</body></html>
