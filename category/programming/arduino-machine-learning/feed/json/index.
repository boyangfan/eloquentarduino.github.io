{
    "version": "https://jsonfeed.org/version/1",
    "user_comment": "This feed allows you to read the posts from this site in any feed reader that supports the JSON Feed format. To add this feed to your reader, copy the following URL -- https://eloquentarduino.github.io/category/programming/arduino-machine-learning/feed/json/ -- and add it your reader.",
    "home_page_url": "https://eloquentarduino.github.io/category/programming/arduino-machine-learning/",
    "feed_url": "https://eloquentarduino.github.io/category/programming/arduino-machine-learning/feed/json/",
    "title": "Eloquent Arduino Blog",
    "description": "A blog about Arduino, programming &amp; electronics",
    "items": [
        {
            "id": "https://eloquentarduino.github.io/2019/12/word-classification-using-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/word-classification-using-arduino/",
            "title": "Word classification using Arduino and MicroML",
            "content_html": "<p>In this Arduno Machine learning tutorial we're going to use a microphone to identify the word you speak.<br />\nThis is going to run on an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.</p>\n<p><span id=\"more-180\"></span></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/WakeWord.jpg\" alt=\"from https://www.udemy.com/course/learn-audio-processing-complete-engineers-course/\" /></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: repeat each word a few times and save the values from the serial monitor to a file, one for each word</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<p>In this project the features are going to be the Fast Fourier Transform of 50 analog readings from a microphone, taken starting from when a loud sound is detected, sampled at intervals of 5 millis.</p>\n<h3>1. Features definition</h3>\n<p>The microphone we're going to use is a super simple device: it produces an analog signal (0-1024) based on the sound it detects. </p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/WakeWord-Sensor.jpg\" alt=\"from http://arduinolearning.com/code/ky038-microphone-module-and-arduino-example.php\" /></p>\n<p>When working with audio you almost always don't want to use raw readings, since they're hardly useful. Instead you often go with <a href=\"https://en.wikipedia.org/wiki/Fourier_transform\">Fourier Transform</a>, which extracts the frequency information from a time signal. That's going to become our features vector: let's see how in the next step.</p>\n<h3>2. Record sample data</h3>\n<p>First of all, we start with raw audio data. The following plot is me saying random words.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Raw-audio.gif\" alt=\"Raw audio stream\" /></p>\n<pre><code class=\"language-cpp\">#define MIC A0\n#define INTERVAL 5\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(MIC, INPUT);\n}\n\nvoid loop() {\n    Serial.println(analogRead(MIC));\n    delay(INTERVAL);\n}</code></pre>\n<h4>2.1 Translate the raw values</h4>\n<p>For the Fourier Transform to work, we need to provide as input an array of values both positive and negative. <code>analogRead()</code> is returning only positive values, tough, so we need to translate them.</p>\n<pre><code class=\"language-cpp\">int16_t readMic() {\n    // this translated the analog value to a proper interval\n    return  (analogRead(MIC) - 512) &gt;&gt; 2;\n}</code></pre>\n<h4>2.2 Detect sound</h4>\n<p>As in the <a href=\"/2019/12/how-to-do-gesture-identification-on-arduino/\">tutorial about gesture classification</a>, we'll start recording the features when a word is beginning to be pronounced. Also in this project we'll use a threshold to detect the start of a word.</p>\n<p>To do this, we first record a &quot;background&quot; sound level, that is the value produced by the sensor when we're not talking at all.</p>\n<pre><code class=\"language-cpp\">float backgroundSound = 0;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(MIC, INPUT);\n    calibrate();\n}\n\nvoid calibrate() {\n    for (int i = 0; i &lt; 200; i++)\n        backgroundSound += readMic();\n\n    backgroundSound /= 200;\n\n    Serial.print(&quot;Background sound level is &quot;);\n    Serial.println(backgroundSound);\n}</code></pre>\n<p>At this point we can check for the starting of a word when the detected sound level exceeds tha background one by a given threshold.</p>\n<pre><code class=\"language-cpp\">// adjust as per your need\n// it will depend on the sensitivity of you microphone\n#define SOUND_THRESHOLD 3\n\nvoid loop() {\n    if (!soundDetected()) {\n        delay(10);\n        return;\n    }\n}\n\nbool soundDetected() {\n    return abs(read() - backgroundSound) &gt;= SOUND_THRESHOLD;\n}</code></pre>\n<h4>2.3 Record the words</h4>\n<p>As for the gestures, we'll record a fixed number of readings at a fixed interval.<br />\nHere a tradeoff arises: you want to have a decent number of readings to be able to accurately describe the words you want to classify, but not too much otherwise your model is going to be too large to fit in your board.</p>\n<p>I made some experiments, and I got good results with 32 samples at 5 millis interval, which covers ~150 ms of speech.</p>\n<div class=\"watchout\">\nThe dilemma here is that the Fourier Transform to work needs a number of samples that is a power of 2. So, if you think 32 features are not enough for you, you're forced to go with at least 64: this has a REALLY bad impact on the model size.\n</div>\n<pre><code class=\"language-cpp\">#define NUM_SAMPLES 32\n#define INTERVAL 5\n\ndouble features[NUM_SAMPLES];\n\nvoid loop() {\n    if (!soundDetected()) {\n        delay(10);\n        return;\n    }\n\n    captureWord();\n    printFeatures();\n    delay(1000);\n}\n\nvoid captureWord() {\n    for (uint16_t i = 0; i &lt; NUM_SAMPLES; i++) {\n        features[i] = readMic();\n        delay(INTERVAL);\n    }\n}</code></pre>\n<pre><code class=\"language-cpp\">\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n</code></pre>\n<h4>2.4 Fast Fourier Transform</h4>\n<p>Here we are with the Fourier Transform. When implemented in software, the most widely implementation of the FT is actually called <a href=\"https://en.wikipedia.org/wiki/Fast_Fourier_transform\">Fast Fourier Transform (FFT)</a>, which is - as you may guess - a fast implementation of the FT. </p>\n<p>Luckily for us, there exists <a href=\"https://github.com/kosme/arduinoFFT\">a library</a> for Arduino that does FFT.</p>\n<p>And is so easy to use that we only need a line to get usable results!</p>\n<pre><code class=\"language-cpp\">#include &lt;arduinoFFT.h&gt;\n\narduinoFFT fft;\n\nvoid captureWord() {\n    for (uint16_t i = 0; i &lt; NUM_SAMPLES; i++) {\n        features[i] = readMic();\n        delay(INTERVAL);\n    }\n\n    fft.Windowing(features, NUM_SAMPLES, FFT_WIN_TYP_HAMMING, FFT_FORWARD);\n}</code></pre>\n<p>You don't need to know what the <code>Windowing</code> function actually does (I don't either): what matters is that it extracts meaningful informations from our signal. Since it overwrites the features array, after calling that line we have what we need to input to our classifier.</p>\n<p>At this point, record 10-15 samples for each word and save them to a file, one for each word.</p>\n<div class=\"watchout\">\nAfter you have recorded the samples for a word, I suggest you to manually check them. It is sufficient to look at the first 3 values: if one of them seems to be clearly out of range, I suggest you to delete it. You will lose some accuracy, but your model will be smaller.\n</div>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<p>In this project on Machine learning we're not achieving 100% accuracy easily.<br />\nAudio is quite noise, so you should experiment with a few params for the classifier and choose the ones that perform best. I'll showcase a few examples:</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Word-classification-linear-kernel-87-accuracy.svg\" alt=\"Decision boundaries of 2 PCA components of Word classification, linear kernel\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Word-classification-poly-3-kernel-91-accuracy.svg\" alt=\"Decision boundaries of 2 PCA components of Word classification, poly-3 kernel\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Word-classification-rbf-kernel-94-accuracy.svg\" alt=\"Decision boundaries of 2 PCA components of Word classification, rbf kernel\" /></p>\n<h4>Select a suitable model</h4>\n<p>Here's an overview table of the 3 tests I did.</p>\n<table>\n<thead>\n<tr>\n<th>Kernel</th>\n<th style=\"text-align: center;\">No. support vectors</th>\n<th style=\"text-align: center;\">Avg. accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Linear</td>\n<td style=\"text-align: center;\">22</td>\n<td style=\"text-align: center;\">87%</td>\n</tr>\n<tr>\n<td>Poly 3</td>\n<td style=\"text-align: center;\">29</td>\n<td style=\"text-align: center;\">91%</td>\n</tr>\n<tr>\n<td>RBF</td>\n<td style=\"text-align: center;\">36</td>\n<td style=\"text-align: center;\">94%</td>\n</tr>\n</tbody>\n</table>\n<p>Of course the one with the RBF kernel would be the most desiderable since it has a very high accuracy: 36 support vectors, tough, will produce a model too large to fit on an Arduino Nano.</p>\n<p>So you're forced to pick the one with the highest accuracy that fit on your board: in my case it was the Linear kernel one.</p>\n<h3>3. Run the inference</h3>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid loop() {\n    if (!soundDetected()) {\n        delay(10);\n        return;\n    }\n\n    captureWord();\n    Serial.print(&quot;You said &quot;);\n    Serial.println(classIdxToName(predict(features)));\n\n    delay(1000);\n}</code></pre>\n<p>And that's it: word classification through machine learning on your Arduino board! Say some word and see the classification result on the Serial monitor. </p>\n<p>Here's me testing the system (English is not my language, so forgive my bad pronounce). The video quality is very low, I know, but you get the point.</p>\n<div style=\"width: 640px;\" class=\"wp-video\"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->\n<video class=\"wp-video-shortcode\" id=\"video-180-1\" width=\"640\" height=\"352\" preload=\"metadata\" controls=\"controls\"><source type=\"video/mp4\" src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Word-classification.mp4?_=1\" /><a href=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Word-classification.mp4\">https://eloquentarduino.github.io/wp-content/uploads/2019/12/Word-classification.mp4</a></video></div>\n<div class=\"watchout\">\nAs you can hear from the video, you should be quite accurate when pronouncing the words. I have to admit there are cases where the system totally fails to classify correctly the words. Restarting helps most of the time, so I'm suspecting there could be some kind of leak that \"corrupts\" the inference procedure.\n</div>\n<p><br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlWakeWordIdentificationExample/MicromlWakeWordIdentificationExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/word-classification-using-arduino/\">Word classification using Arduino and MicroML</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this Arduno Machine learning tutorial we're going to use a microphone to identify the word you speak.\nThis is going to run on an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.\n\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: repeat each word a few times and save the values from the serial monitor to a file, one for each word\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\nIn this project the features are going to be the Fast Fourier Transform of 50 analog readings from a microphone, taken starting from when a loud sound is detected, sampled at intervals of 5 millis.\n1. Features definition\nThe microphone we're going to use is a super simple device: it produces an analog signal (0-1024) based on the sound it detects. \n\nWhen working with audio you almost always don't want to use raw readings, since they're hardly useful. Instead you often go with Fourier Transform, which extracts the frequency information from a time signal. That's going to become our features vector: let's see how in the next step.\n2. Record sample data\nFirst of all, we start with raw audio data. The following plot is me saying random words.\n\n#define MIC A0\n#define INTERVAL 5\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(MIC, INPUT);\n}\n\nvoid loop() {\n    Serial.println(analogRead(MIC));\n    delay(INTERVAL);\n}\n2.1 Translate the raw values\nFor the Fourier Transform to work, we need to provide as input an array of values both positive and negative. analogRead() is returning only positive values, tough, so we need to translate them.\nint16_t readMic() {\n    // this translated the analog value to a proper interval\n    return  (analogRead(MIC) - 512) &gt;&gt; 2;\n}\n2.2 Detect sound\nAs in the tutorial about gesture classification, we'll start recording the features when a word is beginning to be pronounced. Also in this project we'll use a threshold to detect the start of a word.\nTo do this, we first record a &quot;background&quot; sound level, that is the value produced by the sensor when we're not talking at all.\nfloat backgroundSound = 0;\n\nvoid setup() {\n    Serial.begin(115200);\n    pinMode(MIC, INPUT);\n    calibrate();\n}\n\nvoid calibrate() {\n    for (int i = 0; i &lt; 200; i++)\n        backgroundSound += readMic();\n\n    backgroundSound /= 200;\n\n    Serial.print(&quot;Background sound level is &quot;);\n    Serial.println(backgroundSound);\n}\nAt this point we can check for the starting of a word when the detected sound level exceeds tha background one by a given threshold.\n// adjust as per your need\n// it will depend on the sensitivity of you microphone\n#define SOUND_THRESHOLD 3\n\nvoid loop() {\n    if (!soundDetected()) {\n        delay(10);\n        return;\n    }\n}\n\nbool soundDetected() {\n    return abs(read() - backgroundSound) &gt;= SOUND_THRESHOLD;\n}\n2.3 Record the words\nAs for the gestures, we'll record a fixed number of readings at a fixed interval.\nHere a tradeoff arises: you want to have a decent number of readings to be able to accurately describe the words you want to classify, but not too much otherwise your model is going to be too large to fit in your board.\nI made some experiments, and I got good results with 32 samples at 5 millis interval, which covers ~150 ms of speech.\n\nThe dilemma here is that the Fourier Transform to work needs a number of samples that is a power of 2. So, if you think 32 features are not enough for you, you're forced to go with at least 64: this has a REALLY bad impact on the model size.\n\n#define NUM_SAMPLES 32\n#define INTERVAL 5\n\ndouble features[NUM_SAMPLES];\n\nvoid loop() {\n    if (!soundDetected()) {\n        delay(10);\n        return;\n    }\n\n    captureWord();\n    printFeatures();\n    delay(1000);\n}\n\nvoid captureWord() {\n    for (uint16_t i = 0; i &lt; NUM_SAMPLES; i++) {\n        features[i] = readMic();\n        delay(INTERVAL);\n    }\n}\n\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n\n2.4 Fast Fourier Transform\nHere we are with the Fourier Transform. When implemented in software, the most widely implementation of the FT is actually called Fast Fourier Transform (FFT), which is - as you may guess - a fast implementation of the FT. \nLuckily for us, there exists a library for Arduino that does FFT.\nAnd is so easy to use that we only need a line to get usable results!\n#include &lt;arduinoFFT.h&gt;\n\narduinoFFT fft;\n\nvoid captureWord() {\n    for (uint16_t i = 0; i &lt; NUM_SAMPLES; i++) {\n        features[i] = readMic();\n        delay(INTERVAL);\n    }\n\n    fft.Windowing(features, NUM_SAMPLES, FFT_WIN_TYP_HAMMING, FFT_FORWARD);\n}\nYou don't need to know what the Windowing function actually does (I don't either): what matters is that it extracts meaningful informations from our signal. Since it overwrites the features array, after calling that line we have what we need to input to our classifier.\nAt this point, record 10-15 samples for each word and save them to a file, one for each word.\n\nAfter you have recorded the samples for a word, I suggest you to manually check them. It is sufficient to look at the first 3 values: if one of them seems to be clearly out of range, I suggest you to delete it. You will lose some accuracy, but your model will be smaller.\n\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\nIn this project on Machine learning we're not achieving 100% accuracy easily.\nAudio is quite noise, so you should experiment with a few params for the classifier and choose the ones that perform best. I'll showcase a few examples:\n\n\n\nSelect a suitable model\nHere's an overview table of the 3 tests I did.\n\n\n\nKernel\nNo. support vectors\nAvg. accuracy\n\n\n\n\nLinear\n22\n87%\n\n\nPoly 3\n29\n91%\n\n\nRBF\n36\n94%\n\n\n\nOf course the one with the RBF kernel would be the most desiderable since it has a very high accuracy: 36 support vectors, tough, will produce a model too large to fit on an Arduino Nano.\nSo you're forced to pick the one with the highest accuracy that fit on your board: in my case it was the Linear kernel one.\n3. Run the inference\n#include &quot;model.h&quot;\n\nvoid loop() {\n    if (!soundDetected()) {\n        delay(10);\n        return;\n    }\n\n    captureWord();\n    Serial.print(&quot;You said &quot;);\n    Serial.println(classIdxToName(predict(features)));\n\n    delay(1000);\n}\nAnd that's it: word classification through machine learning on your Arduino board! Say some word and see the classification result on the Serial monitor. \nHere's me testing the system (English is not my language, so forgive my bad pronounce). The video quality is very low, I know, but you get the point.\n\nhttps://eloquentarduino.github.io/wp-content/uploads/2019/12/Word-classification.mp4\n\nAs you can hear from the video, you should be quite accurate when pronouncing the words. I have to admit there are cases where the system totally fails to classify correctly the words. Restarting helps most of the time, so I'm suspecting there could be some kind of leak that \"corrupts\" the inference procedure.\n\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo Word classification using Arduino and MicroML proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-22T19:12:59+01:00",
            "date_modified": "2019-12-22T19:20:24+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "Arduino Machine learning"
            ],
            "attachments": [
                [
                    {
                        "url": "https://eloquentarduino.github.io/wp-content/uploads/2019/12/Word-classification.mp4",
                        "mime_type": "video/mp4",
                        "size_in_bytes": 2055653
                    }
                ]
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/wifi-indoor-positioning-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/wifi-indoor-positioning-on-arduino/",
            "title": "Indoor positioning using Arduino and Machine Learning in 4 steps",
            "content_html": "<p>In this Arduno Machine learning project we're going to use the nearby WiFi access points to locate where we are. For this project to work you will need a Wifi equipped board, such as ESP8266 or ESP32.</p>\n<p><span id=\"more-224\"></span></p>\n<p>The task of detecting where you are when GPS or satellite localization is not an option is called <a href=\"https://en.wikipedia.org/wiki/Indoor_positioning_system\">indoor positioning</a>: it could be in a building, an airport, a parking garage. I opted for WiFi because it is widely available, but the same project could be re-purposed to use Bluetooth, if there are enough devices in your location.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/illustrations_ambient-wifi-site-survey2.jpg\" alt=\"Wifi indoor positioning @ ri-elaborated from https://www.accuware.com/blog/ambient-signals-plus-video-images/\" /></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: run a few scans for each location to be predicted and record the RSSI (signal strength) of each visible network</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h2>1. Features definition</h2>\n<p>The features for this project are going to be the RSSIs (Received signal strength indication) of the known WiFi networks. If a network is out of range, it will have an RSSI equal to 0.</p>\n<h3>2. Record sample data</h3>\n<h4>2.1 Enumerate the access points</h4>\n<p>First of all we need to enumerate all the networks we will encounter during the inference process. This is because not all networks will be visible all the time:  we have to work, however, with a fixed number of features.</p>\n<p>To begin, we take a &quot;reconnaissance tour&quot; of the locations we want to predict and log all the networks we detect. Load the following sketch and take note of all the networks that appear on the Serial monitor.</p>\n<pre><code class=\"language-cpp\">#include &lt;WiFi.h&gt;\n\nvoid setup() {\n    Serial.begin(115200);\n    WiFi.mode(WIFI_STA);\n    WiFi.disconnect();\n}\n\nvoid loop() {\n  int numNetworks = WiFi.scanNetworks();\n\n  for (int i = 0; i &lt; numNetworks; i++) {\n      Serial.println(WiFi.SSID(i));\n\n  delay(3000);\n}</code></pre>\n<h4>2.2 Create an access point array</h4>\n<p>Now that we have a bunch of SSIDs, we need to assign each SSID to a fixed index, from 0 to <code>MAX_NETWORKS</code>.</p>\n<p>You can implement this part as you like, but in this demo I'll make use of a class I wrote called <code>Array</code> (you can see the <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/src/data_structures/Array.h\">source code</a> and <a href=\"https://github.com/agrimagsrl/eloquentarduino/blob/master/examples/ArrayExample/ArrayExample.ino\">example</a> on Github), which implements 2 useful functions: </p>\n<ol>\n<li><code>push()</code> to add an element to the array</li>\n<li><code>indexOf()</code> to get the index of an element.</li>\n</ol>\n<p>See <a href=\"/2019/12/how-to-install-the-eloquent-library/\">how to install the Eloquent library</a> if you don't have it already installed.<br />\nAt this point we populate the array with all the networks we saved from the reconnaissance tour.</p>\n<pre><code class=\"language-cpp\">#include &lt;eDataStructures.h&gt;\n\n#define MAX_NETWORKS 10\n\nusing namespace Eloquent::DataStructures;\n\ndouble features[MAX_NETWORKS];\nArray&lt;String, MAX_NETWORKS&gt; knownNetworks(&quot;&quot;);\n\nvoid setup() {\n    Serial.begin(115200);\n    WiFi.mode(WIFI_STA);\n    WiFi.disconnect();\n\n    knownNetworks.push(&quot;Put your SSID #0&quot;);\n    knownNetworks.push(&quot;Put your SSID #1&quot;);\n    knownNetworks.push(&quot;Put your SSID #2&quot;);\n    knownNetworks.push(&quot;Put your SSID #3&quot;);\n    // and so on\n}</code></pre>\n<h4>2.3 Convert to features vector</h4>\n<p>The second step is to convert the scan results into a features vector. Each feature will be the RSSI of the given SSID, in the exact order we populated the <code>knownNetworks</code> array.</p>\n<p>In practice:</p>\n<pre><code class=\"language-cpp\">features[0] == RSSI of &quot;Put your SSID #0&quot;;\nfeatures[1] == RSSI of &quot;Put your SSID #1&quot;;\nfeatures[2] == RSSI of &quot;Put your SSID #2&quot;;\nfeatures[3] == RSSI of &quot;Put your SSID #3&quot;;\n// and so on</code></pre>\n<p>The code below will do the job.</p>\n<pre><code class=\"language-cpp\">void loop() {\n    scan();\n    printFeatures();\n    delay(3000);\n}\n\nvoid scan() {\n    int numNetworks = WiFi.scanNetworks();\n\n    resetFeatures();\n\n    // assign RSSIs to feature vector\n    for (int i = 0; i &lt; numNetworks; i++) {\n        String ssid = WiFi.SSID(i);\n        uint16_t networkIndex = knownNetworks.indexOf(ssid);\n\n        // only create feature if the current SSID is a known one\n        if (!isnan(networkIndex))\n            features[networkIndex] = WiFi.RSSI(i);\n    }\n}\n\n// reset all features to 0\nvoid resetFeatures() {\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\n\n    for (int i = 0; i &lt; numFeatues; i++)\n        features[i] = 0;\n}</code></pre>\n<pre><code class=\"language-cpp\">\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n</code></pre>\n<p>Grab some recordings just staying in a location for a few seconds and save the serial output to a file; then move to the next location and repeat: 10-15 samples for each location will suffice.</p>\n<p>If you do a good job, you should end with distinguible features, as show in the plot below.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-from-Wifi-indoor-positioning-features.svg\" alt=\"Decision boundaries of 2 PCA components from Wifi indoor positioning features\" /></p>\n<div class=\"watchout\">\nRSSIs may be a little noisy, mostly on the boundaries where weak networks may appear and disappear with a very low RSSI: this was not a problem for me, but if you're getting bad results you may filter out those low values.</p>\n<pre><code class=\"language-cpp\">\n// replace\nfeatures[networkIndex] = WiFi.RSSI(i);\n\n// with\n#define MIN_RSSI -90 // adjust to your needs\n\nfeatures[networkIndex] = WiFi.RSSI(i) > MIN_RSSI ? WiFi.RSSI(i) : 0;\n</code></pre>\n</div>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<h3>4. Run the inference</h3>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid loop() {\n    scan();\n    classify();\n    delay(3000);\n}\n\nvoid classify() {\n    Serial.print(&quot;You are in &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}</code></pre>\n<p>Move around your house/office/whatever and see your location printed on the serial monitor!</p>\n<p><br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlWifiIndoorPositioningExample/MicromlWifiIndoorPositioningExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/wifi-indoor-positioning-on-arduino/\">Indoor positioning using Arduino and Machine Learning in 4 steps</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this Arduno Machine learning project we're going to use the nearby WiFi access points to locate where we are. For this project to work you will need a Wifi equipped board, such as ESP8266 or ESP32.\n\nThe task of detecting where you are when GPS or satellite localization is not an option is called indoor positioning: it could be in a building, an airport, a parking garage. I opted for WiFi because it is widely available, but the same project could be re-purposed to use Bluetooth, if there are enough devices in your location.\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: run a few scans for each location to be predicted and record the RSSI (signal strength) of each visible network\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nThe features for this project are going to be the RSSIs (Received signal strength indication) of the known WiFi networks. If a network is out of range, it will have an RSSI equal to 0.\n2. Record sample data\n2.1 Enumerate the access points\nFirst of all we need to enumerate all the networks we will encounter during the inference process. This is because not all networks will be visible all the time:  we have to work, however, with a fixed number of features.\nTo begin, we take a &quot;reconnaissance tour&quot; of the locations we want to predict and log all the networks we detect. Load the following sketch and take note of all the networks that appear on the Serial monitor.\n#include &lt;WiFi.h&gt;\n\nvoid setup() {\n    Serial.begin(115200);\n    WiFi.mode(WIFI_STA);\n    WiFi.disconnect();\n}\n\nvoid loop() {\n  int numNetworks = WiFi.scanNetworks();\n\n  for (int i = 0; i &lt; numNetworks; i++) {\n      Serial.println(WiFi.SSID(i));\n\n  delay(3000);\n}\n2.2 Create an access point array\nNow that we have a bunch of SSIDs, we need to assign each SSID to a fixed index, from 0 to MAX_NETWORKS.\nYou can implement this part as you like, but in this demo I'll make use of a class I wrote called Array (you can see the source code and example on Github), which implements 2 useful functions: \n\npush() to add an element to the array\nindexOf() to get the index of an element.\n\nSee how to install the Eloquent library if you don't have it already installed.\nAt this point we populate the array with all the networks we saved from the reconnaissance tour.\n#include &lt;eDataStructures.h&gt;\n\n#define MAX_NETWORKS 10\n\nusing namespace Eloquent::DataStructures;\n\ndouble features[MAX_NETWORKS];\nArray&lt;String, MAX_NETWORKS&gt; knownNetworks(&quot;&quot;);\n\nvoid setup() {\n    Serial.begin(115200);\n    WiFi.mode(WIFI_STA);\n    WiFi.disconnect();\n\n    knownNetworks.push(&quot;Put your SSID #0&quot;);\n    knownNetworks.push(&quot;Put your SSID #1&quot;);\n    knownNetworks.push(&quot;Put your SSID #2&quot;);\n    knownNetworks.push(&quot;Put your SSID #3&quot;);\n    // and so on\n}\n2.3 Convert to features vector\nThe second step is to convert the scan results into a features vector. Each feature will be the RSSI of the given SSID, in the exact order we populated the knownNetworks array.\nIn practice:\nfeatures[0] == RSSI of &quot;Put your SSID #0&quot;;\nfeatures[1] == RSSI of &quot;Put your SSID #1&quot;;\nfeatures[2] == RSSI of &quot;Put your SSID #2&quot;;\nfeatures[3] == RSSI of &quot;Put your SSID #3&quot;;\n// and so on\nThe code below will do the job.\nvoid loop() {\n    scan();\n    printFeatures();\n    delay(3000);\n}\n\nvoid scan() {\n    int numNetworks = WiFi.scanNetworks();\n\n    resetFeatures();\n\n    // assign RSSIs to feature vector\n    for (int i = 0; i &lt; numNetworks; i++) {\n        String ssid = WiFi.SSID(i);\n        uint16_t networkIndex = knownNetworks.indexOf(ssid);\n\n        // only create feature if the current SSID is a known one\n        if (!isnan(networkIndex))\n            features[networkIndex] = WiFi.RSSI(i);\n    }\n}\n\n// reset all features to 0\nvoid resetFeatures() {\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\n\n    for (int i = 0; i &lt; numFeatues; i++)\n        features[i] = 0;\n}\n\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n\nGrab some recordings just staying in a location for a few seconds and save the serial output to a file; then move to the next location and repeat: 10-15 samples for each location will suffice.\nIf you do a good job, you should end with distinguible features, as show in the plot below.\n\n\nRSSIs may be a little noisy, mostly on the boundaries where weak networks may appear and disappear with a very low RSSI: this was not a problem for me, but if you're getting bad results you may filter out those low values.\n\n// replace\nfeatures[networkIndex] = WiFi.RSSI(i);\n\n// with\n#define MIN_RSSI -90 // adjust to your needs\n\nfeatures[networkIndex] = WiFi.RSSI(i) > MIN_RSSI ? WiFi.RSSI(i) : 0;\n\n\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\n4. Run the inference\n#include &quot;model.h&quot;\n\nvoid loop() {\n    scan();\n    classify();\n    delay(3000);\n}\n\nvoid classify() {\n    Serial.print(&quot;You are in &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}\nMove around your house/office/whatever and see your location printed on the serial monitor!\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo Indoor positioning using Arduino and Machine Learning in 4 steps proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-20T18:31:16+01:00",
            "date_modified": "2019-12-21T16:35:27+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-do-gesture-identification-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-do-gesture-identification-on-arduino/",
            "title": "How to do Gesture identification through machine learning on Arduino",
            "content_html": "<p>In this Arduno Machine learning project we're going to use an accelerometer sensor to identify the gestures you play.<br />\nThis is a remake of the project found on the <a href=\"https://blog.tensorflow.org/2019/11/how-to-get-started-with-machine.html\">Tensorflow blog</a>. We're going to use a lot less powerful chip in this tutorial, tough: an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.</p>\n<p><span id=\"more-35\"></span></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: repeat each gesture a few times and save the values from the serial monitor to a file, one for each gesture</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h2>1. Features definition</h2>\n<p>We're going to use the accelerations along the 3 axis (X, Y, Z) coming from an <a href=\"https://en.wikipedia.org/wiki/Inertial_measurement_unit\">IMU</a> to infer which gesture we're playing. We'll use a fixed number of recordings (<code>NUM_SAMPLES</code>) starting from the first detection of movement. </p>\n<p>This means our feature vectors are going to be of dimension <code>3 * NUM_SAMPLES</code>, which can become too large to fit in the memory of the Arduino Nano. We'll start with a low value for <code>NUM_SAMPLES</code> to keep it as leaner as possible: if your classifications suffer from poor accuracy, you can increase this number.</p>\n<h3>2. Record sample data</h3>\n<h4>2.1 Read the IMU sensor</h4>\n<p>First of all, we need to read the raw data from the IMU. This piece of code will be different based on the specific chip you use. To keep things consistent, we'll wrap the IMU logic in 2 functions: <code>imu_setup</code> and <code>imu_read</code>. </p>\n<p>I'll report a couple of example implementations for the <code>MPU6050</code> and the <code>MPU9250</code> (these are the chip I have at hand). You should save whichever code you use in a file called <code>imu.h</code>. </p>\n<pre><code class=\"language-cpp\">#include &quot;Wire.h&quot;\n// library from https://github.com/jrowberg/i2cdevlib/tree/master/Arduino/MPU6050\n#include &quot;MPU6050.h&quot;\n#define OUTPUT_READABLE_ACCELGYRO\n\nMPU6050 imu;\n\nvoid imu_setup() {\n    Wire.begin();\n    imu.initialize();\n}\n\nvoid imu_read(float *ax, float *ay, float *az) {\n    float gx, gy, gz;\n\n    imu.getMotion6(&amp;ax, &amp;ay, &amp;az, &amp;gx, &amp;gy, &amp;gz);\n}</code></pre>\n<pre><code class=\"language-cpp\">#include &quot;Wire.h&quot;\n// library from https://github.com/bolderflight/MPU9250\n#include &quot;MPU9250.h&quot;\n\nMPU9250 imu(Wire, 0x68);\n\nvoid imu_setup() {\n    Wire.begin();\n    imu.begin();\n}\n\nvoid imu_read(float *ax, float *ay, float *az) {\n    imu.readSensor();\n\n    *ax = imu.getAccelX_mss();\n    *ay = imu.getAccelY_mss();\n    *az = imu.getAccelZ_mss();\n}</code></pre>\n<p>In the main .ino file, we dump the values to Serial monitor / plotter.</p>\n<pre><code class=\"language-cpp\">#include &quot;imu.h&quot;\n\n#define NUM_SAMPLES 30\n#define NUM_AXES 3\n// sometimes you may get &quot;spikes&quot; in the readings\n// set a sensible value to truncate too large values\n#define TRUNCATE_AT 20\n\ndouble features[NUM_SAMPLES * NUM_AXES];\n\nvoid setup() {\n    Serial.begin(115200);\n    imu_setup();\n}\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax, -TRUNCATE_AT, TRUNCATE_AT);\n    ay = constrain(ay, -TRUNCATE_AT, TRUNCATE_AT);\n    az = constrain(az, -TRUNCATE_AT, TRUNCATE_AT);\n\n    Serial.print(ax);\n    Serial.print(&#039;\\t&#039;);\n    Serial.print(ay);\n    Serial.print(&#039;\\t&#039;);\n    Serial.println(az);\n}</code></pre>\n<p>Open the Serial plotter and make some movement to have an idea of the range of your readings.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Raw-gestures.gif&quot;\" alt=\"Raw IMU readings for the gestures identification project\" /></p>\n<h4>2.2 Calibration</h4>\n<p>Don't know if it's just my case, but I'm getting <code>az</code> values of about -10 at rest (you can see this in the previous image). Since I'd like to have almost 0 at rest, I created a super simple calibration procedure to remove this fixed offset from the readings.</p>\n<p>If you're already getting all zeros, you can skip this part. Still, if you add it to your project it won't hurt.</p>\n<pre><code class=\"language-cpp\">double baseline[NUM_AXES];\ndouble features[NUM_SAMPLES * NUM_AXES];\n\nvoid setup() {\n    Serial.begin(115200);\n    imu_setup();\n    calibrate();\n}\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n}\n\nvoid calibrate() {\n    float ax, ay, az;\n\n    for (int i = 0; i &lt; 10; i++) {\n        imu_read(&amp;ax, &amp;ay, &amp;az);\n        delay(100);\n    }\n\n    baseline[0] = ax;\n    baseline[1] = ay;\n    baseline[2] = az;\n}</code></pre>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Calibrated-gestures.gif\" alt=\"Calibrated IMU readings for the gestures identification project\" /></p>\n<p>Much better.</p>\n<h4>2.3 Detect first motion</h4>\n<p>Now we need to check if motion is happening. To keep it simple, we'll use a naive approach that will look for an high value in the acceleration: if a threshold is exceeded, a gesture is starting. </p>\n<p>If you did the calibration step, a threshold of 5 should work well. If you didn't calibrate, you have to come up with a value that suits your needs.</p>\n<pre><code class=\"language-cpp\">#include imu.h\n\n#define ACCEL_THRESHOLD 5\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n}\n\nbool motionDetected(float ax, float ay, float az) {\n    return (abs(ax) + abs(ay) + abs(az)) &gt; ACCEL_THRESHOLD;\n}</code></pre>\n<h4>2.4 Record features</h4>\n<p>If no motion is happening, we don't take any action and keep watching. If motion is happening, we print the next <code>NUM_SAMPLES</code> readings to Serial. </p>\n<pre><code class=\"language-cpp\">void loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n\n    recordIMU();\n    printFeatures();\n    delay(2000);\n}\n\nvoid recordIMU() {\n    float ax, ay, az;\n\n    for (int i = 0; i &lt; NUM_SAMPLES; i++) {\n        imu_read(&amp;ax, &amp;ay, &amp;az);\n\n        ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n        ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n        az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n        features[i * NUM_AXES + 0] = ax;\n        features[i * NUM_AXES + 1] = ay;\n        features[i * NUM_AXES + 2] = az;\n\n        delay(INTERVAL);\n    }\n}</code></pre>\n<pre><code class=\"language-cpp\">\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n</code></pre>\n<p>Record 15-20 samples for each geasture and save them to a file, one for each gesture. Since we're dealing with highly dimensional data, you should collect as much samples as possible, to average out the noise.</p>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<p>In this project on Machine learning, differently from the previous and simpler ones, we're not achieving 100% accuracy easily. Motion is quite noise, so you should experiment with a few params for the classifier and choose the ones that perform best. I'll showcase a few examples:</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Gestures-features-Linear-kernel.svg\" alt=\"Decision boundaries of 2 PCA components of Gestures features, Linear kernel, 95% accuracy\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Gestures-features-Polynomial-kernel.svg\" alt=\"Decision boundaries of 2 PCA components of Gestures features, Polynomial kernel, 97% accuracy\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Gestures-features-RBF-kernel-0.01-gamma.svg\" alt=\"Decision boundaries of 2 PCA components of Gestures features, RBF kernel, 0.01 gamma, 95% accuracy\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Gestures-features-RBF-kernel-0.001-gamma.svg\" alt=\"Decision boundaries of 2 PCA components of Gestures features, RBF kernel, 0.001 gamma, 99% accuracy\" /></p>\n<h4>Select a suitable model</h4>\n<p>Now that we selected the best model, we have to export it to C code. Here comes the culprit: not all models will fit on your board.</p>\n<p>The core of SVM (Support Vector Machines) are support vectors: each trained classifier will be characterized by a certain number of them. The problem is: if there're too much, the generated code will be too large to fit in your flash.</p>\n<p>For this reason, instead of selecting <em>the best</em> model on accuracy, you should make a ranking, from the best performing to the worst. For each model, starting from the top, you should import it in your Arduino project and try to compile: if it fits, fine, you're done. Otherwise you should pick the next and try again.</p>\n<p>It may seem a tedious process, but keep in mind that we're trying to infer a class from 90 features in 2 Kb of RAM and 32 Kb of flash: I think this is an acceptable tradeoff.</p>\n<hr /><p><em>We&#039;re fitting a model to infer a class from 90 features in 2 Kb of RAM and 32 Kb of flash!</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F12%2Fhow-to-do-gesture-identification-on-arduino%2F&#038;text=We%27re%20fitting%20a%20model%20to%20infer%20a%20class%20from%2090%20features%20in%202%20Kb%20of%20RAM%20and%2032%20Kb%20of%20flash%21&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>I'll report a few figures for different combinations I tested.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">Kernel</th>\n<th style=\"text-align: center;\">C</th>\n<th style=\"text-align: center;\">Gamma</th>\n<th style=\"text-align: center;\">Degree</th>\n<th style=\"text-align: center;\">Vectors</th>\n<th style=\"text-align: center;\">Flash size</th>\n<th style=\"text-align: center;\">RAM (b)</th>\n<th style=\"text-align: center;\">Avg accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">RBF</td>\n<td style=\"text-align: center;\">10</td>\n<td style=\"text-align: center;\">0.001</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">37</td>\n<td style=\"text-align: center;\">53 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>Poly</strong></td>\n<td style=\"text-align: center;\"><strong>100</strong></td>\n<td style=\"text-align: center;\"><strong>0.001</strong></td>\n<td style=\"text-align: center;\"><strong>2</strong></td>\n<td style=\"text-align: center;\"><strong>12</strong></td>\n<td style=\"text-align: center;\"><strong>25 Kb</strong></td>\n<td style=\"text-align: center;\"><strong>1228</strong></td>\n<td style=\"text-align: center;\"><strong>99%</strong></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Poly</td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: center;\">0.001</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">25</td>\n<td style=\"text-align: center;\">40 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">97%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Linear</td>\n<td style=\"text-align: center;\">50</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">1</td>\n<td style=\"text-align: center;\">40</td>\n<td style=\"text-align: center;\">55 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">95%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">RBF</td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: center;\">0.01</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">61</td>\n<td style=\"text-align: center;\">80 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">95%</td>\n</tr>\n</tbody>\n</table>\n<p>As you can see, we achieved a very high accuracy on the test set for all the classifiers: only one, though, fitted on the Arduino Nano. Of course, if you use a larger board, you can deploy the others too.</p>\n<div class=\"infobox\">As a side note, take a look at the <code>RAM</code> column: all the values are equal: this is because in the implementation is independant from the number of support vectors and only depends on the number of features.</div>\n<h3>3. Run the inference</h3>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n\n    recordIMU();\n    classify();\n    delay(2000);\n}\n\nvoid classify() {\n    Serial.print(&quot;Detected gesture: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}</code></pre>\n<p>Here we are: it has been a long post, but now you can classify gestures with an Arduino Nano and 2 Kb of RAM. </p>\n<hr /><p><em>No fancy Neural Networks, no Tensorflow, no 32-bit ARM processors: plain old SVM on plain old 8 bits with 97% accuracy.</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F12%2Fhow-to-do-gesture-identification-on-arduino%2F&#038;text=No%20fancy%20Neural%20Networks%2C%20no%20Tensorflow%2C%20no%2032-bit%20ARM%20processors%3A%20plain%20old%20SVM%20on%20plain%20old%208%20bits%20with%2097%25%20accuracy.&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>Here's a short demo of me playing 3 gestures and getting the results on the serial monitor.</p>\n<div style=\"width: 640px;\" class=\"wp-video\"><video class=\"wp-video-shortcode\" id=\"video-35-2\" width=\"640\" height=\"360\" preload=\"metadata\" controls=\"controls\"><source type=\"video/mp4\" src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4?_=2\" /><a href=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4\">https://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4</a></video></div>\n<p><h4>Project figures</h4>\r\n<p>On my machine, the sketch targeted at the Arduino Nano (old generation) requires 25310 bytes (82%) of program space and 1228 bytes (59%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question <em>Can I run machine learning on Arduino?</em> is <strong>definetly YES</strong>.<br />\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlGestureIdentificationExample/MicromlGestureIdentificationExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-do-gesture-identification-on-arduino/\">How to do Gesture identification through machine learning on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this Arduno Machine learning project we're going to use an accelerometer sensor to identify the gestures you play.\nThis is a remake of the project found on the Tensorflow blog. We're going to use a lot less powerful chip in this tutorial, tough: an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: repeat each gesture a few times and save the values from the serial monitor to a file, one for each gesture\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nWe're going to use the accelerations along the 3 axis (X, Y, Z) coming from an IMU to infer which gesture we're playing. We'll use a fixed number of recordings (NUM_SAMPLES) starting from the first detection of movement. \nThis means our feature vectors are going to be of dimension 3 * NUM_SAMPLES, which can become too large to fit in the memory of the Arduino Nano. We'll start with a low value for NUM_SAMPLES to keep it as leaner as possible: if your classifications suffer from poor accuracy, you can increase this number.\n2. Record sample data\n2.1 Read the IMU sensor\nFirst of all, we need to read the raw data from the IMU. This piece of code will be different based on the specific chip you use. To keep things consistent, we'll wrap the IMU logic in 2 functions: imu_setup and imu_read. \nI'll report a couple of example implementations for the MPU6050 and the MPU9250 (these are the chip I have at hand). You should save whichever code you use in a file called imu.h. \n#include &quot;Wire.h&quot;\n// library from https://github.com/jrowberg/i2cdevlib/tree/master/Arduino/MPU6050\n#include &quot;MPU6050.h&quot;\n#define OUTPUT_READABLE_ACCELGYRO\n\nMPU6050 imu;\n\nvoid imu_setup() {\n    Wire.begin();\n    imu.initialize();\n}\n\nvoid imu_read(float *ax, float *ay, float *az) {\n    float gx, gy, gz;\n\n    imu.getMotion6(&amp;ax, &amp;ay, &amp;az, &amp;gx, &amp;gy, &amp;gz);\n}\n#include &quot;Wire.h&quot;\n// library from https://github.com/bolderflight/MPU9250\n#include &quot;MPU9250.h&quot;\n\nMPU9250 imu(Wire, 0x68);\n\nvoid imu_setup() {\n    Wire.begin();\n    imu.begin();\n}\n\nvoid imu_read(float *ax, float *ay, float *az) {\n    imu.readSensor();\n\n    *ax = imu.getAccelX_mss();\n    *ay = imu.getAccelY_mss();\n    *az = imu.getAccelZ_mss();\n}\nIn the main .ino file, we dump the values to Serial monitor / plotter.\n#include &quot;imu.h&quot;\n\n#define NUM_SAMPLES 30\n#define NUM_AXES 3\n// sometimes you may get &quot;spikes&quot; in the readings\n// set a sensible value to truncate too large values\n#define TRUNCATE_AT 20\n\ndouble features[NUM_SAMPLES * NUM_AXES];\n\nvoid setup() {\n    Serial.begin(115200);\n    imu_setup();\n}\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax, -TRUNCATE_AT, TRUNCATE_AT);\n    ay = constrain(ay, -TRUNCATE_AT, TRUNCATE_AT);\n    az = constrain(az, -TRUNCATE_AT, TRUNCATE_AT);\n\n    Serial.print(ax);\n    Serial.print(&#039;\\t&#039;);\n    Serial.print(ay);\n    Serial.print(&#039;\\t&#039;);\n    Serial.println(az);\n}\nOpen the Serial plotter and make some movement to have an idea of the range of your readings.\n\n2.2 Calibration\nDon't know if it's just my case, but I'm getting az values of about -10 at rest (you can see this in the previous image). Since I'd like to have almost 0 at rest, I created a super simple calibration procedure to remove this fixed offset from the readings.\nIf you're already getting all zeros, you can skip this part. Still, if you add it to your project it won't hurt.\ndouble baseline[NUM_AXES];\ndouble features[NUM_SAMPLES * NUM_AXES];\n\nvoid setup() {\n    Serial.begin(115200);\n    imu_setup();\n    calibrate();\n}\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n}\n\nvoid calibrate() {\n    float ax, ay, az;\n\n    for (int i = 0; i &lt; 10; i++) {\n        imu_read(&amp;ax, &amp;ay, &amp;az);\n        delay(100);\n    }\n\n    baseline[0] = ax;\n    baseline[1] = ay;\n    baseline[2] = az;\n}\n\nMuch better.\n2.3 Detect first motion\nNow we need to check if motion is happening. To keep it simple, we'll use a naive approach that will look for an high value in the acceleration: if a threshold is exceeded, a gesture is starting. \nIf you did the calibration step, a threshold of 5 should work well. If you didn't calibrate, you have to come up with a value that suits your needs.\n#include imu.h\n\n#define ACCEL_THRESHOLD 5\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n}\n\nbool motionDetected(float ax, float ay, float az) {\n    return (abs(ax) + abs(ay) + abs(az)) &gt; ACCEL_THRESHOLD;\n}\n2.4 Record features\nIf no motion is happening, we don't take any action and keep watching. If motion is happening, we print the next NUM_SAMPLES readings to Serial. \nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n\n    recordIMU();\n    printFeatures();\n    delay(2000);\n}\n\nvoid recordIMU() {\n    float ax, ay, az;\n\n    for (int i = 0; i &lt; NUM_SAMPLES; i++) {\n        imu_read(&amp;ax, &amp;ay, &amp;az);\n\n        ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n        ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n        az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n        features[i * NUM_AXES + 0] = ax;\n        features[i * NUM_AXES + 1] = ay;\n        features[i * NUM_AXES + 2] = az;\n\n        delay(INTERVAL);\n    }\n}\n\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n\nRecord 15-20 samples for each geasture and save them to a file, one for each gesture. Since we're dealing with highly dimensional data, you should collect as much samples as possible, to average out the noise.\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\nIn this project on Machine learning, differently from the previous and simpler ones, we're not achieving 100% accuracy easily. Motion is quite noise, so you should experiment with a few params for the classifier and choose the ones that perform best. I'll showcase a few examples:\n\n\n\n\nSelect a suitable model\nNow that we selected the best model, we have to export it to C code. Here comes the culprit: not all models will fit on your board.\nThe core of SVM (Support Vector Machines) are support vectors: each trained classifier will be characterized by a certain number of them. The problem is: if there're too much, the generated code will be too large to fit in your flash.\nFor this reason, instead of selecting the best model on accuracy, you should make a ranking, from the best performing to the worst. For each model, starting from the top, you should import it in your Arduino project and try to compile: if it fits, fine, you're done. Otherwise you should pick the next and try again.\nIt may seem a tedious process, but keep in mind that we're trying to infer a class from 90 features in 2 Kb of RAM and 32 Kb of flash: I think this is an acceptable tradeoff.\nWe&#039;re fitting a model to infer a class from 90 features in 2 Kb of RAM and 32 Kb of flash!Click To Tweet\nI'll report a few figures for different combinations I tested.\n\n\n\nKernel\nC\nGamma\nDegree\nVectors\nFlash size\nRAM (b)\nAvg accuracy\n\n\n\n\nRBF\n10\n0.001\n-\n37\n53 Kb\n1228\n99%\n\n\nPoly\n100\n0.001\n2\n12\n25 Kb\n1228\n99%\n\n\nPoly\n100\n0.001\n3\n25\n40 Kb\n1228\n97%\n\n\nLinear\n50\n-\n1\n40\n55 Kb\n1228\n95%\n\n\nRBF\n100\n0.01\n-\n61\n80 Kb\n1228\n95%\n\n\n\nAs you can see, we achieved a very high accuracy on the test set for all the classifiers: only one, though, fitted on the Arduino Nano. Of course, if you use a larger board, you can deploy the others too.\nAs a side note, take a look at the RAM column: all the values are equal: this is because in the implementation is independant from the number of support vectors and only depends on the number of features.\n3. Run the inference\n#include &quot;model.h&quot;\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n\n    recordIMU();\n    classify();\n    delay(2000);\n}\n\nvoid classify() {\n    Serial.print(&quot;Detected gesture: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}\nHere we are: it has been a long post, but now you can classify gestures with an Arduino Nano and 2 Kb of RAM. \nNo fancy Neural Networks, no Tensorflow, no 32-bit ARM processors: plain old SVM on plain old 8 bits with 97% accuracy.Click To Tweet\nHere's a short demo of me playing 3 gestures and getting the results on the serial monitor.\nhttps://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4\nProject figures\r\nOn my machine, the sketch targeted at the Arduino Nano (old generation) requires 25310 bytes (82%) of program space and 1228 bytes (59%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question Can I run machine learning on Arduino? is definetly YES.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo How to do Gesture identification through machine learning on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-19T14:25:46+01:00",
            "date_modified": "2019-12-20T07:41:36+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ],
            "attachments": [
                [
                    {
                        "url": "https://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4",
                        "mime_type": "video/mp4",
                        "size_in_bytes": 1035484
                    }
                ]
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-do-morse-alphabet-identification-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-do-morse-alphabet-identification-on-arduino/",
            "title": "How to do Morse alphabet identification through machine learning on Arduino",
            "content_html": "<p>In this Arduno Machine learning project we're going to identify the letters from the <a href=\"https://en.wikipedia.org/wiki/Morse_code\">Morse alphabet</a>.<br />\nIn practice, we'll translate dots (\u2022) and dashes (\u2012)  &quot;typed&quot; with a push button into meaningful characters.<br />\nIn this tutorial we're going to target an Arduino Nano board (old generation), equipped with 32 kb of flash and only 2 kb of RAM.</p>\n<p><span id=\"more-194\"></span></p>\n<p><img src=\"https://i.ytimg.com/vi/L6gxfX4GrbI/maxresdefault.jpg\" alt=\"credits to https://www.youtube.com/watch?v=L6gxfX4GrbI\" /></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: repeat each letter a few times and save the values from the serial monitor to a file, one for each letter.</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h3>1. Features definition</h3>\n<p>For our task we'll use a simple push button as input and a fixed number of samples taken at a fixed interval (100 ms), starting from the first detection of the button press. I chose to record 30 samples for each letter, but you can easily customize the value as per your needs. </p>\n<p>With 30 samples at 100 ms frequency, we'll have 3 seconds to &quot;type&quot; the letter and on the Serial monitor will appear a sequence of 0s and 1s, representing if the button was pressed or not; the inference procedure will translate this sequence into a letter.<br />\nAs a reference, here are a couple example of what we'll be working with.</p>\n<pre><code class=\"language-cpp\">// A (\u2022\u2012)\n0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n\n// D (\u2012\u2022\u2022)\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n\n// E (\u2022)\n0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1</code></pre>\n<h3>2. Record sample data</h3>\n<p>To the bare minimum, we'll need a push button and two wires: one to ground and the other to a digital pin. Since in the example we'll make the button an <code>INPUT_PULLUP</code>, we'll read 0 when the button is pressed and 1 when not.  </p>\n<p><img src=\"https://www.arduino.cc/en/uploads/Tutorial/PullUp_bbd.png\" alt=\"credits to https://www.arduino.cc/en/Tutorial/DigitalInputPullup\" /></p>\n<p>All we need to do is detect a press and record the following 30 samples of the digital pin:</p>\n<pre><code class=\"language-cpp\">#define IN 4\n#define NUM_SAMPLES 30\n#define INTERVAL 100\n\ndouble features[NUM_SAMPLES];\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(IN, INPUT_PULLUP);\n}\n\nvoid loop() {\n  if (digitalRead(IN) == 0) {\n    recordButtonStatus();\n    printFeatures();\n    delay(1000);\n  }\n\n  delay(10);\n}\n\nvoid recordButtonStatus() {\n  for (int i = 0; i &lt; NUM_SAMPLES; i++) {\n    features[i] = digitalRead(IN);\n    delay(INTERVAL);\n  } \n}</code></pre>\n<pre><code class=\"language-cpp\">\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n</code></pre>\n<p>Open the Serial monitor and type a few times each letter: try to introduce some variations each time, for example waiting some more milliseconds before releasing the dash.</p>\n<div class=\"watchout\"> If you've never typed morse code before (as me), choose letters with few keystrokes and quite differentiable, otherwise you will need to be very good with the timing.</div>\n<p>Save the recordings for each letter in a file named after the letter, so you will get meaningful results later on.</p>\n<p>You may end with duplicate recordings: don't worry, that's not a problem. I'll paste my recordings for a few letters, as a reference.</p>\n<pre><code>// A (\u2022\u2012)\n0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1\n\n// D (\u2012\u2022\u2022)\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1\n\n// E (\u2022)\n0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n\n// S (\u2022\u2022\u2022)\n0,0,0,1,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n\n// T (\u2012)\n0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1</code></pre>\n<p>If you do a good job, you should end with quite distinguible features, as show in the plot below.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-from-Morse-alphabet-identification-features.svg\" alt=\"Decision boundaries of 2 PCA components from Morse alphabet identification features\" /></p>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<h3>3. Run the inference</h3>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid loop() {\n  if (digitalRead(IN) == 0) {\n    recordButtonStatus();\n    Serial.print(&quot;Detected letter: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n    delay(1000);\n  }\n\n  delay(10);\n}</code></pre>\n<p>Type some letter using the push button and see the identified value printed on the serial monitor.</p>\n<p>That\u2019s it: you deployed machine learning in 2 Kb! </p>\n<p><h4>Project figures</h4>\r\n<p>On my machine, the sketch targeted at the Arduino Nano (old generation) requires 12546 bytes (40%) of program space and 366 bytes (17%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question <em>Can I run machine learning on Arduino?</em> is <strong>definetly YES</strong>.<br />\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlMorseIdentificationExample/MicromlMorseIdentificationExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-do-morse-alphabet-identification-on-arduino/\">How to do Morse alphabet identification through machine learning on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this Arduno Machine learning project we're going to identify the letters from the Morse alphabet.\nIn practice, we'll translate dots (\u2022) and dashes (\u2012)  &quot;typed&quot; with a push button into meaningful characters.\nIn this tutorial we're going to target an Arduino Nano board (old generation), equipped with 32 kb of flash and only 2 kb of RAM.\n\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: repeat each letter a few times and save the values from the serial monitor to a file, one for each letter.\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nFor our task we'll use a simple push button as input and a fixed number of samples taken at a fixed interval (100 ms), starting from the first detection of the button press. I chose to record 30 samples for each letter, but you can easily customize the value as per your needs. \nWith 30 samples at 100 ms frequency, we'll have 3 seconds to &quot;type&quot; the letter and on the Serial monitor will appear a sequence of 0s and 1s, representing if the button was pressed or not; the inference procedure will translate this sequence into a letter.\nAs a reference, here are a couple example of what we'll be working with.\n// A (\u2022\u2012)\n0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n\n// D (\u2012\u2022\u2022)\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n\n// E (\u2022)\n0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n2. Record sample data\nTo the bare minimum, we'll need a push button and two wires: one to ground and the other to a digital pin. Since in the example we'll make the button an INPUT_PULLUP, we'll read 0 when the button is pressed and 1 when not.  \n\nAll we need to do is detect a press and record the following 30 samples of the digital pin:\n#define IN 4\n#define NUM_SAMPLES 30\n#define INTERVAL 100\n\ndouble features[NUM_SAMPLES];\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(IN, INPUT_PULLUP);\n}\n\nvoid loop() {\n  if (digitalRead(IN) == 0) {\n    recordButtonStatus();\n    printFeatures();\n    delay(1000);\n  }\n\n  delay(10);\n}\n\nvoid recordButtonStatus() {\n  for (int i = 0; i &lt; NUM_SAMPLES; i++) {\n    features[i] = digitalRead(IN);\n    delay(INTERVAL);\n  } \n}\n\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n\nOpen the Serial monitor and type a few times each letter: try to introduce some variations each time, for example waiting some more milliseconds before releasing the dash.\n If you've never typed morse code before (as me), choose letters with few keystrokes and quite differentiable, otherwise you will need to be very good with the timing.\nSave the recordings for each letter in a file named after the letter, so you will get meaningful results later on.\nYou may end with duplicate recordings: don't worry, that's not a problem. I'll paste my recordings for a few letters, as a reference.\n// A (\u2022\u2012)\n0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1\n\n// D (\u2012\u2022\u2022)\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1\n\n// E (\u2022)\n0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n\n// S (\u2022\u2022\u2022)\n0,0,0,1,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n\n// T (\u2012)\n0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\nIf you do a good job, you should end with quite distinguible features, as show in the plot below.\n\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\n3. Run the inference\n#include &quot;model.h&quot;\n\nvoid loop() {\n  if (digitalRead(IN) == 0) {\n    recordButtonStatus();\n    Serial.print(&quot;Detected letter: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n    delay(1000);\n  }\n\n  delay(10);\n}\nType some letter using the push button and see the identified value printed on the serial monitor.\nThat\u2019s it: you deployed machine learning in 2 Kb! \nProject figures\r\nOn my machine, the sketch targeted at the Arduino Nano (old generation) requires 12546 bytes (40%) of program space and 366 bytes (17%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question Can I run machine learning on Arduino? is definetly YES.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo How to do Morse alphabet identification through machine learning on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-06T13:07:38+01:00",
            "date_modified": "2019-12-20T07:18:11+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-do-color-identification-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-do-color-identification-on-arduino/",
            "title": "How to do color identification through machine learning on Arduino",
            "content_html": "<p>In this Arduno Machine learning project we're going to use an RGB sensor to identify objects based on their color.<br />\nThis is a remake of the project found on the <a href=\"https://blog.tensorflow.org/2019/11/fruit-identification-using-arduino-and-tensorflow.html\">Tensorflow blog</a>. We're going to use a lot less powerful chip in this tutorial, tough: an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.</p>\n<p><span id=\"more-6\"></span></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: put some colored objects in front of your sensor and save the readings</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h2>1. Features definition</h2>\n<p>We're going to use the RGB components of a color sensor (TCS3200 in my case) to infer which object we're pointing it at. This means our features are going to be of 3-dimensional, which leads to a really simple model with very high accuracy.</p>\n<hr /><p><em>You can do color identification on Arduino using Machine learning without Neural Networks #Arduino #microml #ml #tinyml #MachineLearning #ai #svm</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F12%2Fhow-to-do-color-identification-on-arduino%2F&#038;text=You%20can%20do%20color%20identification%20on%20Arduino%20using%20Machine%20learning%20without%20Neural%20Networks%20%23Arduino%20%23microml%20%23ml%20%23tinyml%20%23MachineLearning%20%23ai%20%23svm&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<h2>2. Record sample data</h2>\n<p>We don't need any processing to get from the sensor readings to the feature vector, so the code will be straight-forward: read each component from the sensor and assign it to the features array. This part will vary based on the specific chip you have: I'll report the code for a TCS 230/3200. </p>\n<pre><code class=\"language-cpp\">#define S2 2\n#define S3 3\n#define sensorOut 4\n\ndouble features[3];\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(S2, OUTPUT);\n  pinMode(S3, OUTPUT);\n  pinMode(sensorOut, INPUT);\n}\n\nvoid loop() {\n  readRGB();\n  printFeatures();\n  delay(100);\n}\n\nint readComponent(bool s2, bool s3) {\n  delay(10);\n  digitalWrite(S2, s2);\n  digitalWrite(S3, s3);\n\n  return pulseIn(sensorOut, LOW);\n}\n\nvoid readRGB() {\n  features[0] = readComponent(LOW, LOW);\n  features[1] = readComponent(HIGH, HIGH);\n  features[2] = readComponent(LOW, HIGH);\n}</code></pre>\n<pre><code class=\"language-cpp\">\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n</code></pre>\n<p>Open the Serial monitor and put some colored objects in front of the sensor: move the object a bit and rotate it, so the samples will include different shades of the color.</p>\n<p>Save the recordings for each color in a file named after the color, so you will get meaningful results later on.</p>\n<div class=\"watchout\">\nDon\u2019t forget to sample the \u201cempty color\u201d too: don\u2019t put anything in front of the sensor and let it record for a while.\n</div>\n<p>If you do a good job, you should end with distinguible features, as show in the contour plot below.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-from-the-colors-features.png\" alt=\"Decision boundaries of 2 PCA components from the colors features\" /></p>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<h2>4. Run the inference</h2>\n<pre><code class=\"language-cpp\">#include model.h\n\nvoid loop() {\n  readRGB();\n  Serial.println(classIdxToName(predict(features)));\n  delay(1000);\n}</code></pre>\n<p>Put some colored object in front of the sensor and see the identified object name printed on the serial monitor.</p>\n<div class=\"watchout\">Do you remember the \"empty color\"? It needs to be recorded so you will get \"empty\" when no object is present, otherwise you'll get unexpected predictions</div>\n<p>Given the simplicity of the task, you should easily achieve near 100% accuracy for different colors (I had some troubles distinguishing orange from yellow because of the bad illumination). Just be sure to replicate the exact same setup both during training and classification.</p>\n<p>That\u2019s it: you deployed machine learning in 2 Kb! </p>\n<p><h4>Project figures</h4>\r\n<p>On my machine, the sketch targeted at the Arduino Nano (old generation) requires 5570 bytes (18%) of program space and 266 bytes (12%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question <em>Can I run machine learning on Arduino?</em> is <strong>definetly YES</strong>.<br />\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlColorIdentificationExample/MicromlColorIdentificationExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-do-color-identification-on-arduino/\">How to do color identification through machine learning on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this Arduno Machine learning project we're going to use an RGB sensor to identify objects based on their color.\nThis is a remake of the project found on the Tensorflow blog. We're going to use a lot less powerful chip in this tutorial, tough: an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: put some colored objects in front of your sensor and save the readings\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nWe're going to use the RGB components of a color sensor (TCS3200 in my case) to infer which object we're pointing it at. This means our features are going to be of 3-dimensional, which leads to a really simple model with very high accuracy.\nYou can do color identification on Arduino using Machine learning without Neural Networks #Arduino #microml #ml #tinyml #MachineLearning #ai #svmClick To Tweet\n2. Record sample data\nWe don't need any processing to get from the sensor readings to the feature vector, so the code will be straight-forward: read each component from the sensor and assign it to the features array. This part will vary based on the specific chip you have: I'll report the code for a TCS 230/3200. \n#define S2 2\n#define S3 3\n#define sensorOut 4\n\ndouble features[3];\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(S2, OUTPUT);\n  pinMode(S3, OUTPUT);\n  pinMode(sensorOut, INPUT);\n}\n\nvoid loop() {\n  readRGB();\n  printFeatures();\n  delay(100);\n}\n\nint readComponent(bool s2, bool s3) {\n  delay(10);\n  digitalWrite(S2, s2);\n  digitalWrite(S3, s3);\n\n  return pulseIn(sensorOut, LOW);\n}\n\nvoid readRGB() {\n  features[0] = readComponent(LOW, LOW);\n  features[1] = readComponent(HIGH, HIGH);\n  features[2] = readComponent(LOW, HIGH);\n}\n\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n\nOpen the Serial monitor and put some colored objects in front of the sensor: move the object a bit and rotate it, so the samples will include different shades of the color.\nSave the recordings for each color in a file named after the color, so you will get meaningful results later on.\n\nDon\u2019t forget to sample the \u201cempty color\u201d too: don\u2019t put anything in front of the sensor and let it record for a while.\n\nIf you do a good job, you should end with distinguible features, as show in the contour plot below.\n\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\n4. Run the inference\n#include model.h\n\nvoid loop() {\n  readRGB();\n  Serial.println(classIdxToName(predict(features)));\n  delay(1000);\n}\nPut some colored object in front of the sensor and see the identified object name printed on the serial monitor.\nDo you remember the \"empty color\"? It needs to be recorded so you will get \"empty\" when no object is present, otherwise you'll get unexpected predictions\nGiven the simplicity of the task, you should easily achieve near 100% accuracy for different colors (I had some troubles distinguishing orange from yellow because of the bad illumination). Just be sure to replicate the exact same setup both during training and classification.\nThat\u2019s it: you deployed machine learning in 2 Kb! \nProject figures\r\nOn my machine, the sketch targeted at the Arduino Nano (old generation) requires 5570 bytes (18%) of program space and 266 bytes (12%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question Can I run machine learning on Arduino? is definetly YES.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo How to do color identification through machine learning on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-01T11:35:29+01:00",
            "date_modified": "2019-12-21T07:20:02+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-do-iris-classification-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-do-iris-classification-on-arduino/",
            "title": "How to do Iris classification through machine learning on Arduino",
            "content_html": "<p>In this first tutorial from the series <em><a href=\"/category/programming/arduino-machine-learning/\">Arduino Machine learning</a></em> we're going to implement the &quot;Hello world&quot; of Machine learning projects: classifying the Iris dataset on an Arduino board. The <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">Iris dataset</a> is a well known one in the Machine learning world and is often used in introductory tutorials about classification.<br />\nIn this tutorial we're going to run the classification directly on a Arduino Nano board (old generation), equipped with 32 kb of flash and only 2 kb of RAM: that's the only thing you will need!</p>\n<p><span id=\"more-409\"></span></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: we'll use the publicly available dataset</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h3>1. Features definition</h3>\n<p>There are 4 features in this dataset: sepal length, sepal width, petal length, petal width; and 3 classes: Setosa, Versicolor, Virginica. You can see in the picture below how they relate to the actual flower.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/iris-278x300.png\" alt=\"Iris features illustrated @ credits to https://gallery.azure.ai/Experiment/Classify-Iris-Dataset-using-Decision-Forest-1\" /></p>\n<h3>2. Sample data</h3>\n<p>You may download the dataset <a href=\"https://gist.github.com/netj/8836201\">here</a>.<br />\nAn excerpt of the dataset is reported in the following table.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">sepal.length</th>\n<th style=\"text-align: center;\">sepal.width</th>\n<th style=\"text-align: center;\">petal.length</th>\n<th style=\"text-align: center;\">petal.width</th>\n<th style=\"text-align: center;\">variety</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">5.1</td>\n<td style=\"text-align: center;\">3.5</td>\n<td style=\"text-align: center;\">1.4</td>\n<td style=\"text-align: center;\">0.2</td>\n<td style=\"text-align: center;\">Setosa</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">4.9</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">1.4</td>\n<td style=\"text-align: center;\">0.2</td>\n<td style=\"text-align: center;\">Setosa</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">4.6</td>\n<td style=\"text-align: center;\">3.1</td>\n<td style=\"text-align: center;\">1.5</td>\n<td style=\"text-align: center;\">0.2</td>\n<td style=\"text-align: center;\">Setosa</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">5.8</td>\n<td style=\"text-align: center;\">2.6</td>\n<td style=\"text-align: center;\">4</td>\n<td style=\"text-align: center;\">1.2</td>\n<td style=\"text-align: center;\">Versicolor</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">5.6</td>\n<td style=\"text-align: center;\">2.7</td>\n<td style=\"text-align: center;\">4.2</td>\n<td style=\"text-align: center;\">1.3</td>\n<td style=\"text-align: center;\">Versicolor</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">6.3</td>\n<td style=\"text-align: center;\">2.5</td>\n<td style=\"text-align: center;\">5</td>\n<td style=\"text-align: center;\">1.9</td>\n<td style=\"text-align: center;\">Virginica</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">6.5</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">5.2</td>\n<td style=\"text-align: center;\">2</td>\n<td style=\"text-align: center;\">Virginica</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">5.9</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">5.1</td>\n<td style=\"text-align: center;\">1.8</td>\n<td style=\"text-align: center;\">Virginica</td>\n</tr>\n</tbody>\n</table>\n<p>A contour plot of this dataset is depicted in the image below.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Iris-features.svg\" alt=\"Decision boundaries of 2 PCA components of Iris features\" /></p>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<h3>4. Run the inference</h3>\n<p>We will be running the inferences from the features entered via Serial monitor: you type 4 float values representing the 4 features and get back the predicted Iris species.</p>\n<pre><code class=\"language-cpp\">#include &quot;iris.h&quot;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    if (Serial.available()) {\n        double features[4];\n\n        for (int i = 0; i &lt; 4; i++) {\n            // split features on comma (,)\n            String feature = Serial.readStringUntil(&#039;,&#039;);\n\n            features[i] = atof(feature.c_str());\n        }\n\n        Serial.print(&quot;Detected species: &quot;);\n        Serial.println(classIdxToName(predict(features)));\n    }\n\n    delay(10);\n}</code></pre>\n<p>If you open the Serial monitor you should see something like the next picture as you type in the features from different species.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Iris-serial.png\" alt=\"Iris classification serial output\" /></p>\n<p>That\u2019s it: you deployed machine learning in 2 Kb!</p>\n<p><h4>Project figures</h4>\r\n<p>On my machine, the sketch targeted at the Arduino Nano (old generation) requires 7446 bytes (24%) of program space and 302 bytes (14%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question <em>Can I run machine learning on Arduino?</em> is <strong>definetly YES</strong>.<br />\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlIrisExample/MicromlIrisExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-do-iris-classification-on-arduino/\">How to do Iris classification through machine learning on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this first tutorial from the series Arduino Machine learning we're going to implement the &quot;Hello world&quot; of Machine learning projects: classifying the Iris dataset on an Arduino board. The Iris dataset is a well known one in the Machine learning world and is often used in introductory tutorials about classification.\nIn this tutorial we're going to run the classification directly on a Arduino Nano board (old generation), equipped with 32 kb of flash and only 2 kb of RAM: that's the only thing you will need!\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: we'll use the publicly available dataset\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nThere are 4 features in this dataset: sepal length, sepal width, petal length, petal width; and 3 classes: Setosa, Versicolor, Virginica. You can see in the picture below how they relate to the actual flower.\n\n2. Sample data\nYou may download the dataset here.\nAn excerpt of the dataset is reported in the following table.\n\n\n\nsepal.length\nsepal.width\npetal.length\npetal.width\nvariety\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nSetosa\n\n\n4.9\n3\n1.4\n0.2\nSetosa\n\n\n4.6\n3.1\n1.5\n0.2\nSetosa\n\n\n5.8\n2.6\n4\n1.2\nVersicolor\n\n\n5.6\n2.7\n4.2\n1.3\nVersicolor\n\n\n6.3\n2.5\n5\n1.9\nVirginica\n\n\n6.5\n3\n5.2\n2\nVirginica\n\n\n5.9\n3\n5.1\n1.8\nVirginica\n\n\n\nA contour plot of this dataset is depicted in the image below.\n\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\n4. Run the inference\nWe will be running the inferences from the features entered via Serial monitor: you type 4 float values representing the 4 features and get back the predicted Iris species.\n#include &quot;iris.h&quot;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    if (Serial.available()) {\n        double features[4];\n\n        for (int i = 0; i &lt; 4; i++) {\n            // split features on comma (,)\n            String feature = Serial.readStringUntil(&#039;,&#039;);\n\n            features[i] = atof(feature.c_str());\n        }\n\n        Serial.print(&quot;Detected species: &quot;);\n        Serial.println(classIdxToName(predict(features)));\n    }\n\n    delay(10);\n}\nIf you open the Serial monitor you should see something like the next picture as you type in the features from different species.\n\nThat\u2019s it: you deployed machine learning in 2 Kb!\nProject figures\r\nOn my machine, the sketch targeted at the Arduino Nano (old generation) requires 7446 bytes (24%) of program space and 302 bytes (14%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question Can I run machine learning on Arduino? is definetly YES.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo How to do Iris classification through machine learning on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-01T10:02:02+01:00",
            "date_modified": "2019-12-20T07:18:46+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/11/how-to-create-a-classifier-for-arduino-machine-learning-projects/",
            "url": "https://eloquentarduino.github.io/2019/11/how-to-create-a-classifier-for-arduino-machine-learning-projects/",
            "title": "This is how I create my Arduino Machine learning classifiers in 4 easy steps",
            "content_html": "<p>In this post I'll show you how I train my classifiers in scikit-learn and export them for Arduino machine learning projects. Since this is a repetitive task, you can save a short snippet of Python code on your PC and use it whenever you need to train a classifier from Arduino data. It really is a general-purpose piece of code that reads the files from a folder and generates a features matrix from them; the useful bit, so to say, is that it generates a classmap to translate class indexes to readable names.</p>\n<p><span id=\"more-104\"></span></p>\n<h2>Setup</h2>\n<div class=\"watchout\">The code assumes you've saved your samples in a folder, one class per file, one sample per line.</div>\n<pre><code class=\"language-python\">import numpy as np\nfrom glob import glob\nfrom os.path import basename\n\ndef load_features(folder):\n    dataset = None\n    classmap = {}\n    for class_idx, filename in enumerate(glob(&#039;%s/*.csv&#039; % folder)):\n        class_name = basename(filename)[:-4]\n        classmap[class_idx] = class_name\n        samples = np.loadtxt(filename)\n        labels = np.ones((len(samples), 1)) * class_idx\n        samples = np.hstack((samples, labels))\n        dataset = samples if dataset is None else np.vstack((dataset, samples))\n    return dataset, classmap</code></pre>\n<h2>Train the classifier</h2>\n<p>Include the snippet in your scikit-learn project and use it to train your SVM classifier.</p>\n<pre><code class=\"language-python\">from sklearn.svm import SVC\n\nfeatures, classmap = load_features(&#039;datasets/colors/&#039;)\nX, y = features[:, :-1], features[:, -1]\nclassifier = SVC(kernel=&#039;linear&#039;).fit(X, y)</code></pre>\n<h2>Generate C code</h2>\n<p>Now you can convert the trained classifier to C code using the <a href=\"https://github.com/agrimagsrl/micromlgen\"><code>micromlgen</code></a> package.</p>\n<pre><code class=\"language-python\">pip install micromlgen</code></pre>\n<pre><code class=\"language-python\">from micromlgen import port\n\nc_code = port(classifier)\nprint(c_code)</code></pre>\n<p>This is the code you need to import in your Arduino project. To follow along with the tutorials on this blog, save it in a file called <code>model.h</code>.</p>\n<h2>Use in Arduino project</h2>\n<p>There are two methods you will need to call to run the predictions in your project:</p>\n<ol>\n<li><code>predict(double features[])</code>: it runs the actual prediction and returns a number representing the predicted class</li>\n<li><code>classIdxToName(uint8_t classIdx)</code>: converts the class index to a readable string, based on the classmap generated from your files</li>\n</ol>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid classify() {\n    Serial.print(&quot;Predicted class: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}</code></pre>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/11/how-to-create-a-classifier-for-arduino-machine-learning-projects/\">This is how I create my Arduino Machine learning classifiers in 4 easy steps</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this post I'll show you how I train my classifiers in scikit-learn and export them for Arduino machine learning projects. Since this is a repetitive task, you can save a short snippet of Python code on your PC and use it whenever you need to train a classifier from Arduino data. It really is a general-purpose piece of code that reads the files from a folder and generates a features matrix from them; the useful bit, so to say, is that it generates a classmap to translate class indexes to readable names.\n\nSetup\nThe code assumes you've saved your samples in a folder, one class per file, one sample per line.\nimport numpy as np\nfrom glob import glob\nfrom os.path import basename\n\ndef load_features(folder):\n    dataset = None\n    classmap = {}\n    for class_idx, filename in enumerate(glob(&#039;%s/*.csv&#039; % folder)):\n        class_name = basename(filename)[:-4]\n        classmap[class_idx] = class_name\n        samples = np.loadtxt(filename)\n        labels = np.ones((len(samples), 1)) * class_idx\n        samples = np.hstack((samples, labels))\n        dataset = samples if dataset is None else np.vstack((dataset, samples))\n    return dataset, classmap\nTrain the classifier\nInclude the snippet in your scikit-learn project and use it to train your SVM classifier.\nfrom sklearn.svm import SVC\n\nfeatures, classmap = load_features(&#039;datasets/colors/&#039;)\nX, y = features[:, :-1], features[:, -1]\nclassifier = SVC(kernel=&#039;linear&#039;).fit(X, y)\nGenerate C code\nNow you can convert the trained classifier to C code using the micromlgen package.\npip install micromlgen\nfrom micromlgen import port\n\nc_code = port(classifier)\nprint(c_code)\nThis is the code you need to import in your Arduino project. To follow along with the tutorials on this blog, save it in a file called model.h.\nUse in Arduino project\nThere are two methods you will need to call to run the predictions in your project:\n\npredict(double features[]): it runs the actual prediction and returns a number representing the predicted class\nclassIdxToName(uint8_t classIdx): converts the class index to a readable string, based on the classmap generated from your files\n\n#include &quot;model.h&quot;\n\nvoid classify() {\n    Serial.print(&quot;Predicted class: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}\nL'articolo This is how I create my Arduino Machine learning classifiers in 4 easy steps proviene da Eloquent Arduino Blog.",
            "date_published": "2019-11-11T22:10:51+01:00",
            "date_modified": "2019-12-16T19:41:16+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/11/you-can-run-machine-learning-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/11/you-can-run-machine-learning-on-arduino/",
            "title": "You can run Machine learning on Arduino. And any other MCU out there too!",
            "content_html": "<p><a href=\"https://www.quora.com/I-want-to-make-a-robot-with-an-Arduino-that-uses-basic-machine-learning-where-can-I-start\">A</a> <a href=\"https://robotics.stackexchange.com/questions/568/is-it-possible-to-run-a-neural-network-on-a-microcontroller\">lot</a> <a href=\"https://www.reddit.com/r/robotics/comments/bnmm75/arduino_for_machine_learning/\">of</a> <a href=\"https://www.quora.com/How-do-I-use-machine-learning-with-Arduino\">forum</a> <a href=\"https://forum.arduino.cc/index.php?topic=63981.0\">threads</a> ask about the possibility to run Machine learning on Arduino.<br />\nThe answers mostly follow in one of these 3 categories:</p>\n<ol>\n<li>Arduino is too resource-constrained to handle Machine learning</li>\n<li>Come up with a naive implementation of a <a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron\">Multi Layer Perceptron</a></li>\n<li>(recently) Sure! You can use <a href=\"https://www.tensorflow.org/lite/microcontrollers\">Tensorflow Lite for Microcontrollers</a></li>\n</ol>\n<p>No single answer I read talked about the other 100s alghoritms that fall under the Machine learning umbrella. <strong>No. Single. One.</strong> Let me explain what I think is wrong with this.</p>\n<p><span id=\"more-76\"></span></p>\n<p>First of all I'd like to state one absolutely important thing:</p>\n<hr /><p><em>Artificial intelligence \u2260 Machine learning \u2260 Neural networks. This should be clear</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F11%2Fyou-can-run-machine-learning-on-arduino%2F&#038;text=Artificial%20intelligence%20%E2%89%A0%20Machine%20learning%20%E2%89%A0%20Neural%20networks.%20This%20should%20be%20clear&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>I admit most of those questions seemed to come from principiants. Also the answers, though, most often lack any sound knowledge about the topic.</p>\n<hr /><p><em>You can run classification and regression on Arduino boards, even the less powerful ones: just don&#039;t use Neural networks. It&#039;s that simple.</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F11%2Fyou-can-run-machine-learning-on-arduino%2F&#038;text=You%20can%20run%20classification%20and%20regression%20on%20Arduino%20boards%2C%20even%20the%20less%20powerful%20ones%3A%20just%20don%27t%20use%20Neural%20networks.%20It%27s%20that%20simple.&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<h2>Introducing MicroML generator</h2>\n<p>So I do you <em>actually</em> run machine learning on such constrained devices?</p>\n<p>Here you are: <a href=\"https://github.com/eloquentarduino/micromlgen\">MicroML</a> is a project to bring Machine learning algorithms to microcontrollers. It was born as an alternative to Tensorflow for Microcontrollers, which is solely dedicated to Artificial Neural Networks: here you will find leaner alternatives to neural networks to run inference <strong>even on 8-bit microcontrollers</strong>.</p>\n<p>Quoting from the Tensoflow blog: <em>The core runtime fits in 16 KB on an Arm Cortex M3</em> (that's just the runtime, without any actual operator!). </p>\n<hr /><p><em>MicroML lets you deploy models that fit in under 2 Kb of RAM #microml #arduino #ai #ml</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F11%2Fyou-can-run-machine-learning-on-arduino%2F&#038;text=MicroML%20lets%20you%20deploy%20models%20that%20fit%20in%20under%202%20Kb%20of%20RAM%20%23microml%20%23arduino%20%23ai%20%23ml&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>At the current state, it can convert <a href=\"https://en.wikipedia.org/wiki/Support-vector_machine\">Support Vector Machines</a> to optimized C code you can deploy on any MCU of you choice: Arduino (Uno, Nano, Micro...), ESP8266, ESP32 and really any other MCU with C support.</p>\n<div class=\"watchout\">At the moment you can't deploy to Attiny boards because their compiler seems not to support variadic functions: I'll fix this as soon as possible, already got a working implementation</div>\n<p>Why Support Vector Machines? Because they're really good at classifying highly-dimensional features and are quite easy to optimize for RAM-constrained environments (check the tutorial on <a href=\"/2019/12/how-to-do-gesture-identification-on-arduino/\">Gesture identification</a> which has 90 features!)</p>\n<h2>How to port a classifier</h2>\n<p>First of all, you need to train a classifier. You have to use the Python's library <a href=\"https://scikit-learn.org/stable/\">scikit-learn</a> \u2014 which you're probably already using considering its widespread adoption. Then you need to install the MicroML package.</p>\n<pre><code class=\"language-python\">pip install micromlgen</code></pre>\n<p>Finally, you <code>port</code> your trained classifier to optimized C code.</p>\n<pre><code class=\"language-python\">from micromlgen import port\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\n\nif __name__ == &#039;__main__&#039;:\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    clf = SVC(kernel=&#039;linear&#039;).fit(X, y)\n    print(port(clf))</code></pre>\n<p>That's it: you now have all you need to do classification in your Arduino projects.</p>\n<h2>Existing alternatives</h2>\n<p>There exists some alternatives to this library, but they suffer from some limitations:</p>\n<ol>\n<li><a href=\"https://github.com/nok/sklearn-porter\">sklearn-porter</a> can output C code (among the others), but it's not optimized for microcontrollers. You'll hit a wall on RAM because it needs to declare all the support vectors in memory (to have an idea, the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\">breast cancer dataset</a> produces a 57x30 matrix of doubles, totalling 6840 bytes just for the support vectors).</li>\n<li><a href=\"https://github.com/emlearn/emlearn\">emlearn</a> is optimized for microcontrollers, can do Decision Tree, Random Forest, Naive Gaussian Bayes, Fully connected Neural Networks. No SVM though.</li>\n</ol>\n<p>My effort was to find an implementation that needed the least amount possible of memory: this was possible sacrificing the program space, but that's less often a problem since RAM is usually the most limiting factor. If your model fills up the program space you can revert to <code>sklearn-porter</code> (if you have enough RAM, of course).</p>\n<h2>Use in Arduino project</h2>\n<p>There are two methods you will need to call to run the predictions in your project:</p>\n<ol>\n<li><code>predict(double features[])</code>: it runs the actual prediction and returns a number representing the predicted class</li>\n<li><code>classIdxToName(uint8_t classIdx)</code>: converts the class index to a readable string, based on the classmap generated from your files</li>\n</ol>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid classify() {\n    Serial.print(&quot;Predicted class: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}</code></pre>\n<hr />\n<p>I'm starting a series of tutorials about hands-on projects to put Machine learning in use: you can follow the <strong>Related posts</strong> links to follow along, so keep reading!</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/11/you-can-run-machine-learning-on-arduino/\">You can run Machine learning on Arduino. And any other MCU out there too!</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "A lot of forum threads ask about the possibility to run Machine learning on Arduino.\nThe answers mostly follow in one of these 3 categories:\n\nArduino is too resource-constrained to handle Machine learning\nCome up with a naive implementation of a Multi Layer Perceptron\n(recently) Sure! You can use Tensorflow Lite for Microcontrollers\n\nNo single answer I read talked about the other 100s alghoritms that fall under the Machine learning umbrella. No. Single. One. Let me explain what I think is wrong with this.\n\nFirst of all I'd like to state one absolutely important thing:\nArtificial intelligence \u2260 Machine learning \u2260 Neural networks. This should be clearClick To Tweet\nI admit most of those questions seemed to come from principiants. Also the answers, though, most often lack any sound knowledge about the topic.\nYou can run classification and regression on Arduino boards, even the less powerful ones: just don&#039;t use Neural networks. It&#039;s that simple.Click To Tweet\nIntroducing MicroML generator\nSo I do you actually run machine learning on such constrained devices?\nHere you are: MicroML is a project to bring Machine learning algorithms to microcontrollers. It was born as an alternative to Tensorflow for Microcontrollers, which is solely dedicated to Artificial Neural Networks: here you will find leaner alternatives to neural networks to run inference even on 8-bit microcontrollers.\nQuoting from the Tensoflow blog: The core runtime fits in 16 KB on an Arm Cortex M3 (that's just the runtime, without any actual operator!). \nMicroML lets you deploy models that fit in under 2 Kb of RAM #microml #arduino #ai #mlClick To Tweet\nAt the current state, it can convert Support Vector Machines to optimized C code you can deploy on any MCU of you choice: Arduino (Uno, Nano, Micro...), ESP8266, ESP32 and really any other MCU with C support.\nAt the moment you can't deploy to Attiny boards because their compiler seems not to support variadic functions: I'll fix this as soon as possible, already got a working implementation\nWhy Support Vector Machines? Because they're really good at classifying highly-dimensional features and are quite easy to optimize for RAM-constrained environments (check the tutorial on Gesture identification which has 90 features!)\nHow to port a classifier\nFirst of all, you need to train a classifier. You have to use the Python's library scikit-learn \u2014 which you're probably already using considering its widespread adoption. Then you need to install the MicroML package.\npip install micromlgen\nFinally, you port your trained classifier to optimized C code.\nfrom micromlgen import port\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\n\nif __name__ == &#039;__main__&#039;:\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    clf = SVC(kernel=&#039;linear&#039;).fit(X, y)\n    print(port(clf))\nThat's it: you now have all you need to do classification in your Arduino projects.\nExisting alternatives\nThere exists some alternatives to this library, but they suffer from some limitations:\n\nsklearn-porter can output C code (among the others), but it's not optimized for microcontrollers. You'll hit a wall on RAM because it needs to declare all the support vectors in memory (to have an idea, the breast cancer dataset produces a 57x30 matrix of doubles, totalling 6840 bytes just for the support vectors).\nemlearn is optimized for microcontrollers, can do Decision Tree, Random Forest, Naive Gaussian Bayes, Fully connected Neural Networks. No SVM though.\n\nMy effort was to find an implementation that needed the least amount possible of memory: this was possible sacrificing the program space, but that's less often a problem since RAM is usually the most limiting factor. If your model fills up the program space you can revert to sklearn-porter (if you have enough RAM, of course).\nUse in Arduino project\nThere are two methods you will need to call to run the predictions in your project:\n\npredict(double features[]): it runs the actual prediction and returns a number representing the predicted class\nclassIdxToName(uint8_t classIdx): converts the class index to a readable string, based on the classmap generated from your files\n\n#include &quot;model.h&quot;\n\nvoid classify() {\n    Serial.print(&quot;Predicted class: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}\n\nI'm starting a series of tutorials about hands-on projects to put Machine learning in use: you can follow the Related posts links to follow along, so keep reading!\nL'articolo You can run Machine learning on Arduino. And any other MCU out there too! proviene da Eloquent Arduino Blog.",
            "date_published": "2019-11-10T20:18:40+01:00",
            "date_modified": "2019-12-21T15:50:02+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        }
    ]
}