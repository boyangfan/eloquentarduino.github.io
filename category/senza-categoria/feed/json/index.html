<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><p>{
    "version": "https://jsonfeed.org/version/1.1",
    "user_comment": "This feed allows you to read the posts from this site in any feed reader that supports the JSON Feed format. To add this feed to your reader, copy the following URL -- https://eloquentarduino.github.io/category/senza-categoria/feed/json/ -- and add it your reader.",
    "home_page_url": "https://eloquentarduino.github.io/category/senza-categoria/",
    "feed_url": "https://eloquentarduino.github.io/category/senza-categoria/feed/json/",
    "language": "en-US",
    "title": "Senza categoria â€“ Eloquent Arduino Blog",
    "description": "Machine learning on Arduino, programming & electronics",
    "items": [
        {
            "id": "https://eloquentarduino.github.io/?p=1050",
            "url": "https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/",
            "title": "Passive-aggressive classifier for embedded devices",
            "content_html": "</p><p>When working with memory constrained devices you may not able to keep all the training data in memory: passive-aggressive classifiers may help solve your memory problems.</p>\n<p><span id='\"more-1050\"'></span></p>\n<h2>Batch learning</h2>\n<p>A couple weeks ago I started exploring the possibility to train a machine learning classifier directly on a microcontroller. Since I like SVM, <a href="%5C%22/2020/03/so-you-want-to-train-an-ml-classifier-directly-on-an-arduino-board%5C%22">I ported the simplified SVM SMO (Sequential Minimal Optimization) algorithm</a> to plain C, ready to be deployed to embedded devices.</p>\n<p>Now, that kind of algorithm works in the so-called "batch-mode": it needs all the training data to be available in memory to learn.</p>\n<p>This may be a limiting factor on resource-constrained devices, since it poses an upper bound to the number of samples you can train on. And when working with high-dimensional datasets, the number of samples could be not enough to achieve good accuracy.</p>\n<h2>Enter incremental learning</h2>\n<p>To solve this limitation, you need a totally different kind of learning algorithms: you need incremental (a.k.a online a.k.a out of core) learning.</p>\n<p>Incremental learning works by inspecting one training sample at a time, instead of all at once.</p>\n<p>The clear advantage is that you have a tiny memory footprint. And this is a <strong>huge</strong> advantage.</p>\n<p>The clear disadvantage is that you don't have the "big picture" of your data, so:</p>\n<ul>\n<li>the end result will probably be affected by the order of presentation of the samples</li>\n<li>you may not be able to achieve top accuracy</li>\n</ul>\n<h2>Passive-aggressive classifier</h2>\n<p>Passive-aggressive classification is one of the available incremental learning algorithms and it is very simple to implement, since it has a closed-form update rule.</p>\n<p>Please refer to this <a href="%5C%22https://www.bonaccorso.eu/2017/10/06/ml-algorithms-addendum-passive-aggressive-algorithms/%5C%22">short explanation on Passive-aggressive classifiers</a> for a nice description with images.</p>\n<p>The core concept is that the classifier adjusts it weight vector for each mis-classified training sample it receives, trying to get it correct.</p>\n<p><img src="%5C%22https://eloquentarduino.github.io/wp-content/uploads/2020/04/passive-aggressive-classifier.png%5C%22" alt='\"Passive' aggressive classifier></p>\n<h2>Benchmarks</h2>\n<p>I run a couple benchmark on my Esp32 to assess both accuracy and training time.</p>\n<p>First of all: <strong>it is fast!</strong>. When I say it is fast I mean it takes ~1ms to train on 400 samples x 30 features each.</p>\n<p>Talking about accuracy instead... Uhm...</p>\n<p>Accuracy vary. <strong>Greatly</strong>. </p>\n<p>You can achieve 100% on some datasets. </p>\n<p>And 40% on others. But on those same datasets you can achieve >85% if training on a different number of samples. Or in a different order.</p>\n<p>I guess this is the tradeoff for such a simple and space-efficient algorithm.</p>\n<p>I report my results in the following table. It is not meant to be an exhaustive benchmark of the classifier, since those number will vary based on the order of presentation, but still you can get an idea of what it is able to achieve.</p>\n<table>\n<thead>\n<tr>\n<th>Dataset size</th>\n<th style='\"text-align:' center>Train samples</th>\n<th style='\"text-align:' right>Accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>BREAST CANCER</td>\n<td style='\"text-align:' center></td>\n<td style='\"text-align:' right></td>\n</tr>\n<tr>\n<td>567 samples</td>\n<td style='\"text-align:' center>20</td>\n<td style='\"text-align:' right>62</td>\n</tr>\n<tr>\n<td>30 features</td>\n<td style='\"text-align:' center>40</td>\n<td style='\"text-align:' right>37</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>60</td>\n<td style='\"text-align:' right>63</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>100</td>\n<td style='\"text-align:' right>39</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>150</td>\n<td style='\"text-align:' right>38</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>200</td>\n<td style='\"text-align:' right>64</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>250</td>\n<td style='\"text-align:' right>61</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>300</td>\n<td style='\"text-align:' right>69</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>350</td>\n<td style='\"text-align:' right>73</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>400</td>\n<td style='\"text-align:' right>85</td>\n</tr>\n<tr>\n<td>IRIS</td>\n<td style='\"text-align:' center></td>\n<td style='\"text-align:' right></td>\n</tr>\n<tr>\n<td>100 samples</td>\n<td style='\"text-align:' center>10</td>\n<td style='\"text-align:' right>50</td>\n</tr>\n<tr>\n<td>4 features</td>\n<td style='\"text-align:' center>20</td>\n<td style='\"text-align:' right>51</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>40</td>\n<td style='\"text-align:' right>100</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>60</td>\n<td style='\"text-align:' right>100</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>80</td>\n<td style='\"text-align:' right>100</td>\n</tr>\n<tr>\n<td>DIGITS</td>\n<td style='\"text-align:' center></td>\n<td style='\"text-align:' right></td>\n</tr>\n<tr>\n<td>358 samples</td>\n<td style='\"text-align:' center>20</td>\n<td style='\"text-align:' right>98</td>\n</tr>\n<tr>\n<td>64 features</td>\n<td style='\"text-align:' center>40</td>\n<td style='\"text-align:' right>98</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>60</td>\n<td style='\"text-align:' right>99</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>100</td>\n<td style='\"text-align:' right>100</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>150</td>\n<td style='\"text-align:' right>100</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>200</td>\n<td style='\"text-align:' right>99</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>250</td>\n<td style='\"text-align:' right>98</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>300</td>\n<td style='\"text-align:' right>95</td>\n</tr>\n<tr>\n<td>CLEVELAND HEART DISEASE</td>\n<td style='\"text-align:' center></td>\n<td style='\"text-align:' right></td>\n</tr>\n<tr>\n<td>212 samples</td>\n<td style='\"text-align:' center>20</td>\n<td style='\"text-align:' right>76</td>\n</tr>\n<tr>\n<td>13 features</td>\n<td style='\"text-align:' center>40</td>\n<td style='\"text-align:' right>24</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>60</td>\n<td style='\"text-align:' right>77</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>100</td>\n<td style='\"text-align:' right>19</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>120</td>\n<td style='\"text-align:' right>82</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>140</td>\n<td style='\"text-align:' right>78</td>\n</tr>\n<tr>\n<td></td>\n<td style='\"text-align:' center>180</td>\n<td style='\"text-align:' right>88</td>\n</tr>\n</tbody>\n</table>\n<h2>Time to code</h2>\n<p>Here I'll report an extract of the example code you can find on <a href="%5C%22https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PassiveAggressiveExample/PassiveAggressiveExample.ino%5C%22">Github</a> for this classifier.</p>\n<pre><code class='\"language-c\"'>#include <EloquentPassiveAggressiveClassifier.h>\n#include <EloquentAccuracyScorer.h>\n#include "iris.h"\n\nusing namespace Eloquent::ML;\n\nvoid loop() {\n    int trainSamples;\n    PassiveAggressiveClassifier<FEATURES_DIM> clf;\n    AccuracyScorer scorer;\n\n    trainSamples = readSerialNumber("How many samples will you use as training?", DATASET_SIZE - 2);\n\n    if (trainSamples == 0)\n        return;\n\n    clf.setC(1);\n\n    // train\n    for (uint16_t i = 0; i < trainSamples; i++)\n        clf.fitOne(X[i], y[i]);\n\n    // predict\n    for (uint16_t i = trainSamples; i < DATASET_SIZE; i++) {\n        int predicted = clf.predict(X[i]);\n        int actual = y[i] > 0 ? 1 : -1;\n\n        scorer.scoreOne(actual, predicted);\n    }\n\n    Serial.print("Accuracy: ");\n    Serial.print(round(100 * scorer.accuracy()));\n    Serial.print("% out of ");\n    Serial.print(scorer.support());\n    Serial.println(" predictions");\n}</code></pre>\n<hr>\n<p>On the <a href="%5C%22https://github.com/eloquentarduino/EloquentMicroML/blob/master/examples/PassiveAggressiveExample/PassiveAggressiveExample.ino%5C%22">project page</a> you will find the code to reproduce these numbers.</p>\n<hr>\n<p>L'articolo <a rel='\"nofollow\"' href="%5C%22https://eloquentarduino.github.io/2020/04/passive-aggressive-classifier-for-embedded-devices/%5C%22">Passive-aggressive classifier for embedded devices</a> proviene da <a rel='\"nofollow\"' href="%5C%22https://eloquentarduino.github.io%5C%22">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "When working with memory constrained devices you may not able to keep all the training data in memory: passive-aggressive classifiers may help solve your memory problems.\n\nBatch learning\nA couple weeks ago I started exploring the possibility to train a machine learning classifier directly on a microcontroller. Since I like SVM, I ported the simplified SVM SMO (Sequential Minimal Optimization) algorithm to plain C, ready to be deployed to embedded devices.\nNow, that kind of algorithm works in the so-called "batch-mode": it needs all the training data to be available in memory to learn.\nThis may be a limiting factor on resource-constrained devices, since it poses an upper bound to the number of samples you can train on. And when working with high-dimensional datasets, the number of samples could be not enough to achieve good accuracy.\nEnter incremental learning\nTo solve this limitation, you need a totally different kind of learning algorithms: you need incremental (a.k.a online a.k.a out of core) learning.\nIncremental learning works by inspecting one training sample at a time, instead of all at once.\nThe clear advantage is that you have a tiny memory footprint. And this is a huge advantage.\nThe clear disadvantage is that you don't have the "big picture" of your data, so:\n\nthe end result will probably be affected by the order of presentation of the samples\nyou may not be able to achieve top accuracy\n\nPassive-aggressive classifier\nPassive-aggressive classification is one of the available incremental learning algorithms and it is very simple to implement, since it has a closed-form update rule.\nPlease refer to this short explanation on Passive-aggressive classifiers for a nice description with images.\nThe core concept is that the classifier adjusts it weight vector for each mis-classified training sample it receives, trying to get it correct.\n\nBenchmarks\nI run a couple benchmark on my Esp32 to assess both accuracy and training time.\nFirst of all: it is fast!. When I say it is fast I mean it takes ~1ms to train on 400 samples x 30 features each.\nTalking about accuracy instead... Uhm...\nAccuracy vary. Greatly. \nYou can achieve 100% on some datasets. \nAnd 40% on others. But on those same datasets you can achieve >85% if training on a different number of samples. Or in a different order.\nI guess this is the tradeoff for such a simple and space-efficient algorithm.\nI report my results in the following table. It is not meant to be an exhaustive benchmark of the classifier, since those number will vary based on the order of presentation, but still you can get an idea of what it is able to achieve.\n\n\n\nDataset size\nTrain samples\nAccuracy\n\n\n\n\nBREAST CANCER\n\n\n\n\n567 samples\n20\n62\n\n\n30 features\n40\n37\n\n\n\n60\n63\n\n\n\n100\n39\n\n\n\n150\n38\n\n\n\n200\n64\n\n\n\n250\n61\n\n\n\n300\n69\n\n\n\n350\n73\n\n\n\n400\n85\n\n\nIRIS\n\n\n\n\n100 samples\n10\n50\n\n\n4 features\n20\n51\n\n\n\n40\n100\n\n\n\n60\n100\n\n\n\n80\n100\n\n\nDIGITS\n\n\n\n\n358 samples\n20\n98\n\n\n64 features\n40\n98\n\n\n\n60\n99\n\n\n\n100\n100\n\n\n\n150\n100\n\n\n\n200\n99\n\n\n\n250\n98\n\n\n\n300\n95\n\n\nCLEVELAND HEART DISEASE\n\n\n\n\n212 samples\n20\n76\n\n\n13 features\n40\n24\n\n\n\n60\n77\n\n\n\n100\n19\n\n\n\n120\n82\n\n\n\n140\n78\n\n\n\n180\n88\n\n\n\nTime to code\nHere I'll report an extract of the example code you can find on Github for this classifier.\n#include <EloquentPassiveAggressiveClassifier.h>\n#include <EloquentAccuracyScorer.h>\n#include "iris.h"\n\nusing namespace Eloquent::ML;\n\nvoid loop() {\n    int trainSamples;\n    PassiveAggressiveClassifier<FEATURES_DIM> clf;\n    AccuracyScorer scorer;\n\n    trainSamples = readSerialNumber("How many samples will you use as training?", DATASET_SIZE - 2);\n\n    if (trainSamples == 0)\n        return;\n\n    clf.setC(1);\n\n    // train\n    for (uint16_t i = 0; i < trainSamples; i++)\n        clf.fitOne(X[i], y[i]);\n\n    // predict\n    for (uint16_t i = trainSamples; i < DATASET_SIZE; i++) {\n        int predicted = clf.predict(X[i]);\n        int actual = y[i] > 0 ? 1 : -1;\n\n        scorer.scoreOne(actual, predicted);\n    }\n\n    Serial.print("Accuracy: ");\n    Serial.print(round(100 * scorer.accuracy()));\n    Serial.print("% out of ");\n    Serial.print(scorer.support());\n    Serial.println(" predictions");\n}\n\nOn the project page you will find the code to reproduce these numbers.\n\nL'articolo Passive-aggressive classifier for embedded devices proviene da Eloquent Arduino Blog.",
            "date_published": "2020-04-05T19:04:10+02:00",
            "date_modified": "2020-04-07T09:31:22+02:00",
            "authors": [
                {
                    "name": "simone",
                    "url": "https://eloquentarduino.github.io/author/simone/",
                    "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
                }
            ],
            "tags": [
                "Senza categoria"
            ]
        }
    ]
}</body></html>
