{
    "version": "https://jsonfeed.org/version/1",
    "user_comment": "This feed allows you to read the posts from this site in any feed reader that supports the JSON Feed format. To add this feed to your reader, copy the following URL -- https://eloquentarduino.github.io/feed/json/ -- and add it your reader.",
    "home_page_url": "https://eloquentarduino.github.io/",
    "feed_url": "https://eloquentarduino.github.io/feed/json/",
    "title": "Eloquent Arduino Blog",
    "description": "A blog about Arduino, programming &amp; electronics",
    "items": [
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-do-gesture-identification-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-do-gesture-identification-on-arduino/",
            "title": "How to do Gesture identification through machine learning on Arduino",
            "content_html": "<p>In this Arduno Machine learning project we're going to use an accelerometer sensor to identify the gestures you play.<br />\nThis is a remake of the project found on the <a href=\"https://blog.tensorflow.org/2019/11/how-to-get-started-with-machine.html\">Tensorflow blog</a>. We're going to use a lot less powerful chip in this tutorial, tough: an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.</p>\n<p><span id=\"more-35\"></span></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: repeat each gesture a few times and save the values from the serial monitor to a file, one for each gesture</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h2>1. Features definition</h2>\n<p>We're going to use the accelerations along the 3 axis (X, Y, Z) coming from an <a href=\"https://en.wikipedia.org/wiki/Inertial_measurement_unit\">IMU</a> to infer which gesture we're playing. We'll use a fixed number of recordings (<code>NUM_SAMPLES</code>) starting from the first detection of movement. </p>\n<p>This means our feature vectors are going to be of dimension <code>3 * NUM_SAMPLES</code>, which can become too large to fit in the memory of the Arduino Nano. We'll start with a low value for <code>NUM_SAMPLES</code> to keep it as leaner as possible: if your classifications suffer from poor accuracy, you can increase this number.</p>\n<h3>2. Record sample data</h3>\n<h4>2.1 Read the IMU sensor</h4>\n<p>First of all, we need to read the raw data from the IMU. This piece of code will be different based on the specific chip you use. To keep things consistent, we'll wrap the IMU logic in 2 functions: <code>imu_setup</code> and <code>imu_read</code>. </p>\n<p>I'll report a couple of example implementations for the <code>MPU6050</code> and the <code>MPU9250</code> (these are the chip I have at hand). You should save whichever code you use in a file called <code>imu.h</code>. </p>\n<pre><code class=\"language-cpp\">#include &quot;Wire.h&quot;\n// library from https://github.com/jrowberg/i2cdevlib/tree/master/Arduino/MPU6050\n#include &quot;MPU6050.h&quot;\n#define OUTPUT_READABLE_ACCELGYRO\n\nMPU6050 imu;\n\nvoid imu_setup() {\n    Wire.begin();\n    imu.initialize();\n}\n\nvoid imu_read(float *ax, float *ay, float *az) {\n    float gx, gy, gz;\n\n    imu.getMotion6(&amp;ax, &amp;ay, &amp;az, &amp;gx, &amp;gy, &amp;gz);\n}</code></pre>\n<pre><code class=\"language-cpp\">#include &quot;Wire.h&quot;\n// library from https://github.com/bolderflight/MPU9250\n#include &quot;MPU9250.h&quot;\n\nMPU9250 imu(Wire, 0x68);\n\nvoid imu_setup() {\n    Wire.begin();\n    imu.begin();\n}\n\nvoid imu_read(float *ax, float *ay, float *az) {\n    imu.readSensor();\n\n    *ax = imu.getAccelX_mss();\n    *ay = imu.getAccelY_mss();\n    *az = imu.getAccelZ_mss();\n}</code></pre>\n<p>In the main .ino file, we dump the values to Serial monitor / plotter.</p>\n<pre><code class=\"language-cpp\">#include &quot;imu.h&quot;\n\n#define NUM_SAMPLES 30\n#define NUM_AXES 3\n// sometimes you may get &quot;spikes&quot; in the readings\n// set a sensible value to truncate too large values\n#define TRUNCATE_AT 20\n\ndouble features[NUM_SAMPLES * NUM_AXES];\n\nvoid setup() {\n    Serial.begin(115200);\n    imu_setup();\n}\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax, -TRUNCATE_AT, TRUNCATE_AT);\n    ay = constrain(ay, -TRUNCATE_AT, TRUNCATE_AT);\n    az = constrain(az, -TRUNCATE_AT, TRUNCATE_AT);\n\n    Serial.print(ax);\n    Serial.print(&#039;\\t&#039;);\n    Serial.print(ay);\n    Serial.print(&#039;\\t&#039;);\n    Serial.println(az);\n}</code></pre>\n<p>Open the Serial plotter and make some movement to have an idea of the range of your readings.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Raw-gestures.gif&quot;\" alt=\"Raw IMU readings for the gestures identification project\" /></p>\n<h4>2.2 Calibration</h4>\n<p>Don't know if it's just my case, but I'm getting <code>az</code> values of about -10 at rest (you can see this in the previous image). Since I'd like to have almost 0 at rest, I created a super simple calibration procedure to remove this fixed offset from the readings.</p>\n<p>If you're already getting all zeros, you can skip this part. Still, if you add it to your project it won't hurt.</p>\n<pre><code class=\"language-cpp\">double baseline[NUM_AXES];\ndouble features[NUM_SAMPLES * NUM_AXES];\n\nvoid setup() {\n    Serial.begin(115200);\n    imu_setup();\n    calibrate();\n}\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n}\n\nvoid calibrate() {\n    float ax, ay, az;\n\n    for (int i = 0; i &lt; 10; i++) {\n        imu_read(&amp;ax, &amp;ay, &amp;az);\n        delay(100);\n    }\n\n    baseline[0] = ax;\n    baseline[1] = ay;\n    baseline[2] = az;\n}</code></pre>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Calibrated-gestures.gif\" alt=\"Calibrated IMU readings for the gestures identification project\" /></p>\n<p>Much better.</p>\n<h4>2.3 Detect first motion</h4>\n<p>Now we need to check if motion is happening. To keep it simple, we'll use a naive approach that will look for an high value in the acceleration: if a threshold is exceeded, a gesture is starting. </p>\n<p>If you did the calibration step, a threshold of 5 should work well. If you didn't calibrate, you have to come up with a value that suits your needs.</p>\n<pre><code class=\"language-cpp\">#include imu.h\n\n#define ACCEL_THRESHOLD 5\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n}\n\nbool motionDetected(float ax, float ay, float az) {\n    return (abs(ax) + abs(ay) + abs(az)) &gt; ACCEL_THRESHOLD;\n}</code></pre>\n<h4>2.4 Record features</h4>\n<p>If no motion is happening, we don't take any action and keep watching. If motion is happening, we print the next <code>NUM_SAMPLES</code> readings to Serial. </p>\n<pre><code class=\"language-cpp\">void loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n\n    recordIMU();\n    printFeatures();\n    delay(2000);\n}\n\nvoid recordIMU() {\n    float ax, ay, az;\n\n    for (int i = 0; i &lt; NUM_SAMPLES; i++) {\n        imu_read(&amp;ax, &amp;ay, &amp;az);\n\n        ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n        ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n        az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n        features[i * NUM_AXES + 0] = ax;\n        features[i * NUM_AXES + 1] = ay;\n        features[i * NUM_AXES + 2] = az;\n\n        delay(INTERVAL);\n    }\n}</code></pre>\n<pre><code class=\"language-cpp\">\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n</code></pre>\n<p>Record 15-20 samples for each geasture and save them to a file, one for each gesture. Since we're dealing with highly dimensional data, you should collect as much samples as possible, to average out the noise.</p>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<p>In this project on Machine learning, differently from the previous and simpler ones, we're not achieving 100% accuracy easily. Motion is quite noise, so you should experiment with a few params for the classifier and choose the ones that perform best. I'll showcase a few examples:</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Gestures-features-Linear-kernel.svg\" alt=\"Decision boundaries of 2 PCA components of Gestures features, Linear kernel, 95% accuracy\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Gestures-features-Polynomial-kernel.svg\" alt=\"Decision boundaries of 2 PCA components of Gestures features, Polynomial kernel, 97% accuracy\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Gestures-features-RBF-kernel-0.01-gamma.svg\" alt=\"Decision boundaries of 2 PCA components of Gestures features, RBF kernel, 0.01 gamma, 95% accuracy\" /></p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Gestures-features-RBF-kernel-0.001-gamma.svg\" alt=\"Decision boundaries of 2 PCA components of Gestures features, RBF kernel, 0.001 gamma, 99% accuracy\" /></p>\n<h4>Select a suitable model</h4>\n<p>Now that we selected the best model, we have to export it to C code. Here comes the culprit: not all models will fit on your board.</p>\n<p>The core of SVM (Support Vector Machines) are support vectors: each trained classifier will be characterized by a certain number of them. The problem is: if there're too much, the generated code will be too large to fit in your flash.</p>\n<p>For this reason, instead of selecting <em>the best</em> model on accuracy, you should make a ranking, from the best performing to the worst. For each model, starting from the top, you should import it in your Arduino project and try to compile: if it fits, fine, you're done. Otherwise you should pick the next and try again.</p>\n<p>It may seem a tedious process, but keep in mind that we're trying to infer a class from 90 features in 2 Kb of RAM and 32 Kb of flash: I think this is an acceptable tradeoff.</p>\n<hr /><p><em>We&#039;re fitting a model to infer a class from 90 features in 2 Kb of RAM and 32 Kb of flash!</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F12%2Fhow-to-do-gesture-identification-on-arduino%2F&#038;text=We%27re%20fitting%20a%20model%20to%20infer%20a%20class%20from%2090%20features%20in%202%20Kb%20of%20RAM%20and%2032%20Kb%20of%20flash%21&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>I'll report a few figures for different combinations I tested.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">Kernel</th>\n<th style=\"text-align: center;\">C</th>\n<th style=\"text-align: center;\">Gamma</th>\n<th style=\"text-align: center;\">Degree</th>\n<th style=\"text-align: center;\">Vectors</th>\n<th style=\"text-align: center;\">Flash size</th>\n<th style=\"text-align: center;\">RAM (b)</th>\n<th style=\"text-align: center;\">Avg accuracy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">RBF</td>\n<td style=\"text-align: center;\">10</td>\n<td style=\"text-align: center;\">0.001</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">37</td>\n<td style=\"text-align: center;\">53 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">99%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\"><strong>Poly</strong></td>\n<td style=\"text-align: center;\"><strong>100</strong></td>\n<td style=\"text-align: center;\"><strong>0.001</strong></td>\n<td style=\"text-align: center;\"><strong>2</strong></td>\n<td style=\"text-align: center;\"><strong>12</strong></td>\n<td style=\"text-align: center;\"><strong>25 Kb</strong></td>\n<td style=\"text-align: center;\"><strong>1228</strong></td>\n<td style=\"text-align: center;\"><strong>99%</strong></td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Poly</td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: center;\">0.001</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">25</td>\n<td style=\"text-align: center;\">40 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">97%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Linear</td>\n<td style=\"text-align: center;\">50</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">1</td>\n<td style=\"text-align: center;\">40</td>\n<td style=\"text-align: center;\">55 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">95%</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">RBF</td>\n<td style=\"text-align: center;\">100</td>\n<td style=\"text-align: center;\">0.01</td>\n<td style=\"text-align: center;\">-</td>\n<td style=\"text-align: center;\">61</td>\n<td style=\"text-align: center;\">80 Kb</td>\n<td style=\"text-align: center;\">1228</td>\n<td style=\"text-align: center;\">95%</td>\n</tr>\n</tbody>\n</table>\n<p>As you can see, we achieved a very high accuracy on the test set for all the classifiers: only one, though, fitted on the Arduino Nano. Of course, if you use a larger board, you can deploy the others too.</p>\n<div class=\"infobox\">As a side note, take a look at the <code>RAM</code> column: all the values are equal: this is because in the implementation is independant from the number of support vectors and only depends on the number of features.</div>\n<h3>3. Run the inference</h3>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n\n    recordIMU();\n    classify();\n    delay(2000);\n}\n\nvoid classify() {\n    Serial.print(&quot;Detected gesture: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}</code></pre>\n<p>Here we are: it has been a long post, but now you can classify gestures with an Arduino Nano and 2 Kb of RAM. </p>\n<hr /><p><em>No fancy Neural Networks, no Tensorflow, no 32-bit ARM processors: plain old SVM on plain old 8 bits with 97% accuracy.</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F12%2Fhow-to-do-gesture-identification-on-arduino%2F&#038;text=No%20fancy%20Neural%20Networks%2C%20no%20Tensorflow%2C%20no%2032-bit%20ARM%20processors%3A%20plain%20old%20SVM%20on%20plain%20old%208%20bits%20with%2097%25%20accuracy.&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>Here's a short demo of me playing 3 gestures and getting the results on the serial monitor.</p>\n<div style=\"width: 640px;\" class=\"wp-video\"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->\n<video class=\"wp-video-shortcode\" id=\"video-35-1\" width=\"640\" height=\"360\" preload=\"metadata\" controls=\"controls\"><source type=\"video/mp4\" src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4?_=1\" /><a href=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4\">https://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4</a></video></div>\n<p><h4>Project figures</h4>\r\n<p>On my machine, the sketch targeted at the Arduino Nano (old generation) requires 25310 bytes (82%) of program space and 1228 bytes (59%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question <em>Can I run machine learning on Arduino?</em> is <strong>definetly YES</strong>.<br />\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlGestureIdentificationExample/MicromlGestureIdentificationExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-do-gesture-identification-on-arduino/\">How to do Gesture identification through machine learning on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this Arduno Machine learning project we're going to use an accelerometer sensor to identify the gestures you play.\nThis is a remake of the project found on the Tensorflow blog. We're going to use a lot less powerful chip in this tutorial, tough: an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: repeat each gesture a few times and save the values from the serial monitor to a file, one for each gesture\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nWe're going to use the accelerations along the 3 axis (X, Y, Z) coming from an IMU to infer which gesture we're playing. We'll use a fixed number of recordings (NUM_SAMPLES) starting from the first detection of movement. \nThis means our feature vectors are going to be of dimension 3 * NUM_SAMPLES, which can become too large to fit in the memory of the Arduino Nano. We'll start with a low value for NUM_SAMPLES to keep it as leaner as possible: if your classifications suffer from poor accuracy, you can increase this number.\n2. Record sample data\n2.1 Read the IMU sensor\nFirst of all, we need to read the raw data from the IMU. This piece of code will be different based on the specific chip you use. To keep things consistent, we'll wrap the IMU logic in 2 functions: imu_setup and imu_read. \nI'll report a couple of example implementations for the MPU6050 and the MPU9250 (these are the chip I have at hand). You should save whichever code you use in a file called imu.h. \n#include &quot;Wire.h&quot;\n// library from https://github.com/jrowberg/i2cdevlib/tree/master/Arduino/MPU6050\n#include &quot;MPU6050.h&quot;\n#define OUTPUT_READABLE_ACCELGYRO\n\nMPU6050 imu;\n\nvoid imu_setup() {\n    Wire.begin();\n    imu.initialize();\n}\n\nvoid imu_read(float *ax, float *ay, float *az) {\n    float gx, gy, gz;\n\n    imu.getMotion6(&amp;ax, &amp;ay, &amp;az, &amp;gx, &amp;gy, &amp;gz);\n}\n#include &quot;Wire.h&quot;\n// library from https://github.com/bolderflight/MPU9250\n#include &quot;MPU9250.h&quot;\n\nMPU9250 imu(Wire, 0x68);\n\nvoid imu_setup() {\n    Wire.begin();\n    imu.begin();\n}\n\nvoid imu_read(float *ax, float *ay, float *az) {\n    imu.readSensor();\n\n    *ax = imu.getAccelX_mss();\n    *ay = imu.getAccelY_mss();\n    *az = imu.getAccelZ_mss();\n}\nIn the main .ino file, we dump the values to Serial monitor / plotter.\n#include &quot;imu.h&quot;\n\n#define NUM_SAMPLES 30\n#define NUM_AXES 3\n// sometimes you may get &quot;spikes&quot; in the readings\n// set a sensible value to truncate too large values\n#define TRUNCATE_AT 20\n\ndouble features[NUM_SAMPLES * NUM_AXES];\n\nvoid setup() {\n    Serial.begin(115200);\n    imu_setup();\n}\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax, -TRUNCATE_AT, TRUNCATE_AT);\n    ay = constrain(ay, -TRUNCATE_AT, TRUNCATE_AT);\n    az = constrain(az, -TRUNCATE_AT, TRUNCATE_AT);\n\n    Serial.print(ax);\n    Serial.print(&#039;\\t&#039;);\n    Serial.print(ay);\n    Serial.print(&#039;\\t&#039;);\n    Serial.println(az);\n}\nOpen the Serial plotter and make some movement to have an idea of the range of your readings.\n\n2.2 Calibration\nDon't know if it's just my case, but I'm getting az values of about -10 at rest (you can see this in the previous image). Since I'd like to have almost 0 at rest, I created a super simple calibration procedure to remove this fixed offset from the readings.\nIf you're already getting all zeros, you can skip this part. Still, if you add it to your project it won't hurt.\ndouble baseline[NUM_AXES];\ndouble features[NUM_SAMPLES * NUM_AXES];\n\nvoid setup() {\n    Serial.begin(115200);\n    imu_setup();\n    calibrate();\n}\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n}\n\nvoid calibrate() {\n    float ax, ay, az;\n\n    for (int i = 0; i &lt; 10; i++) {\n        imu_read(&amp;ax, &amp;ay, &amp;az);\n        delay(100);\n    }\n\n    baseline[0] = ax;\n    baseline[1] = ay;\n    baseline[2] = az;\n}\n\nMuch better.\n2.3 Detect first motion\nNow we need to check if motion is happening. To keep it simple, we'll use a naive approach that will look for an high value in the acceleration: if a threshold is exceeded, a gesture is starting. \nIf you did the calibration step, a threshold of 5 should work well. If you didn't calibrate, you have to come up with a value that suits your needs.\n#include imu.h\n\n#define ACCEL_THRESHOLD 5\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n}\n\nbool motionDetected(float ax, float ay, float az) {\n    return (abs(ax) + abs(ay) + abs(az)) &gt; ACCEL_THRESHOLD;\n}\n2.4 Record features\nIf no motion is happening, we don't take any action and keep watching. If motion is happening, we print the next NUM_SAMPLES readings to Serial. \nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n\n    recordIMU();\n    printFeatures();\n    delay(2000);\n}\n\nvoid recordIMU() {\n    float ax, ay, az;\n\n    for (int i = 0; i &lt; NUM_SAMPLES; i++) {\n        imu_read(&amp;ax, &amp;ay, &amp;az);\n\n        ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n        ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n        az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n        features[i * NUM_AXES + 0] = ax;\n        features[i * NUM_AXES + 1] = ay;\n        features[i * NUM_AXES + 2] = az;\n\n        delay(INTERVAL);\n    }\n}\n\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n\nRecord 15-20 samples for each geasture and save them to a file, one for each gesture. Since we're dealing with highly dimensional data, you should collect as much samples as possible, to average out the noise.\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\nIn this project on Machine learning, differently from the previous and simpler ones, we're not achieving 100% accuracy easily. Motion is quite noise, so you should experiment with a few params for the classifier and choose the ones that perform best. I'll showcase a few examples:\n\n\n\n\nSelect a suitable model\nNow that we selected the best model, we have to export it to C code. Here comes the culprit: not all models will fit on your board.\nThe core of SVM (Support Vector Machines) are support vectors: each trained classifier will be characterized by a certain number of them. The problem is: if there're too much, the generated code will be too large to fit in your flash.\nFor this reason, instead of selecting the best model on accuracy, you should make a ranking, from the best performing to the worst. For each model, starting from the top, you should import it in your Arduino project and try to compile: if it fits, fine, you're done. Otherwise you should pick the next and try again.\nIt may seem a tedious process, but keep in mind that we're trying to infer a class from 90 features in 2 Kb of RAM and 32 Kb of flash: I think this is an acceptable tradeoff.\nWe&#039;re fitting a model to infer a class from 90 features in 2 Kb of RAM and 32 Kb of flash!Click To Tweet\nI'll report a few figures for different combinations I tested.\n\n\n\nKernel\nC\nGamma\nDegree\nVectors\nFlash size\nRAM (b)\nAvg accuracy\n\n\n\n\nRBF\n10\n0.001\n-\n37\n53 Kb\n1228\n99%\n\n\nPoly\n100\n0.001\n2\n12\n25 Kb\n1228\n99%\n\n\nPoly\n100\n0.001\n3\n25\n40 Kb\n1228\n97%\n\n\nLinear\n50\n-\n1\n40\n55 Kb\n1228\n95%\n\n\nRBF\n100\n0.01\n-\n61\n80 Kb\n1228\n95%\n\n\n\nAs you can see, we achieved a very high accuracy on the test set for all the classifiers: only one, though, fitted on the Arduino Nano. Of course, if you use a larger board, you can deploy the others too.\nAs a side note, take a look at the RAM column: all the values are equal: this is because in the implementation is independant from the number of support vectors and only depends on the number of features.\n3. Run the inference\n#include &quot;model.h&quot;\n\nvoid loop() {\n    float ax, ay, az;\n\n    imu_read(&amp;ax, &amp;ay, &amp;az);\n\n    ax = constrain(ax - baseline[0], -TRUNCATE, TRUNCATE);\n    ay = constrain(ay - baseline[1], -TRUNCATE, TRUNCATE);\n    az = constrain(az - baseline[2], -TRUNCATE, TRUNCATE);\n\n    if (!motionDetected(ax, ay, az)) {\n        delay(10);\n        return;\n    }\n\n    recordIMU();\n    classify();\n    delay(2000);\n}\n\nvoid classify() {\n    Serial.print(&quot;Detected gesture: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}\nHere we are: it has been a long post, but now you can classify gestures with an Arduino Nano and 2 Kb of RAM. \nNo fancy Neural Networks, no Tensorflow, no 32-bit ARM processors: plain old SVM on plain old 8 bits with 97% accuracy.Click To Tweet\nHere's a short demo of me playing 3 gestures and getting the results on the serial monitor.\n\nhttps://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4\nProject figures\r\nOn my machine, the sketch targeted at the Arduino Nano (old generation) requires 25310 bytes (82%) of program space and 1228 bytes (59%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question Can I run machine learning on Arduino? is definetly YES.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo How to do Gesture identification through machine learning on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-19T14:25:46+01:00",
            "date_modified": "2019-12-20T07:41:36+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ],
            "attachments": [
                [
                    {
                        "url": "https://eloquentarduino.github.io/wp-content/uploads/2019/12/Gesture-identification-in-action.mp4",
                        "mime_type": "video/mp4",
                        "size_in_bytes": 1035484
                    }
                ]
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/arduino-pin-class/",
            "url": "https://eloquentarduino.github.io/2019/12/arduino-pin-class/",
            "title": "Eloquent pin management: the Pin class",
            "content_html": "<p><code>Pin</code> is a class for pin manipulation: you can read, write, turnOn, turnOff, toggle and a lot more. Please, stop writing horrible code like <code>digitalWrite(led, HIGH)</code> and start writing <code>led.turnOn()</code> instead. </p>\n<p><span id=\"more-167\"></span></p>\n<p><code>Pin</code> is actually an abstract class, so you won't use it directly, but through its specialized implementations:</p>\n<ol>\n<li>DigitalIn</li>\n<li>DigitalOut</li>\n<li>AnalogIn</li>\n<li>AnalogOut</li>\n</ol>\n<h2>Import the library</h2>\n<div class=\"watchout\">To follow this tutorial along you need to first <a href=\"/2019/12/how-to-install-the-eloquent-library/\" target=\"_blank\">install the Eloquent library</a></div>\n<pre><code class=\"language-cpp\">#import &lt;eIO.h&gt;\n\nusing namespace Eloquent::Pin;</code></pre>\n<p>If the namespace stuff is new to you, here I'll briefly say that it is used to avoid name collisions among different libraries. This seems to be an alien topic in the Arduino world and I can't really explain why.</p>\n<p>99% of the libraries out there deal with this problem in one of two modes:</p>\n<ol>\n<li>ignoring it altogether, so you have an <code>MPU6050.h</code> library, which elects itself as the only one implementation possible to access the MPU6050 accelerometer in the world</li>\n<li>prefixing each library file, so you get the <code>Adafruit_Si7021</code> class</li>\n</ol>\n<hr /><p><em>The case for Adafruit_Si7021 should not exist in my opinion: use the damn namespaces!</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F12%2Farduino-pin-class%2F&#038;text=The%20case%20for%20Adafruit_Si7021%20should%20not%20exist%20in%20my%20opinion%3A%20use%20the%20damn%20namespaces%21&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>With namespaces, it would become:</p>\n<pre><code class=\"language-cpp\">using namespace Adafruit;\n\nSi7021 si;</code></pre>\n<h2>How to use</h2>\n<p>First of all, all the 4 implementations accept a single constructor argument: the pin number.</p>\n<pre><code class=\"language-cpp\"> DigitalOut led(BUILTIN_LED);\n DigitalIn pushButton(10);\n AnalogIn potentiometer(A0);\n AnalogOut pwmLed(8);</code></pre>\n<p>Then it is good practice to init your pins in the setup.</p>\n<pre><code class=\"language-cpp\"> void setup() {\n    led.begin();\n    pushButton.begin();\n    potentiometer.begin();\n    pwmLed.begin();\n }</code></pre>\n<p>All the 4 classes let you ask for the pin current value via the <code>value()</code> method:</p>\n<pre><code class=\"language-cpp\"> void test() {\n    // DigitalIn returns the last read value, as 0/1\n    digitalIn.value();\n\n    // AnalogIn returns the last read value, in the range [0, 1024]\n    analogIn.value();\n\n    // DigitalOut returns the last written value, as 0/1\n    digitalOut.value();\n\n    // AnaloglOut returns the last written value, in the range [0, 255]\n    analogOut.value();\n }</code></pre>\n<p>At this point each class will provide its specialized methods.</p>\n<h4>DigitalIn</h4>\n<pre><code class=\"language-cpp\">void test() {\n    // configure pin as INPUT_PULLUP\n    pin.pullup();\n\n    // configure pin as Active Low \n    // that is, pin is ON when digitalRead() is LOW\n    pin.activeLow();\n\n    // read and update pin value\n    pin.read();\n\n    // test if pin is on (doesn&#039;t read the pin)\n    pin.isOn();\n\n    // test if pin is off (doesn&#039;t read the pin)\n    pin.isOff();\n\n    // test if pin value changed from last reading\n    pin.changed();\n}</code></pre>\n<h4>DigitalOut</h4>\n<pre><code class=\"language-cpp\">void test() {\n    // set pin as Active Low\n    // that is, turnOn writes LOW\n    pin.activeLow();\n\n    // turn pin on\n    pin.turnOn();\n\n    // turn pin off\n    pin.turnOff();\n\n    // toggle\n    pin.toggle();\n\n    // blink N times at intervals of X milliseconds\n    pin.blink(N, X);\n}</code></pre>\n<h4>AnalogIn</h4>\n<pre><code class=\"language-cpp\">void test() {\n    // read current pin value\n    pin.read();\n\n    // get pin previous value\n    pin.prev();\n\n    // get difference between current value and previous\n    pin.delta();\n\n    // get absolute value of delta()\n    pin.absDelta();\n}</code></pre>\n<h4>AnalogOut</h4>\n<pre><code class=\"language-cpp\">void test() {\n    // write value X to pin\n    pin.write(X);\n}</code></pre>\n<hr />\n<p>If you don't believe a whole class is worthwhile to work with pins, I'll show a few use cases to illustrate my point.</p>\n<h4>Use case #1: active low LED</h4>\n<p>The ESP8266 has a builtin LED you can control, but it is an <em>active low</em> one: it will turn on when you write <code>LOW</code>. In this case, <code>digitalWrite(BUILTIN_LED, LOW)</code> can be misleading regarding your actual intentions. </p>\n<p>It doesn't look intuitive,  it doesn't look <em>eloquent</em>! <code>builtinLed.turnOn()</code> does, however. All you need to get it working correctly is calling <code>builtinLed.activeLow()</code> once in your setup.</p>\n<pre><code class=\"language-cpp\">// BEFORE\nvoid loop() {\n    // to turn the builtin LED on\n    digitalWrite(led, LOW);\n}</code></pre>\n<pre><code class=\"language-cpp\">// AFTER\nDigitalOut buildtinLed;\n\nvoid setup() {\n    builtinLed.activeLow();\n}\n\nvoid loop() {\n    // to turn the builtin LED on\n    builtinLed.turnOn();\n}</code></pre>\n<h4>Use case #2: toggle</h4>\n<p>If you need to toggle the current state of a digital output, you need an helper variable to keep track of the state and remember to <strong>always</strong> update that variable when you write to the output.<br />\nWith a class, the state is tightly bound to the instance, so you have a <a href=\"https://en.wikipedia.org/wiki/Single_source_of_truth\">single source of truth</a>: <code>turnOn()</code>, <code>turnOff()</code> and <code>toggle()</code> will take care of updating the inner state accordingly.</p>\n<pre><code class=\"language-cpp\">// BEFORE\n#define LED 1\n\nbool ledState = true;\n\nloop() {\n    digitalWrite(LED, ledState);\n    ledState = !ledState\n}</code></pre>\n<pre><code class=\"language-cpp\">// AFTER\nDigitalOut led(1);\n\nvoid loop() {\n    led.toggle();\n}</code></pre>\n<h4>Use case #3: analog delta</h4>\n<p>What if you have an analog input and want to know if its valued changed by at least X from your latest reading? You would need an helper variable again. </p>\n<p>Now imagine if you have 5 analog inputs you want to track: you'll end up with 10 variables and of course you have again to <strong>always</strong> keep both in sync.<br />\n<code>AnalogIn</code> conveniently provides <code>delta()</code> and <code>absDelta()</code> methods that give you the change from the previous reading and will always be in sync. Awesome!</p>\n<pre><code class=\"language-cpp\">// BEFORE\n#define INPUT1 A1\n#define INPUT2 A2\n\nuint16_t current1, prev1;\nuint16_t current2, prev2;\n\nvoid loop() {\n    prev1 = current1;\n    current1 = analogRead(INPUT1);\n    prev2 = current2;\n    current2 = analogRead(INPUT2);\n\n    if (abs(current1 - prev1) &gt; THRESHOLD)\n        ...</code></pre>\n<pre><code class=\"language-cpp\">// AFTER\nAnalogIn input1(A1), input2(A2);\n\nvoid loop() {\n    input1.read();\n    input2.read();\n\n    if (input1.absDelta() &gt; THRESHOLD)\n        ...\n}</code></pre>\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/arduino-pin-class/\">Eloquent pin management: the Pin class</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "Pin is a class for pin manipulation: you can read, write, turnOn, turnOff, toggle and a lot more. Please, stop writing horrible code like digitalWrite(led, HIGH) and start writing led.turnOn() instead. \n\nPin is actually an abstract class, so you won't use it directly, but through its specialized implementations:\n\nDigitalIn\nDigitalOut\nAnalogIn\nAnalogOut\n\nImport the library\nTo follow this tutorial along you need to first install the Eloquent library\n#import &lt;eIO.h&gt;\n\nusing namespace Eloquent::Pin;\nIf the namespace stuff is new to you, here I'll briefly say that it is used to avoid name collisions among different libraries. This seems to be an alien topic in the Arduino world and I can't really explain why.\n99% of the libraries out there deal with this problem in one of two modes:\n\nignoring it altogether, so you have an MPU6050.h library, which elects itself as the only one implementation possible to access the MPU6050 accelerometer in the world\nprefixing each library file, so you get the Adafruit_Si7021 class\n\nThe case for Adafruit_Si7021 should not exist in my opinion: use the damn namespaces!Click To Tweet\nWith namespaces, it would become:\nusing namespace Adafruit;\n\nSi7021 si;\nHow to use\nFirst of all, all the 4 implementations accept a single constructor argument: the pin number.\n DigitalOut led(BUILTIN_LED);\n DigitalIn pushButton(10);\n AnalogIn potentiometer(A0);\n AnalogOut pwmLed(8);\nThen it is good practice to init your pins in the setup.\n void setup() {\n    led.begin();\n    pushButton.begin();\n    potentiometer.begin();\n    pwmLed.begin();\n }\nAll the 4 classes let you ask for the pin current value via the value() method:\n void test() {\n    // DigitalIn returns the last read value, as 0/1\n    digitalIn.value();\n\n    // AnalogIn returns the last read value, in the range [0, 1024]\n    analogIn.value();\n\n    // DigitalOut returns the last written value, as 0/1\n    digitalOut.value();\n\n    // AnaloglOut returns the last written value, in the range [0, 255]\n    analogOut.value();\n }\nAt this point each class will provide its specialized methods.\nDigitalIn\nvoid test() {\n    // configure pin as INPUT_PULLUP\n    pin.pullup();\n\n    // configure pin as Active Low \n    // that is, pin is ON when digitalRead() is LOW\n    pin.activeLow();\n\n    // read and update pin value\n    pin.read();\n\n    // test if pin is on (doesn&#039;t read the pin)\n    pin.isOn();\n\n    // test if pin is off (doesn&#039;t read the pin)\n    pin.isOff();\n\n    // test if pin value changed from last reading\n    pin.changed();\n}\nDigitalOut\nvoid test() {\n    // set pin as Active Low\n    // that is, turnOn writes LOW\n    pin.activeLow();\n\n    // turn pin on\n    pin.turnOn();\n\n    // turn pin off\n    pin.turnOff();\n\n    // toggle\n    pin.toggle();\n\n    // blink N times at intervals of X milliseconds\n    pin.blink(N, X);\n}\nAnalogIn\nvoid test() {\n    // read current pin value\n    pin.read();\n\n    // get pin previous value\n    pin.prev();\n\n    // get difference between current value and previous\n    pin.delta();\n\n    // get absolute value of delta()\n    pin.absDelta();\n}\nAnalogOut\nvoid test() {\n    // write value X to pin\n    pin.write(X);\n}\n\nIf you don't believe a whole class is worthwhile to work with pins, I'll show a few use cases to illustrate my point.\nUse case #1: active low LED\nThe ESP8266 has a builtin LED you can control, but it is an active low one: it will turn on when you write LOW. In this case, digitalWrite(BUILTIN_LED, LOW) can be misleading regarding your actual intentions. \nIt doesn't look intuitive,  it doesn't look eloquent! builtinLed.turnOn() does, however. All you need to get it working correctly is calling builtinLed.activeLow() once in your setup.\n// BEFORE\nvoid loop() {\n    // to turn the builtin LED on\n    digitalWrite(led, LOW);\n}\n// AFTER\nDigitalOut buildtinLed;\n\nvoid setup() {\n    builtinLed.activeLow();\n}\n\nvoid loop() {\n    // to turn the builtin LED on\n    builtinLed.turnOn();\n}\nUse case #2: toggle\nIf you need to toggle the current state of a digital output, you need an helper variable to keep track of the state and remember to always update that variable when you write to the output.\nWith a class, the state is tightly bound to the instance, so you have a single source of truth: turnOn(), turnOff() and toggle() will take care of updating the inner state accordingly.\n// BEFORE\n#define LED 1\n\nbool ledState = true;\n\nloop() {\n    digitalWrite(LED, ledState);\n    ledState = !ledState\n}\n// AFTER\nDigitalOut led(1);\n\nvoid loop() {\n    led.toggle();\n}\nUse case #3: analog delta\nWhat if you have an analog input and want to know if its valued changed by at least X from your latest reading? You would need an helper variable again. \nNow imagine if you have 5 analog inputs you want to track: you'll end up with 10 variables and of course you have again to always keep both in sync.\nAnalogIn conveniently provides delta() and absDelta() methods that give you the change from the previous reading and will always be in sync. Awesome!\n// BEFORE\n#define INPUT1 A1\n#define INPUT2 A2\n\nuint16_t current1, prev1;\nuint16_t current2, prev2;\n\nvoid loop() {\n    prev1 = current1;\n    current1 = analogRead(INPUT1);\n    prev2 = current2;\n    current2 = analogRead(INPUT2);\n\n    if (abs(current1 - prev1) &gt; THRESHOLD)\n        ...\n// AFTER\nAnalogIn input1(A1), input2(A2);\n\nvoid loop() {\n    input1.read();\n    input2.read();\n\n    if (input1.absDelta() &gt; THRESHOLD)\n        ...\n}\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\nL'articolo Eloquent pin management: the Pin class proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-06T17:15:13+01:00",
            "date_modified": "2019-12-17T17:43:22+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "eloquent",
                "Eloquent library"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-do-morse-alphabet-identification-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-do-morse-alphabet-identification-on-arduino/",
            "title": "How to do Morse alphabet identification through machine learning on Arduino",
            "content_html": "<p>In this Arduno Machine learning project we're going to identify the letters from the <a href=\"https://en.wikipedia.org/wiki/Morse_code\">Morse alphabet</a>.<br />\nIn practice, we'll translate dots (\u2022) and dashes (\u2012)  &quot;typed&quot; with a push button into meaningful characters.<br />\nIn this tutorial we're going to target an Arduino Nano board (old generation), equipped with 32 kb of flash and only 2 kb of RAM.</p>\n<p><span id=\"more-194\"></span></p>\n<p><img src=\"https://i.ytimg.com/vi/L6gxfX4GrbI/maxresdefault.jpg\" alt=\"credits to https://www.youtube.com/watch?v=L6gxfX4GrbI\" /></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: repeat each letter a few times and save the values from the serial monitor to a file, one for each letter.</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h3>1. Features definition</h3>\n<p>For our task we'll use a simple push button as input and a fixed number of samples taken at a fixed interval (100 ms), starting from the first detection of the button press. I chose to record 30 samples for each letter, but you can easily customize the value as per your needs. </p>\n<p>With 30 samples at 100 ms frequency, we'll have 3 seconds to &quot;type&quot; the letter and on the Serial monitor will appear a sequence of 0s and 1s, representing if the button was pressed or not; the inference procedure will translate this sequence into a letter.<br />\nAs a reference, here are a couple example of what we'll be working with.</p>\n<pre><code class=\"language-cpp\">// A (\u2022\u2012)\n0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n\n// D (\u2012\u2022\u2022)\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n\n// E (\u2022)\n0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1</code></pre>\n<h3>2. Record sample data</h3>\n<p>To the bare minimum, we'll need a push button and two wires: one to ground and the other to a digital pin. Since in the example we'll make the button an <code>INPUT_PULLUP</code>, we'll read 0 when the button is pressed and 1 when not.  </p>\n<p><img src=\"https://www.arduino.cc/en/uploads/Tutorial/PullUp_bbd.png\" alt=\"credits to https://www.arduino.cc/en/Tutorial/DigitalInputPullup\" /></p>\n<p>All we need to do is detect a press and record the following 30 samples of the digital pin:</p>\n<pre><code class=\"language-cpp\">#define IN 4\n#define NUM_SAMPLES 30\n#define INTERVAL 100\n\ndouble features[NUM_SAMPLES];\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(IN, INPUT_PULLUP);\n}\n\nvoid loop() {\n  if (digitalRead(IN) == 0) {\n    recordButtonStatus();\n    printFeatures();\n    delay(1000);\n  }\n\n  delay(10);\n}\n\nvoid recordButtonStatus() {\n  for (int i = 0; i &lt; NUM_SAMPLES; i++) {\n    features[i] = digitalRead(IN);\n    delay(INTERVAL);\n  } \n}</code></pre>\n<pre><code class=\"language-cpp\">\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n</code></pre>\n<p>Open the Serial monitor and type a few times each letter: try to introduce some variations each time, for example waiting some more milliseconds before releasing the dash.</p>\n<div class=\"watchout\"> If you've never typed morse code before (as me), choose letters with few keystrokes and quite differentiable, otherwise you will need to be very good with the timing.</div>\n<p>Save the recordings for each letter in a file named after the letter, so you will get meaningful results later on.</p>\n<p>You may end with duplicate recordings: don't worry, that's not a problem. I'll paste my recordings for a few letters, as a reference.</p>\n<pre><code>// A (\u2022\u2012)\n0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1\n\n// D (\u2012\u2022\u2022)\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1\n\n// E (\u2022)\n0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n\n// S (\u2022\u2022\u2022)\n0,0,0,1,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n\n// T (\u2012)\n0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1</code></pre>\n<p>If you do a good job, you should end with quite distinguible features, as show in the plot below.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-from-Morse-alphabet-identification-features.svg\" alt=\"Decision boundaries of 2 PCA components from Morse alphabet identification features\" /></p>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<h3>3. Run the inference</h3>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid loop() {\n  if (digitalRead(IN) == 0) {\n    recordButtonStatus();\n    Serial.print(&quot;Detected letter: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n    delay(1000);\n  }\n\n  delay(10);\n}</code></pre>\n<p>Type some letter using the push button and see the identified value printed on the serial monitor.</p>\n<p>That\u2019s it: you deployed machine learning in 2 Kb! </p>\n<p><h4>Project figures</h4>\r\n<p>On my machine, the sketch targeted at the Arduino Nano (old generation) requires 12546 bytes (40%) of program space and 366 bytes (17%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question <em>Can I run machine learning on Arduino?</em> is <strong>definetly YES</strong>.<br />\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlMorseIdentificationExample/MicromlMorseIdentificationExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-do-morse-alphabet-identification-on-arduino/\">How to do Morse alphabet identification through machine learning on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this Arduno Machine learning project we're going to identify the letters from the Morse alphabet.\nIn practice, we'll translate dots (\u2022) and dashes (\u2012)  &quot;typed&quot; with a push button into meaningful characters.\nIn this tutorial we're going to target an Arduino Nano board (old generation), equipped with 32 kb of flash and only 2 kb of RAM.\n\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: repeat each letter a few times and save the values from the serial monitor to a file, one for each letter.\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nFor our task we'll use a simple push button as input and a fixed number of samples taken at a fixed interval (100 ms), starting from the first detection of the button press. I chose to record 30 samples for each letter, but you can easily customize the value as per your needs. \nWith 30 samples at 100 ms frequency, we'll have 3 seconds to &quot;type&quot; the letter and on the Serial monitor will appear a sequence of 0s and 1s, representing if the button was pressed or not; the inference procedure will translate this sequence into a letter.\nAs a reference, here are a couple example of what we'll be working with.\n// A (\u2022\u2012)\n0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n\n// D (\u2012\u2022\u2022)\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n\n// E (\u2022)\n0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n2. Record sample data\nTo the bare minimum, we'll need a push button and two wires: one to ground and the other to a digital pin. Since in the example we'll make the button an INPUT_PULLUP, we'll read 0 when the button is pressed and 1 when not.  \n\nAll we need to do is detect a press and record the following 30 samples of the digital pin:\n#define IN 4\n#define NUM_SAMPLES 30\n#define INTERVAL 100\n\ndouble features[NUM_SAMPLES];\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(IN, INPUT_PULLUP);\n}\n\nvoid loop() {\n  if (digitalRead(IN) == 0) {\n    recordButtonStatus();\n    printFeatures();\n    delay(1000);\n  }\n\n  delay(10);\n}\n\nvoid recordButtonStatus() {\n  for (int i = 0; i &lt; NUM_SAMPLES; i++) {\n    features[i] = digitalRead(IN);\n    delay(INTERVAL);\n  } \n}\n\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n\nOpen the Serial monitor and type a few times each letter: try to introduce some variations each time, for example waiting some more milliseconds before releasing the dash.\n If you've never typed morse code before (as me), choose letters with few keystrokes and quite differentiable, otherwise you will need to be very good with the timing.\nSave the recordings for each letter in a file named after the letter, so you will get meaningful results later on.\nYou may end with duplicate recordings: don't worry, that's not a problem. I'll paste my recordings for a few letters, as a reference.\n// A (\u2022\u2012)\n0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1\n\n// D (\u2012\u2022\u2022)\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,1,1,1,1\n\n// E (\u2022)\n0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n\n// S (\u2022\u2022\u2022)\n0,0,0,1,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,1,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,1,1,1,1,0,0,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n\n// T (\u2012)\n0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\n0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\nIf you do a good job, you should end with quite distinguible features, as show in the plot below.\n\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\n3. Run the inference\n#include &quot;model.h&quot;\n\nvoid loop() {\n  if (digitalRead(IN) == 0) {\n    recordButtonStatus();\n    Serial.print(&quot;Detected letter: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n    delay(1000);\n  }\n\n  delay(10);\n}\nType some letter using the push button and see the identified value printed on the serial monitor.\nThat\u2019s it: you deployed machine learning in 2 Kb! \nProject figures\r\nOn my machine, the sketch targeted at the Arduino Nano (old generation) requires 12546 bytes (40%) of program space and 366 bytes (17%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question Can I run machine learning on Arduino? is definetly YES.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo How to do Morse alphabet identification through machine learning on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-06T13:07:38+01:00",
            "date_modified": "2019-12-20T07:18:11+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/arduino-bounded-waiting/",
            "url": "https://eloquentarduino.github.io/2019/12/arduino-bounded-waiting/",
            "title": "Eloquent bounded waiting: the await construct",
            "content_html": "<p>Sometimes you may need to wait for a certain condition to become true, but you don't want to wait forever: it may be awaiting for Serial, for the Wifi to connect to a network, or the response from a SoftwareSerial peripheral. The <code>await</code> construct lets you put an upper bound to the time you're willing to wait.</p>\n<p><span id=\"more-211\"></span></p>\n<p>Most often, you see example code of this kind:</p>\n<pre><code class=\"language-cpp\">Serial.print(&quot;Attempting to connect to WiFi&quot;);\n\nwhile (WiFi.status() != WL_CONNECTED) {\n    Serial.print(&quot;.&quot;);\n    delay(500);\n}</code></pre>\n<p>If the connection doesn't succeed (maybe the AP is out of range or is down), you're stuck in an endless wait. A proper way for handling such situations is with a timeout that gets you out of the loop with an error status so you can handle the failure.<br />\n<code>await</code> is exactly this: a construct to await for a condition to become true until a timeout expires, returning true or false as a response.</p>\n<h3>Definition</h3>\n<pre><code class=\"language-cpp\">#define await(condition, timeout) await_with_interval(condition, timeout, 10)\n#define await_with_interval(condition, timeout, interval) \\\n  ([]() { \\\n    uint32_t start = millis(); \\\n    while (millis() - start &lt;= timeout) { \\\n      if (condition) return true; \\\n      delay(interval); \\\n    } \\\n  return false; })()</code></pre>\n<h3>How to use</h3>\n<p><code>await</code> needs at least two arguments:</p>\n<ol>\n<li>the condition to await for</li>\n<li>the timeout, in milliseconds</li>\n</ol>\n<pre><code>// these are for greater code readability\r\n#define Millis \r\n#define Second  *1000\r\n#define Seconds *1000\r\n</code></pre>\n<pre><code class=\"language-cpp\">bool wifiConnected = await(WiFi.status() == WL_CONNECTED, 10 Seconds)</code></pre>\n<p>The code above will wait 10 seconds for the wifi to connect: on failure, <code>wifiConnected</code> will be false and you can gently fail. </p>\n<p>You can use it for any kind of check, like waiting for <code>Serial</code>.</p>\n<pre><code class=\"language-cpp\">bool serialReady = await(Serial, 5 Seconds)\nbool serialHasCharacters = await(Serial.available(), 5 Seconds)</code></pre>\n<p>The default interval between checks is 10 milliseconds: if you need a custom delay interval you can use the more verbose <code>await_with_interval</code>:</p>\n<pre><code class=\"language-cpp\">// await WiFi for 10 seconds, check if connected every 500 millis\nbool wifiConnected = await_with_interval(WiFi.status() == WL_CONNECTED, 10 Seconds, 500 Millis)</code></pre>\n<h3>How it works</h3>\n<p>The <code>await</code> macro creates an <a href=\"http://www.cplusplus.com/articles/2LywvCM9/\">inline function</a> that loops until the timeout expires. At every loop it checks if the condition is true: if that's the case, it returns true. The inline function construct is needed to get a return value, so you can assign it to a variable or embed directly inside an <code>if</code> test. The following code sample gives you an idea of what's happening.</p>\n<pre><code class=\"language-cpp\">bool wifiConnected = await(WiFi.status() == WL_CONNECTED, 10 Seconds)\n\n// conceptually translates to\n\nbool inline_function() {\n    uint32_t start = millis();\n\n    while (millis() - start &lt;= 10000) {\n      if (WiFi.status() == WL_CONNECTED)\n        return true;\n\n      delay(10);\n    }\n\n   return false;\n}\n\nbool wifiConnected = inline_function();</code></pre>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/arduino-bounded-waiting/\">Eloquent bounded waiting: the await construct</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "Sometimes you may need to wait for a certain condition to become true, but you don't want to wait forever: it may be awaiting for Serial, for the Wifi to connect to a network, or the response from a SoftwareSerial peripheral. The await construct lets you put an upper bound to the time you're willing to wait.\n\nMost often, you see example code of this kind:\nSerial.print(&quot;Attempting to connect to WiFi&quot;);\n\nwhile (WiFi.status() != WL_CONNECTED) {\n    Serial.print(&quot;.&quot;);\n    delay(500);\n}\nIf the connection doesn't succeed (maybe the AP is out of range or is down), you're stuck in an endless wait. A proper way for handling such situations is with a timeout that gets you out of the loop with an error status so you can handle the failure.\nawait is exactly this: a construct to await for a condition to become true until a timeout expires, returning true or false as a response.\nDefinition\n#define await(condition, timeout) await_with_interval(condition, timeout, 10)\n#define await_with_interval(condition, timeout, interval) \\\n  ([]() { \\\n    uint32_t start = millis(); \\\n    while (millis() - start &lt;= timeout) { \\\n      if (condition) return true; \\\n      delay(interval); \\\n    } \\\n  return false; })()\nHow to use\nawait needs at least two arguments:\n\nthe condition to await for\nthe timeout, in milliseconds\n\n// these are for greater code readability\r\n#define Millis \r\n#define Second  *1000\r\n#define Seconds *1000\r\n\nbool wifiConnected = await(WiFi.status() == WL_CONNECTED, 10 Seconds)\nThe code above will wait 10 seconds for the wifi to connect: on failure, wifiConnected will be false and you can gently fail. \nYou can use it for any kind of check, like waiting for Serial.\nbool serialReady = await(Serial, 5 Seconds)\nbool serialHasCharacters = await(Serial.available(), 5 Seconds)\nThe default interval between checks is 10 milliseconds: if you need a custom delay interval you can use the more verbose await_with_interval:\n// await WiFi for 10 seconds, check if connected every 500 millis\nbool wifiConnected = await_with_interval(WiFi.status() == WL_CONNECTED, 10 Seconds, 500 Millis)\nHow it works\nThe await macro creates an inline function that loops until the timeout expires. At every loop it checks if the condition is true: if that's the case, it returns true. The inline function construct is needed to get a return value, so you can assign it to a variable or embed directly inside an if test. The following code sample gives you an idea of what's happening.\nbool wifiConnected = await(WiFi.status() == WL_CONNECTED, 10 Seconds)\n\n// conceptually translates to\n\nbool inline_function() {\n    uint32_t start = millis();\n\n    while (millis() - start &lt;= 10000) {\n      if (WiFi.status() == WL_CONNECTED)\n        return true;\n\n      delay(10);\n    }\n\n   return false;\n}\n\nbool wifiConnected = inline_function();\nL'articolo Eloquent bounded waiting: the await construct proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-05T19:50:59+01:00",
            "date_modified": "2019-12-16T23:03:25+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "eloquent",
                "Eloquent library"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/non-blocking-arduino-code/",
            "url": "https://eloquentarduino.github.io/2019/12/non-blocking-arduino-code/",
            "title": "Eloquent non-blocking code: the Every construct",
            "content_html": "<p>The <code>every</code> construct lets you run a piace of code at regular intervals in a fluent way. If you don't need to start, stop, pause your timer, this construct is a valid alternative to more complex timer libraries already available: it only takes a time interval as argument and will execute the code block periodically.</p>\n<p><span id=\"more-209\"></span></p>\n<h3>Definition</h3>\n<pre><code class=\"language-cpp\">#define every(interval) \\\n    static uint32_t __every__##interval = millis(); \\\n    if (millis() - __every__##interval &gt;= interval &amp;&amp; (__every__##interval = millis()))</code></pre>\n<h3>How to use</h3>\n<pre><code>// these are for greater code readability\r\n#define Millis \r\n#define Second  *1000\r\n#define Seconds *1000\r\n</code></pre>\n<pre><code class=\"language-cpp\">int interval = 1 Second;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    every(1000 Millis) {\n        Serial.println(&quot;This line is printed every 1 second&quot;);\n    }\n\n    every(2000 Millis) {\n        Serial.println(&quot;This line is printed every 2 seconds&quot;);\n    }\n\n    every(interval) {\n        interval += 1 Second;\n        Serial.print(&quot;You can have variable intervals too! &quot;);\n        Serial.print(&quot;This line will be printed again in &quot;);\n        Serial.print(interval / 1000);\n        Serial.println(&quot; seconds&quot;);\n    }\n}</code></pre>\n<h3>Caveats</h3>\n<p><code>every</code> is just a macro definition and is not a proper timer, so it has some limitations:</p>\n<ol>\n<li>you can't stop, pause or resume it: once set, it will run forever</li>\n<li>its argument must be the suffix of a valid identifier</li>\n<li>you can't use several <code>every</code> with the exact same argument: you have to put all the code that needs to happen at the same interval in the same block</li>\n</ol>\n<h4>Caveat #2</h4>\n<p>The macro works by generating a variable named like <code>__every__##argument</code></p>\n<pre><code class=\"language-cpp\">every(1) ==&gt; uint32_t __every__1;\nevery(2) ==&gt; uint32_t __every__2;\nevery(a_given_interval) ==&gt; uint32_t __every__a_given_interval;\nevery(an invalid interval) ==&gt; uint32_t __every__an invalid interval; // Syntax error\nevery(1 Second) ==&gt; uint32_t __every__1 *1000; // Syntax error</code></pre>\n<p>So every integer literal and any variable are all valid arguments. Any expression is forbidden.</p>\n<h4>Caveat #3</h4>\n<p>If you use two <code>every</code> with the exact same argument, two variables with the exact same name will be created and it will rise a compile-time error.</p>\n<p>If you can live with this limitations, <code>every</code> only needs the space of an <code>uint32_t</code> to work.</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/non-blocking-arduino-code/\">Eloquent non-blocking code: the Every construct</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "The every construct lets you run a piace of code at regular intervals in a fluent way. If you don't need to start, stop, pause your timer, this construct is a valid alternative to more complex timer libraries already available: it only takes a time interval as argument and will execute the code block periodically.\n\nDefinition\n#define every(interval) \\\n    static uint32_t __every__##interval = millis(); \\\n    if (millis() - __every__##interval &gt;= interval &amp;&amp; (__every__##interval = millis()))\nHow to use\n// these are for greater code readability\r\n#define Millis \r\n#define Second  *1000\r\n#define Seconds *1000\r\n\nint interval = 1 Second;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    every(1000 Millis) {\n        Serial.println(&quot;This line is printed every 1 second&quot;);\n    }\n\n    every(2000 Millis) {\n        Serial.println(&quot;This line is printed every 2 seconds&quot;);\n    }\n\n    every(interval) {\n        interval += 1 Second;\n        Serial.print(&quot;You can have variable intervals too! &quot;);\n        Serial.print(&quot;This line will be printed again in &quot;);\n        Serial.print(interval / 1000);\n        Serial.println(&quot; seconds&quot;);\n    }\n}\nCaveats\nevery is just a macro definition and is not a proper timer, so it has some limitations:\n\nyou can't stop, pause or resume it: once set, it will run forever\nits argument must be the suffix of a valid identifier\nyou can't use several every with the exact same argument: you have to put all the code that needs to happen at the same interval in the same block\n\nCaveat #2\nThe macro works by generating a variable named like __every__##argument\nevery(1) ==&gt; uint32_t __every__1;\nevery(2) ==&gt; uint32_t __every__2;\nevery(a_given_interval) ==&gt; uint32_t __every__a_given_interval;\nevery(an invalid interval) ==&gt; uint32_t __every__an invalid interval; // Syntax error\nevery(1 Second) ==&gt; uint32_t __every__1 *1000; // Syntax error\nSo every integer literal and any variable are all valid arguments. Any expression is forbidden.\nCaveat #3\nIf you use two every with the exact same argument, two variables with the exact same name will be created and it will rise a compile-time error.\nIf you can live with this limitations, every only needs the space of an uint32_t to work.\nL'articolo Eloquent non-blocking code: the Every construct proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-05T19:42:45+01:00",
            "date_modified": "2019-12-16T22:59:36+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "eloquent",
                "Eloquent library"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-install-the-eloquent-library/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-install-the-eloquent-library/",
            "title": "How to install the Eloquent library",
            "content_html": "<p>In this short tutorial I'll show you how you can install the <a href=\"/2019/11/how-to-write-clean-arduino-code-introducing-the-eloquent-library/\">Eloquent library</a> to take advange of all the good things it provides to you.</p>\n<p>It really is super simple, since the Eloquent library is no different from any other library you already installed on your computer, but I'll repeat the steps for clarity.</p>\n<p><span id=\"more-554\"></span></p>\n<h2>1. Download the zip from Github</h2>\n<p>The whole library is hosted on Github, so head over to <a href=\"https://github.com/eloquentarduino/EloquentArduino\">the repo</a> and click <em>Clone or download</em> &gt; <em>Download ZIP</em>.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Repo.png\" alt=\"Download zip from Github repository\" /></p>\n<h2>2. Extract the zip to you library directory</h2>\n<p>Once downloaded, you should extract the zip into your Arduino libraries folder. The path will vary based on your OS and installation, but I expect you to know where it is.</p>\n<h2>3. Strip the -master suffix</h2>\n<p>When downloaded from Github, your zip and your folder will be named <code>EloquentArduino-master</code>: rename the folder to just <code>EloquentArduino</code>, without the master suffix.</p>\n<h2>4. Done</h2>\n<p>If you follwed the steps correctly, the library is ready to be used.</p>\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-install-the-eloquent-library/\">How to install the Eloquent library</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this short tutorial I'll show you how you can install the Eloquent library to take advange of all the good things it provides to you.\nIt really is super simple, since the Eloquent library is no different from any other library you already installed on your computer, but I'll repeat the steps for clarity.\n\n1. Download the zip from Github\nThe whole library is hosted on Github, so head over to the repo and click Clone or download &gt; Download ZIP.\n\n2. Extract the zip to you library directory\nOnce downloaded, you should extract the zip into your Arduino libraries folder. The path will vary based on your OS and installation, but I expect you to know where it is.\n3. Strip the -master suffix\nWhen downloaded from Github, your zip and your folder will be named EloquentArduino-master: rename the folder to just EloquentArduino, without the master suffix.\n4. Done\nIf you follwed the steps correctly, the library is ready to be used.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\nL'articolo How to install the Eloquent library proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-05T17:18:48+01:00",
            "date_modified": "2019-12-17T17:44:29+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "eloq",
                "Eloquent library"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-do-color-identification-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-do-color-identification-on-arduino/",
            "title": "How to do color identification through machine learning on Arduino",
            "content_html": "<p>In this Arduno Machine learning project we're going to use an RGB sensor to identify objects based on their color.<br />\nThis is a remake of the project found on the <a href=\"https://blog.tensorflow.org/2019/11/fruit-identification-using-arduino-and-tensorflow.html\">Tensorflow blog</a>. We're going to use a lot less powerful chip in this tutorial, tough: an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.</p>\n<p><span id=\"more-6\"></span></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: put some colored objects in front of your sensor and save the readings</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h2>1. Features definition</h2>\n<p>We're going to use the RGB components of a color sensor (TCS3200 in my case) to infer which object we're pointing it at. This means our features are going to be of 3-dimensional, which leads to a really simple model with very high accuracy.</p>\n<hr /><p><em>You can do color identification on Arduino using Machine learning without Neural Networks #Arduino #microml #ml #tinyml #MachineLearning #ai #svm</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F12%2Fhow-to-do-color-identification-on-arduino%2F&#038;text=You%20can%20do%20color%20identification%20on%20Arduino%20using%20Machine%20learning%20without%20Neural%20Networks%20%23Arduino%20%23microml%20%23ml%20%23tinyml%20%23MachineLearning%20%23ai%20%23svm&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<h2>2. Record sample data</h2>\n<p>We don't need any processing to get from the sensor readings to the feature vector, so the code will be straight-forward: read each component from the sensor and assign it to the features array. This part will vary based on the specific chip you have: I'll report the code for a TCS 230/3200. </p>\n<pre><code class=\"language-cpp\">#define S2 2\n#define S3 3\n#define sensorOut 4\n\ndouble features[3];\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(S2, OUTPUT);\n  pinMode(S3, OUTPUT);\n  pinMode(sensorOut, INPUT);\n}\n\nvoid loop() {\n  readRGB();\n  printFeatures();\n  delay(100);\n}\n\nint readComponent(bool s2, bool s3) {\n  delay(10);\n  digitalWrite(S2, s2);\n  digitalWrite(S3, s3);\n\n  return pulseIn(sensorOut, LOW);\n}\n\nvoid readRGB() {\n  features[0] = readComponent(LOW, LOW);\n  features[1] = readComponent(HIGH, HIGH);\n  features[2] = readComponent(LOW, HIGH);\n}</code></pre>\n<pre><code class=\"language-cpp\">\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n</code></pre>\n<p>Open the Serial monitor and put some colored objects in front of the sensor: move the object a bit and rotate it, so the samples will include different shades of the color.</p>\n<p>Save the recordings for each color in a file named after the color, so you will get meaningful results later on.</p>\n<div class=\"watchout\">\nDon\u2019t forget to sample the \u201cempty color\u201d too: don\u2019t put anything in front of the sensor and let it record for a while.\n</div>\n<p>If you do a good job, you should end with distinguible features, as show in the contour plot below.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-from-the-colors-features.png\" alt=\"Decision boundaries of 2 PCA components from the colors features\" /></p>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<h2>4. Run the inference</h2>\n<pre><code class=\"language-cpp\">#include model.h\n\nvoid loop() {\n  readRGB();\n  Serial.println(classIdxToName(predict(features)));\n  delay(1000);\n}</code></pre>\n<p>Put some colored object in front of the sensor and see the identified object name printed on the serial monitor.</p>\n<div class=\"watchout\">Do you remember the \"empty color\"? It needs to be recorded so you will get \"empty\" when no object is present, otherwise you'll get unexpected predictions</div>\n<p>Given the simplicity of the task, you should easily achieve near 100% accuracy for different colors (I had some troubles distinguishing orange from yellow because of the bad illumination). Just be sure to replicate the exact same setup both during training and classification.</p>\n<p>That\u2019s it: you deployed machine learning in 2 Kb! </p>\n<p><h4>Project figures</h4>\r\n<p>On my machine, the sketch targeted at the Arduino Nano (old generation) requires 5570 bytes (18%) of program space and 266 bytes (12%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question <em>Can I run machine learning on Arduino?</em> is <strong>definetly YES</strong>.<br />\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlColorIdentificationExample/MicromlColorIdentificationExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-do-color-identification-on-arduino/\">How to do color identification through machine learning on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this Arduno Machine learning project we're going to use an RGB sensor to identify objects based on their color.\nThis is a remake of the project found on the Tensorflow blog. We're going to use a lot less powerful chip in this tutorial, tough: an Arduino Nano (old generation), equipped with 32 kb of flash and only 2 kb of RAM.\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: put some colored objects in front of your sensor and save the readings\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nWe're going to use the RGB components of a color sensor (TCS3200 in my case) to infer which object we're pointing it at. This means our features are going to be of 3-dimensional, which leads to a really simple model with very high accuracy.\nYou can do color identification on Arduino using Machine learning without Neural Networks #Arduino #microml #ml #tinyml #MachineLearning #ai #svmClick To Tweet\n2. Record sample data\nWe don't need any processing to get from the sensor readings to the feature vector, so the code will be straight-forward: read each component from the sensor and assign it to the features array. This part will vary based on the specific chip you have: I'll report the code for a TCS 230/3200. \n#define S2 2\n#define S3 3\n#define sensorOut 4\n\ndouble features[3];\n\nvoid setup() {\n  Serial.begin(115200);\n  pinMode(S2, OUTPUT);\n  pinMode(S3, OUTPUT);\n  pinMode(sensorOut, INPUT);\n}\n\nvoid loop() {\n  readRGB();\n  printFeatures();\n  delay(100);\n}\n\nint readComponent(bool s2, bool s3) {\n  delay(10);\n  digitalWrite(S2, s2);\n  digitalWrite(S3, s3);\n\n  return pulseIn(sensorOut, LOW);\n}\n\nvoid readRGB() {\n  features[0] = readComponent(LOW, LOW);\n  features[1] = readComponent(HIGH, HIGH);\n  features[2] = readComponent(LOW, HIGH);\n}\n\r\nvoid printFeatures() {\r\n    const uint16_t numFeatures = sizeof(features) / sizeof(double);\r\n    \r\n    for (int i = 0; i < numFeatures; i++) {\r\n        Serial.print(features[i]);\r\n        Serial.print(i == numFeatures - 1 ? '\\n' : ',');\r\n    }\r\n}\r\n\nOpen the Serial monitor and put some colored objects in front of the sensor: move the object a bit and rotate it, so the samples will include different shades of the color.\nSave the recordings for each color in a file named after the color, so you will get meaningful results later on.\n\nDon\u2019t forget to sample the \u201cempty color\u201d too: don\u2019t put anything in front of the sensor and let it record for a while.\n\nIf you do a good job, you should end with distinguible features, as show in the contour plot below.\n\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\n4. Run the inference\n#include model.h\n\nvoid loop() {\n  readRGB();\n  Serial.println(classIdxToName(predict(features)));\n  delay(1000);\n}\nPut some colored object in front of the sensor and see the identified object name printed on the serial monitor.\nDo you remember the \"empty color\"? It needs to be recorded so you will get \"empty\" when no object is present, otherwise you'll get unexpected predictions\nGiven the simplicity of the task, you should easily achieve near 100% accuracy for different colors (I had some troubles distinguishing orange from yellow because of the bad illumination). Just be sure to replicate the exact same setup both during training and classification.\nThat\u2019s it: you deployed machine learning in 2 Kb! \nProject figures\r\nOn my machine, the sketch targeted at the Arduino Nano (old generation) requires 5570 bytes (18%) of program space and 266 bytes (12%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question Can I run machine learning on Arduino? is definetly YES.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo How to do color identification through machine learning on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-01T11:35:29+01:00",
            "date_modified": "2019-12-21T07:20:02+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/12/how-to-do-iris-classification-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/12/how-to-do-iris-classification-on-arduino/",
            "title": "How to do Iris classification through machine learning on Arduino",
            "content_html": "<p>In this first tutorial from the series <em><a href=\"/category/programming/arduino-machine-learning/\">Arduino Machine learning</a></em> we're going to implement the &quot;Hello world&quot; of Machine learning projects: classifying the Iris dataset on an Arduino board. The <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">Iris dataset</a> is a well known one in the Machine learning world and is often used in introductory tutorials about classification.<br />\nIn this tutorial we're going to run the classification directly on a Arduino Nano board (old generation), equipped with 32 kb of flash and only 2 kb of RAM: that's the only thing you will need!</p>\n<p><span id=\"more-409\"></span></p>\n<p>This tutorial is part of a <a href=\"/category/programming/arduino-machine-learning/\" target=\"_blank\">series of tutorials</a> about Machine learning on Arduino and all follow the same outline:</p>\r\n<ol>\r\n  <li>define the features</li>\r\n  <li>record sample data: we'll use the publicly available dataset</li>\r\n <li>train an SVM classifier with Python's scikit-learn and export it to optimized C code using <code><a href=\"https://github.com/agrimagsrl/micromlgen\" target=\"_blank\">micromlgen</a></code></li>\r\n <li>copy and paste the generated code in a <code>model.h</code> file in the Arduino project and call <code>predict()</code> from it</li>\r\n</ol>\n<h3>1. Features definition</h3>\n<p>There are 4 features in this dataset: sepal length, sepal width, petal length, petal width; and 3 classes: Setosa, Versicolor, Virginica. You can see in the picture below how they relate to the actual flower.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/iris-278x300.png\" alt=\"Iris features illustrated @ credits to https://gallery.azure.ai/Experiment/Classify-Iris-Dataset-using-Decision-Forest-1\" /></p>\n<h3>2. Sample data</h3>\n<p>You may download the dataset <a href=\"https://gist.github.com/netj/8836201\">here</a>.<br />\nAn excerpt of the dataset is reported in the following table.</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">sepal.length</th>\n<th style=\"text-align: center;\">sepal.width</th>\n<th style=\"text-align: center;\">petal.length</th>\n<th style=\"text-align: center;\">petal.width</th>\n<th style=\"text-align: center;\">variety</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">5.1</td>\n<td style=\"text-align: center;\">3.5</td>\n<td style=\"text-align: center;\">1.4</td>\n<td style=\"text-align: center;\">0.2</td>\n<td style=\"text-align: center;\">Setosa</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">4.9</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">1.4</td>\n<td style=\"text-align: center;\">0.2</td>\n<td style=\"text-align: center;\">Setosa</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">4.6</td>\n<td style=\"text-align: center;\">3.1</td>\n<td style=\"text-align: center;\">1.5</td>\n<td style=\"text-align: center;\">0.2</td>\n<td style=\"text-align: center;\">Setosa</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">5.8</td>\n<td style=\"text-align: center;\">2.6</td>\n<td style=\"text-align: center;\">4</td>\n<td style=\"text-align: center;\">1.2</td>\n<td style=\"text-align: center;\">Versicolor</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">5.6</td>\n<td style=\"text-align: center;\">2.7</td>\n<td style=\"text-align: center;\">4.2</td>\n<td style=\"text-align: center;\">1.3</td>\n<td style=\"text-align: center;\">Versicolor</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">6.3</td>\n<td style=\"text-align: center;\">2.5</td>\n<td style=\"text-align: center;\">5</td>\n<td style=\"text-align: center;\">1.9</td>\n<td style=\"text-align: center;\">Virginica</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">6.5</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">5.2</td>\n<td style=\"text-align: center;\">2</td>\n<td style=\"text-align: center;\">Virginica</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">5.9</td>\n<td style=\"text-align: center;\">3</td>\n<td style=\"text-align: center;\">5.1</td>\n<td style=\"text-align: center;\">1.8</td>\n<td style=\"text-align: center;\">Virginica</td>\n</tr>\n</tbody>\n</table>\n<p>A contour plot of this dataset is depicted in the image below.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Decision-boundaries-of-2-PCA-components-of-Iris-features.svg\" alt=\"Decision boundaries of 2 PCA components of Iris features\" /></p>\n<h3>3. Train and export the SVM classifier</h3>\r\n\r\n<p>For a detailed guide refer to the <a href=\"/2019/11/how-to-train-a-classifier-in-scikit-learn\" target=\"_blank\">tutorial</a></p>\r\n\r\n<p>\r\n<pre><code class=\"language-python\">from sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)</code></pre>\r\n\r\n<p>At this point you have to copy the printed code and import it in your Arduino project, in a file called <code>model.h</code>.</p>\n<h3>4. Run the inference</h3>\n<p>We will be running the inferences from the features entered via Serial monitor: you type 4 float values representing the 4 features and get back the predicted Iris species.</p>\n<pre><code class=\"language-cpp\">#include &quot;iris.h&quot;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    if (Serial.available()) {\n        double features[4];\n\n        for (int i = 0; i &lt; 4; i++) {\n            // split features on comma (,)\n            String feature = Serial.readStringUntil(&#039;,&#039;);\n\n            features[i] = atof(feature.c_str());\n        }\n\n        Serial.print(&quot;Detected species: &quot;);\n        Serial.println(classIdxToName(predict(features)));\n    }\n\n    delay(10);\n}</code></pre>\n<p>If you open the Serial monitor you should see something like the next picture as you type in the features from different species.</p>\n<p><img src=\"https://eloquentarduino.github.io/wp-content/uploads/2019/12/Iris-serial.png\" alt=\"Iris classification serial output\" /></p>\n<p>That\u2019s it: you deployed machine learning in 2 Kb!</p>\n<p><h4>Project figures</h4>\r\n<p>On my machine, the sketch targeted at the Arduino Nano (old generation) requires 7446 bytes (24%) of program space and 302 bytes (14%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question <em>Can I run machine learning on Arduino?</em> is <strong>definetly YES</strong>.<br />\n<br><p>Did you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.</p><br />\n<hr>\r\n<p>Check the full project code on <a href=\"https://github.com/eloquentarduino/EloquentArduino/blob/master/examples/MicromlIrisExample/MicromlIrisExample.ino\" target=\"_blank\">Github</a></p></p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/12/how-to-do-iris-classification-on-arduino/\">How to do Iris classification through machine learning on Arduino</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this first tutorial from the series Arduino Machine learning we're going to implement the &quot;Hello world&quot; of Machine learning projects: classifying the Iris dataset on an Arduino board. The Iris dataset is a well known one in the Machine learning world and is often used in introductory tutorials about classification.\nIn this tutorial we're going to run the classification directly on a Arduino Nano board (old generation), equipped with 32 kb of flash and only 2 kb of RAM: that's the only thing you will need!\n\nThis tutorial is part of a series of tutorials about Machine learning on Arduino and all follow the same outline:\r\n\r\n  define the features\r\n  record sample data: we'll use the publicly available dataset\r\n train an SVM classifier with Python's scikit-learn and export it to optimized C code using micromlgen\r\n copy and paste the generated code in a model.h file in the Arduino project and call predict() from it\r\n\n1. Features definition\nThere are 4 features in this dataset: sepal length, sepal width, petal length, petal width; and 3 classes: Setosa, Versicolor, Virginica. You can see in the picture below how they relate to the actual flower.\n\n2. Sample data\nYou may download the dataset here.\nAn excerpt of the dataset is reported in the following table.\n\n\n\nsepal.length\nsepal.width\npetal.length\npetal.width\nvariety\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nSetosa\n\n\n4.9\n3\n1.4\n0.2\nSetosa\n\n\n4.6\n3.1\n1.5\n0.2\nSetosa\n\n\n5.8\n2.6\n4\n1.2\nVersicolor\n\n\n5.6\n2.7\n4.2\n1.3\nVersicolor\n\n\n6.3\n2.5\n5\n1.9\nVirginica\n\n\n6.5\n3\n5.2\n2\nVirginica\n\n\n5.9\n3\n5.1\n1.8\nVirginica\n\n\n\nA contour plot of this dataset is depicted in the image below.\n\n3. Train and export the SVM classifier\r\n\r\nFor a detailed guide refer to the tutorial\r\n\r\n\r\nfrom sklearn.svm import SVC\r\nfrom micromlgen import port\r\n\r\n# put your samples in the dataset folder\r\n# one class per file\r\n# one feature vector per line, in CSV format\r\nfeatures, classmap = load_features('dataset/')\r\nX, y = features[:, :-1], features[:, -1]\r\nclassifier = SVC(kernel='linear').fit(X, y)\r\nc_code = port(classifier, classmap=classmap)\r\nprint(c_code)\r\n\r\nAt this point you have to copy the printed code and import it in your Arduino project, in a file called model.h.\n4. Run the inference\nWe will be running the inferences from the features entered via Serial monitor: you type 4 float values representing the 4 features and get back the predicted Iris species.\n#include &quot;iris.h&quot;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    if (Serial.available()) {\n        double features[4];\n\n        for (int i = 0; i &lt; 4; i++) {\n            // split features on comma (,)\n            String feature = Serial.readStringUntil(&#039;,&#039;);\n\n            features[i] = atof(feature.c_str());\n        }\n\n        Serial.print(&quot;Detected species: &quot;);\n        Serial.println(classIdxToName(predict(features)));\n    }\n\n    delay(10);\n}\nIf you open the Serial monitor you should see something like the next picture as you type in the features from different species.\n\nThat\u2019s it: you deployed machine learning in 2 Kb!\nProject figures\r\nOn my machine, the sketch targeted at the Arduino Nano (old generation) requires 7446 bytes (24%) of program space and 302 bytes (14%) of RAM. This means you could actually run machine learning in even less space than what the Arduino Nano provides. So, the answer to the question Can I run machine learning on Arduino? is definetly YES.\nDid you find this tutorial useful? Was is it easy to follow or did I miss something? Let me know in the comments so I can keep improving the blog.\n\r\nCheck the full project code on Github\nL'articolo How to do Iris classification through machine learning on Arduino proviene da Eloquent Arduino Blog.",
            "date_published": "2019-12-01T10:02:02+01:00",
            "date_modified": "2019-12-20T07:18:46+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/11/how-to-create-a-classifier-for-arduino-machine-learning-projects/",
            "url": "https://eloquentarduino.github.io/2019/11/how-to-create-a-classifier-for-arduino-machine-learning-projects/",
            "title": "This is how I create my Arduino Machine learning classifiers in 4 easy steps",
            "content_html": "<p>In this post I'll show you how I train my classifiers in scikit-learn and export them for Arduino machine learning projects. Since this is a repetitive task, you can save a short snippet of Python code on your PC and use it whenever you need to train a classifier from Arduino data. It really is a general-purpose piece of code that reads the files from a folder and generates a features matrix from them; the useful bit, so to say, is that it generates a classmap to translate class indexes to readable names.</p>\n<p><span id=\"more-104\"></span></p>\n<h2>Setup</h2>\n<div class=\"watchout\">The code assumes you've saved your samples in a folder, one class per file, one sample per line.</div>\n<pre><code class=\"language-python\">import numpy as np\nfrom glob import glob\nfrom os.path import basename\n\ndef load_features(folder):\n    dataset = None\n    classmap = {}\n    for class_idx, filename in enumerate(glob(&#039;%s/*.csv&#039; % folder)):\n        class_name = basename(filename)[:-4]\n        classmap[class_idx] = class_name\n        samples = np.loadtxt(filename)\n        labels = np.ones((len(samples), 1)) * class_idx\n        samples = np.hstack((samples, labels))\n        dataset = samples if dataset is None else np.vstack((dataset, samples))\n    return dataset, classmap</code></pre>\n<h2>Train the classifier</h2>\n<p>Include the snippet in your scikit-learn project and use it to train your SVM classifier.</p>\n<pre><code class=\"language-python\">from sklearn.svm import SVC\n\nfeatures, classmap = load_features(&#039;datasets/colors/&#039;)\nX, y = features[:, :-1], features[:, -1]\nclassifier = SVC(kernel=&#039;linear&#039;).fit(X, y)</code></pre>\n<h2>Generate C code</h2>\n<p>Now you can convert the trained classifier to C code using the <a href=\"https://github.com/agrimagsrl/micromlgen\"><code>micromlgen</code></a> package.</p>\n<pre><code class=\"language-python\">pip install micromlgen</code></pre>\n<pre><code class=\"language-python\">from micromlgen import port\n\nc_code = port(classifier)\nprint(c_code)</code></pre>\n<p>This is the code you need to import in your Arduino project. To follow along with the tutorials on this blog, save it in a file called <code>model.h</code>.</p>\n<h2>Use in Arduino project</h2>\n<p>There are two methods you will need to call to run the predictions in your project:</p>\n<ol>\n<li><code>predict(double features[])</code>: it runs the actual prediction and returns a number representing the predicted class</li>\n<li><code>classIdxToName(uint8_t classIdx)</code>: converts the class index to a readable string, based on the classmap generated from your files</li>\n</ol>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid classify() {\n    Serial.print(&quot;Predicted class: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}</code></pre>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/11/how-to-create-a-classifier-for-arduino-machine-learning-projects/\">This is how I create my Arduino Machine learning classifiers in 4 easy steps</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "In this post I'll show you how I train my classifiers in scikit-learn and export them for Arduino machine learning projects. Since this is a repetitive task, you can save a short snippet of Python code on your PC and use it whenever you need to train a classifier from Arduino data. It really is a general-purpose piece of code that reads the files from a folder and generates a features matrix from them; the useful bit, so to say, is that it generates a classmap to translate class indexes to readable names.\n\nSetup\nThe code assumes you've saved your samples in a folder, one class per file, one sample per line.\nimport numpy as np\nfrom glob import glob\nfrom os.path import basename\n\ndef load_features(folder):\n    dataset = None\n    classmap = {}\n    for class_idx, filename in enumerate(glob(&#039;%s/*.csv&#039; % folder)):\n        class_name = basename(filename)[:-4]\n        classmap[class_idx] = class_name\n        samples = np.loadtxt(filename)\n        labels = np.ones((len(samples), 1)) * class_idx\n        samples = np.hstack((samples, labels))\n        dataset = samples if dataset is None else np.vstack((dataset, samples))\n    return dataset, classmap\nTrain the classifier\nInclude the snippet in your scikit-learn project and use it to train your SVM classifier.\nfrom sklearn.svm import SVC\n\nfeatures, classmap = load_features(&#039;datasets/colors/&#039;)\nX, y = features[:, :-1], features[:, -1]\nclassifier = SVC(kernel=&#039;linear&#039;).fit(X, y)\nGenerate C code\nNow you can convert the trained classifier to C code using the micromlgen package.\npip install micromlgen\nfrom micromlgen import port\n\nc_code = port(classifier)\nprint(c_code)\nThis is the code you need to import in your Arduino project. To follow along with the tutorials on this blog, save it in a file called model.h.\nUse in Arduino project\nThere are two methods you will need to call to run the predictions in your project:\n\npredict(double features[]): it runs the actual prediction and returns a number representing the predicted class\nclassIdxToName(uint8_t classIdx): converts the class index to a readable string, based on the classmap generated from your files\n\n#include &quot;model.h&quot;\n\nvoid classify() {\n    Serial.print(&quot;Predicted class: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}\nL'articolo This is how I create my Arduino Machine learning classifiers in 4 easy steps proviene da Eloquent Arduino Blog.",
            "date_published": "2019-11-11T22:10:51+01:00",
            "date_modified": "2019-12-16T19:41:16+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        },
        {
            "id": "https://eloquentarduino.github.io/2019/11/you-can-run-machine-learning-on-arduino/",
            "url": "https://eloquentarduino.github.io/2019/11/you-can-run-machine-learning-on-arduino/",
            "title": "You can run Machine learning on Arduino. And any other MCU out there too!",
            "content_html": "<p><a href=\"https://www.quora.com/I-want-to-make-a-robot-with-an-Arduino-that-uses-basic-machine-learning-where-can-I-start\">A</a> <a href=\"https://robotics.stackexchange.com/questions/568/is-it-possible-to-run-a-neural-network-on-a-microcontroller\">lot</a> <a href=\"https://www.reddit.com/r/robotics/comments/bnmm75/arduino_for_machine_learning/\">of</a> <a href=\"https://www.quora.com/How-do-I-use-machine-learning-with-Arduino\">forum</a> <a href=\"https://forum.arduino.cc/index.php?topic=63981.0\">threads</a> ask about the possibility to run Machine learning on Arduino.<br />\nThe answers mostly follow in one of these 3 categories:</p>\n<ol>\n<li>Arduino is too resource-constrained to handle Machine learning</li>\n<li>Come up with a naive implementation of a <a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron\">Multi Layer Perceptron</a></li>\n<li>(recently) Sure! You can use <a href=\"https://www.tensorflow.org/lite/microcontrollers\">Tensorflow Lite for Microcontrollers</a></li>\n</ol>\n<p>No single answer I read talked about the other 100s alghoritms that fall under the Machine learning umbrella. <strong>No. Single. One.</strong> Let me explain what I think is wrong with this.</p>\n<p><span id=\"more-76\"></span></p>\n<p>First of all I'd like to state one absolutely important thing:</p>\n<hr /><p><em>Artificial intelligence \u2260 Machine learning \u2260 Neural networks. This should be clear</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F11%2Fyou-can-run-machine-learning-on-arduino%2F&#038;text=Artificial%20intelligence%20%E2%89%A0%20Machine%20learning%20%E2%89%A0%20Neural%20networks.%20This%20should%20be%20clear&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>I admit most of those questions seemed to come from principiants. Also the answers, though, most often lack any sound knowledge about the topic.</p>\n<hr /><p><em>You can run classification and regression on Arduino boards, even the less powerful ones: just don&#039;t use Neural networks. It&#039;s that simple.</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F11%2Fyou-can-run-machine-learning-on-arduino%2F&#038;text=You%20can%20run%20classification%20and%20regression%20on%20Arduino%20boards%2C%20even%20the%20less%20powerful%20ones%3A%20just%20don%27t%20use%20Neural%20networks.%20It%27s%20that%20simple.&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<h2>Introducing MicroML generator</h2>\n<p>So I do you <em>actually</em> run machine learning on such constrained devices?</p>\n<p>Here you are: <a href=\"https://github.com/eloquentarduino/micromlgen\">MicroML</a> is a project to bring Machine learning algorithms to microcontrollers. It was born as an alternative to Tensorflow for Microcontrollers, which is solely dedicated to Artificial Neural Networks: here you will find leaner alternatives to neural networks to run inference <strong>even on 8-bit microcontrollers</strong>.</p>\n<p>Quoting from the Tensoflow blog: <em>The core runtime fits in 16 KB on an Arm Cortex M3</em> (that's just the runtime, without any actual operator!). </p>\n<hr /><p><em>MicroML lets you deploy models that fit in under 2 Kb of RAM #microml #arduino #ai #ml</em><br /><a href='https://twitter.com/intent/tweet?url=http%3A%2F%2Feloquent.blog%2F2019%2F11%2Fyou-can-run-machine-learning-on-arduino%2F&#038;text=MicroML%20lets%20you%20deploy%20models%20that%20fit%20in%20under%202%20Kb%20of%20RAM%20%23microml%20%23arduino%20%23ai%20%23ml&#038;via=ArduinoEloquent&#038;related=ArduinoEloquent' target='_blank' rel=\"noopener noreferrer\" >Click To Tweet</a><br /><hr />\n<p>At the current state, it can convert <a href=\"https://en.wikipedia.org/wiki/Support-vector_machine\">Support Vector Machines</a> to optimized C code you can deploy on any MCU of you choice: Arduino (Uno, Nano, Micro...), ESP8266, ESP32 and really any other MCU with C support.</p>\n<div class=\"watchout\">At the moment you can't deploy to Attiny boards because their compiler seems not to support variadic functions: I'll fix this as soon as possible, already got a working implementation</div>\n<p>Why Support Vector Machines? Because they're really good at classifying highly-dimensional features and are quite easy to optimize for RAM-constrained environments (check the tutorial on <a href=\"/2019/12/how-to-do-gesture-identification-on-arduino/\">Gesture identification</a> which has 90 features!)</p>\n<h2>How to port a classifier</h2>\n<p>First of all, you need to train a classifier. You have to use the Python's library <a href=\"https://scikit-learn.org/stable/\">scikit-learn</a> \u2014 which you're probably already using considering its widespread adoption. Then you need to install the MicroML package.</p>\n<pre><code class=\"language-python\">pip install micromlgen</code></pre>\n<p>Finally, you <code>port</code> your trained classifier to optimized C code.</p>\n<pre><code class=\"language-python\">from micromlgen import port\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\n\nif __name__ == &#039;__main__&#039;:\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    clf = SVC(kernel=&#039;linear&#039;).fit(X, y)\n    print(port(clf))</code></pre>\n<p>That's it: you now have all you need to do classification in your Arduino projects.</p>\n<h2>Existing alternatives</h2>\n<p>There exists some alternatives to this library, but they suffer from some limitations:</p>\n<ol>\n<li><a href=\"https://github.com/nok/sklearn-porter\">sklearn-porter</a> can output C code (among the others), but it's not optimized for microcontrollers. You'll hit a wall on RAM because it needs to declare all the support vectors in memory (to have an idea, the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\">breast cancer dataset</a> produces a 57x30 matrix of doubles, totalling 6840 bytes just for the support vectors).</li>\n<li>I found one once, but can't find it again </li>\n</ol>\n<p>My effort was to find an implementation that needed the least amount possible of memory: this was possible sacrificing the program space, but that's less often a problem since RAM is usually the most limiting factor. If your model fills up the program space you can revert to <code>sklearn-porter</code> (if you have enough RAM, of course).</p>\n<h2>Use in Arduino project</h2>\n<p>There are two methods you will need to call to run the predictions in your project:</p>\n<ol>\n<li><code>predict(double features[])</code>: it runs the actual prediction and returns a number representing the predicted class</li>\n<li><code>classIdxToName(uint8_t classIdx)</code>: converts the class index to a readable string, based on the classmap generated from your files</li>\n</ol>\n<pre><code class=\"language-cpp\">#include &quot;model.h&quot;\n\nvoid classify() {\n    Serial.print(&quot;Predicted class: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}</code></pre>\n<hr />\n<p>I'm starting a series of tutorials about hands-on projects to put Machine learning in use: you can follow the <strong>Related posts</strong> links to follow along, so keep reading!</p>\n<p>L'articolo <a rel=\"nofollow\" href=\"https://eloquentarduino.github.io/2019/11/you-can-run-machine-learning-on-arduino/\">You can run Machine learning on Arduino. And any other MCU out there too!</a> proviene da <a rel=\"nofollow\" href=\"http://eloquentarduino.github.io/\">Eloquent Arduino Blog</a>.</p>\n",
            "content_text": "A lot of forum threads ask about the possibility to run Machine learning on Arduino.\nThe answers mostly follow in one of these 3 categories:\n\nArduino is too resource-constrained to handle Machine learning\nCome up with a naive implementation of a Multi Layer Perceptron\n(recently) Sure! You can use Tensorflow Lite for Microcontrollers\n\nNo single answer I read talked about the other 100s alghoritms that fall under the Machine learning umbrella. No. Single. One. Let me explain what I think is wrong with this.\n\nFirst of all I'd like to state one absolutely important thing:\nArtificial intelligence \u2260 Machine learning \u2260 Neural networks. This should be clearClick To Tweet\nI admit most of those questions seemed to come from principiants. Also the answers, though, most often lack any sound knowledge about the topic.\nYou can run classification and regression on Arduino boards, even the less powerful ones: just don&#039;t use Neural networks. It&#039;s that simple.Click To Tweet\nIntroducing MicroML generator\nSo I do you actually run machine learning on such constrained devices?\nHere you are: MicroML is a project to bring Machine learning algorithms to microcontrollers. It was born as an alternative to Tensorflow for Microcontrollers, which is solely dedicated to Artificial Neural Networks: here you will find leaner alternatives to neural networks to run inference even on 8-bit microcontrollers.\nQuoting from the Tensoflow blog: The core runtime fits in 16 KB on an Arm Cortex M3 (that's just the runtime, without any actual operator!). \nMicroML lets you deploy models that fit in under 2 Kb of RAM #microml #arduino #ai #mlClick To Tweet\nAt the current state, it can convert Support Vector Machines to optimized C code you can deploy on any MCU of you choice: Arduino (Uno, Nano, Micro...), ESP8266, ESP32 and really any other MCU with C support.\nAt the moment you can't deploy to Attiny boards because their compiler seems not to support variadic functions: I'll fix this as soon as possible, already got a working implementation\nWhy Support Vector Machines? Because they're really good at classifying highly-dimensional features and are quite easy to optimize for RAM-constrained environments (check the tutorial on Gesture identification which has 90 features!)\nHow to port a classifier\nFirst of all, you need to train a classifier. You have to use the Python's library scikit-learn \u2014 which you're probably already using considering its widespread adoption. Then you need to install the MicroML package.\npip install micromlgen\nFinally, you port your trained classifier to optimized C code.\nfrom micromlgen import port\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\n\nif __name__ == &#039;__main__&#039;:\n    iris = load_iris()\n    X = iris.data\n    y = iris.target\n    clf = SVC(kernel=&#039;linear&#039;).fit(X, y)\n    print(port(clf))\nThat's it: you now have all you need to do classification in your Arduino projects.\nExisting alternatives\nThere exists some alternatives to this library, but they suffer from some limitations:\n\nsklearn-porter can output C code (among the others), but it's not optimized for microcontrollers. You'll hit a wall on RAM because it needs to declare all the support vectors in memory (to have an idea, the breast cancer dataset produces a 57x30 matrix of doubles, totalling 6840 bytes just for the support vectors).\nI found one once, but can't find it again \n\nMy effort was to find an implementation that needed the least amount possible of memory: this was possible sacrificing the program space, but that's less often a problem since RAM is usually the most limiting factor. If your model fills up the program space you can revert to sklearn-porter (if you have enough RAM, of course).\nUse in Arduino project\nThere are two methods you will need to call to run the predictions in your project:\n\npredict(double features[]): it runs the actual prediction and returns a number representing the predicted class\nclassIdxToName(uint8_t classIdx): converts the class index to a readable string, based on the classmap generated from your files\n\n#include &quot;model.h&quot;\n\nvoid classify() {\n    Serial.print(&quot;Predicted class: &quot;);\n    Serial.println(classIdxToName(predict(features)));\n}\n\nI'm starting a series of tutorials about hands-on projects to put Machine learning in use: you can follow the Related posts links to follow along, so keep reading!\nL'articolo You can run Machine learning on Arduino. And any other MCU out there too! proviene da Eloquent Arduino Blog.",
            "date_published": "2019-11-10T20:18:40+01:00",
            "date_modified": "2019-12-21T07:13:12+01:00",
            "author": {
                "name": "simone",
                "url": "https://eloquentarduino.github.io/author/simone/",
                "avatar": "http://1.gravatar.com/avatar/d670eb91ca3b1135f213ffad83cb8de4?s=512&d=mm&r=g"
            },
            "tags": [
                "microml",
                "Arduino Machine learning"
            ]
        }
    ]
}